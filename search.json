[
  {
    "objectID": "listing-danl-210-hw.html",
    "href": "listing-danl-210-hw.html",
    "title": "DANL 210 - Homework",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nHomework 1\n\n\nSurvey, Personal Website, and Python Basics\n\n\nFebruary 5, 2025\n\n\n\n\nHomework 2\n\n\nPandas Basics\n\n\nFebruary 20, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "econml.html",
    "href": "econml.html",
    "title": "Causal Machine Learning Bookmarks",
    "section": "",
    "text": "Dive into Causal Machine Learning, The World Bank and Pontificia Universidad Cat√≥lica del Per√∫, Alexander Quispe et. al. \nMIT 14.388: Inference on Causal and Structural Parameters Using ML and AI, Department of Economics, MIT, Victor Chernozukhov\n\nPython Website\nJulia Website \n\nMGTECON 634: ML-based Causal Inference, Stanford, Susan Athey \nMachine Learning & Causal Inference: A Short Course, Stanford, Susan Athey, Jan Spiess, and Stefan Wager\n\nTutorial\nYouTube \n\n2018 American Economic Association Continuing Education: Machine Learning and Econometrics, Susan Athey and Guido Imbens \nCausal Inference and Machine Learning in Practice with EconML and CausalML: Industrial Use Cases at Microsoft, TripAdvisor, Uber \nDoubleML: Python and R Packages for the Double/Debiased Machine Learning Framework, P. Bach, V. Chernozhukov, M. S. Kurz, and M. Spindler \nEconML: A Python Package for ML-based Heterogeneous Treatment Effects Estimation, Microsoft \nCausalML: A Python Package for ML-based Causal Inference, Uber"
  },
  {
    "objectID": "econml.html#causal-machine-learning",
    "href": "econml.html#causal-machine-learning",
    "title": "Causal Machine Learning Bookmarks",
    "section": "",
    "text": "Dive into Causal Machine Learning, The World Bank and Pontificia Universidad Cat√≥lica del Per√∫, Alexander Quispe et. al. \nMIT 14.388: Inference on Causal and Structural Parameters Using ML and AI, Department of Economics, MIT, Victor Chernozukhov\n\nPython Website\nJulia Website \n\nMGTECON 634: ML-based Causal Inference, Stanford, Susan Athey \nMachine Learning & Causal Inference: A Short Course, Stanford, Susan Athey, Jan Spiess, and Stefan Wager\n\nTutorial\nYouTube \n\n2018 American Economic Association Continuing Education: Machine Learning and Econometrics, Susan Athey and Guido Imbens \nCausal Inference and Machine Learning in Practice with EconML and CausalML: Industrial Use Cases at Microsoft, TripAdvisor, Uber \nDoubleML: Python and R Packages for the Double/Debiased Machine Learning Framework, P. Bach, V. Chernozhukov, M. S. Kurz, and M. Spindler \nEconML: A Python Package for ML-based Heterogeneous Treatment Effects Estimation, Microsoft \nCausalML: A Python Package for ML-based Causal Inference, Uber"
  },
  {
    "objectID": "econml.html#machine-learning-and-big-data",
    "href": "econml.html#machine-learning-and-big-data",
    "title": "Causal Machine Learning Bookmarks",
    "section": "Machine Learning and Big Data",
    "text": "Machine Learning and Big Data\n\n2023 American Economic Association Continuing Education: Machine Learning and Big Data, Melissa Dell and Matthew Harding \nMachine Learning for Economists (ml4econ), Bank of Israel, Itamar Caspi and Ariel Mansura"
  },
  {
    "objectID": "econml.html#causal-inference",
    "href": "econml.html#causal-inference",
    "title": "Causal Machine Learning Bookmarks",
    "section": "Causal Inference",
    "text": "Causal Inference\n\nCausal Inference: The Mixtape, Scott Cunningham \nCausal Inference for the Brave and True, Matheus Facure \nCausal Inference and Its Applications in Online Industry, Alex Deng \nApplied Empirical Methods, Yale SOM, Paul Goldsmith-Pinkham\n\nYouTube \n\nCausal Inference with Panel Data, Department of Political Science, Stanford, Yiqing Xu\n\nYouTube \n\nCausal Inference: What If, Miguel A. Hern√°n and James M. Robins \nRecent Developments in Difference-in-Differences, Vienna University of Economics and Business, Asjad Naqvi \nDifference-in-Differences Blog \nGov 2003: Causal Inference, Department of Government, Harvard, Matthew Blackwell"
  },
  {
    "objectID": "econml.html#researchers-in-causal-machine-learning",
    "href": "econml.html#researchers-in-causal-machine-learning",
    "title": "Causal Machine Learning Bookmarks",
    "section": "Researchers in Causal Machine Learning",
    "text": "Researchers in Causal Machine Learning\n\nSusan Athey \nAlexandre Belloni \nVictor Chernozhukov \nCarlos Cinelli \nChristian Hansen \nGuido Imbens\nJann Spiess \nStefan Wager"
  },
  {
    "objectID": "listing-danl-210-cw.html",
    "href": "listing-danl-210-cw.html",
    "title": "DANL 210 - Classwork",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nClasswork 1\n\n\nBuilding a Personal Website using Git, GitHub, and RStudio with Quarto\n\n\nJanuary 24, 2025\n\n\n\n\nClasswork 2\n\n\nMarkdown Basics\n\n\nJanuary 24, 2025\n\n\n\n\nClasswork 3\n\n\nQuarto Website Basics\n\n\nJanuary 27, 2025\n\n\n\n\nClasswork 4\n\n\nPython Basics\n\n\nJanuary 29, 2025\n\n\n\n\nClasswork 5\n\n\nPandas Basics - Loading, Summarizing, Selecting, Counting, Sorting, and Indexing Data\n\n\nFebruary 12, 2025\n\n\n\n\nClasswork 6\n\n\nPandas Basics - Convering Data Types; Filtering Data; Dealing with Missing Values/Duplicates\n\n\nFebruary 17, 2025\n\n\n\n\nClasswork 7\n\n\nPandas Basics - Reshaping DataFrames; Joining DataFrames; Concatenating Rows and Columns\n\n\nFebruary 24, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DANL 210-01: Data Preparation and Management, Spring 2025",
    "section": "",
    "text": "Welcome! üëã\n\\(-\\) Explore, Learn, and Grow with Data Analytics! üåü"
  },
  {
    "objectID": "index.html#bullet-lecture-slides",
    "href": "index.html#bullet-lecture-slides",
    "title": "DANL 210-01: Data Preparation and Management, Spring 2025",
    "section": "\\(\\bullet\\,\\) Lecture Slides üöÄ",
    "text": "\\(\\bullet\\,\\) Lecture Slides üöÄ\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nLecture 11\n\n\nFebruary 21, 2025\n\n\n\n\nLecture 10\n\n\nFebruary 19, 2025\n\n\n\n\nLecture 9\n\n\nFebruary 17, 2025\n\n\n\n\nLecture 8\n\n\nFebruary 14, 2025\n\n\n\n\nLecture 7\n\n\nFebruary 12, 2025\n\n\n\n\nLecture 6\n\n\nFebruary 10, 2025\n\n\n\n\nLecture 5\n\n\nFebruary 3, 2025\n\n\n\n\nLecture 4\n\n\nJanuary 31, 2025\n\n\n\n\nLecture 3\n\n\nJanuary 27, 2025\n\n\n\n\nLecture 2\n\n\nJanuary 24, 2025\n\n\n\n\nLecture 1\n\n\nJanuary 22, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-classwork",
    "href": "index.html#bullet-classwork",
    "title": "DANL 210-01: Data Preparation and Management, Spring 2025",
    "section": "\\(\\bullet\\,\\) Classwork ‚å®Ô∏è",
    "text": "\\(\\bullet\\,\\) Classwork ‚å®Ô∏è\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nClasswork 7\n\n\nFebruary 24, 2025\n\n\n\n\nClasswork 6\n\n\nFebruary 17, 2025\n\n\n\n\nClasswork 5\n\n\nFebruary 12, 2025\n\n\n\n\nClasswork 4\n\n\nJanuary 29, 2025\n\n\n\n\nClasswork 3\n\n\nJanuary 27, 2025\n\n\n\n\nClasswork 2\n\n\nJanuary 24, 2025\n\n\n\n\nClasswork 1\n\n\nJanuary 24, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bullet-homework",
    "href": "index.html#bullet-homework",
    "title": "DANL 210-01: Data Preparation and Management, Spring 2025",
    "section": "\\(\\bullet\\,\\) Homework üíª",
    "text": "\\(\\bullet\\,\\) Homework üíª\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nHomework 2\n\n\nFebruary 20, 2025\n\n\n\n\nHomework 1\n\n\nFebruary 5, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "listing-danl-210-lec.html",
    "href": "listing-danl-210-lec.html",
    "title": "DANL 210 - Lecture",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nLecture 1\n\n\nSyllabus, Course Outline, and Introduction\n\n\nJanuary 22, 2025\n\n\n\n\nLecture 2\n\n\nPrologue; DANL Tools; Building a Website; Markdown\n\n\nJanuary 24, 2025\n\n\n\n\nLecture 3\n\n\nGetting Started with Jupyter Notebook and Quarto\n\n\nJanuary 27, 2025\n\n\n\n\nLecture 4\n\n\nPython Basics I\n\n\nJanuary 31, 2025\n\n\n\n\nLecture 5\n\n\nPython Basics II\n\n\nFebruary 3, 2025\n\n\n\n\nLecture 6\n\n\npandas Basics - Loading Data\n\n\nFebruary 10, 2025\n\n\n\n\nLecture 7\n\n\npandas Basics - Getting a Summary of Data; Selecting Variables; Counting Methods; Sorting Methods\n\n\nFebruary 12, 2025\n\n\n\n\nLecture 8\n\n\npandas Basics - Sorting Methods; Setting a New Index; Locating Observations/Values\n\n\nFebruary 14, 2025\n\n\n\n\nLecture 9\n\n\npandas Basics - Mathematical & Vectorized Operations; Adding, Removing, & Renaming Variables; Data Types; Filtering by a Condition\n\n\nFebruary 17, 2025\n\n\n\n\nLecture 10\n\n\npandas Basics - Filtering by a Condition\n\n\nFebruary 19, 2025\n\n\n\n\nLecture 11\n\n\npandas Basics - Missing Values; Duplicates; Reshaping\n\n\nFebruary 21, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-210-cw-01.html",
    "href": "danl-cw/danl-210-cw-01.html",
    "title": "Classwork 1",
    "section": "",
    "text": "Getting a GitHub account\nStep 1. Create the GitHub account with your Geneseo email.\n\nGo to GitHub.\nClick ‚ÄúSign up for GitHub‚Äù.\n\n\nChoose your GitHub username carefully:\n\nhttps://USERNAME.github.io will be the address for your website.\nByeong-Hak‚Äôs GitHub username is bcdanl, so that Byeong-Hak owns the web address https://bcdanl.github.io.\n\nIt is recommended to have a username with all lower cases.\n\n\n\n\n\nInstalling git if you do not have one.\nStep 2.\n\nCheck whether git is installed in your laptop.\n\n\nFrom the Console Pane in RStudio, click Terminal tab.\n\n\n\n\n\nFrom the Terminal, run the following command to check if your laptop has git installed.\n\ngit --version\n\nIf your computer has git installed, you will see the message below and you do not need to install git:\n\ngit version 2.xx\n\nIf your computer does not have git installed, you will see the message below and you need to install git:\n\n'git' is not recognized as an internal or external command\n\n\nInstall git if you do not have one. Move to the next step if you have git installed in your laptop.\n\n\n\n\nMac\n\nGo to http://git-scm.com/downloads, and download the file.\nClick ‚ÄúmacOS‚Äù, scroll down the webpage, and then click ‚Äúinstaller‚Äù from the Binary installer section.\nRun the downloaded file.\n\n\n\n\nWindows\n\nGo to https://gitforwindows.org, and download the file.\nRun the downloaded file.\n\n\n\n\n\nKeep clicking ‚ÄúNext‚Äù to complete the installation of git.\nAfter the git installation is done, close RStudio and re-open it.\n\n\nHow to open git installation file on Mac?\n\nRun the downloaded file.\nClick Okay\nGo to ‚ÄúSetting‚Äù &gt; ‚ÄúPrivacy and Security‚Äù\nGo to ‚ÄúGeneral‚Äù or scroll down\nClick ‚ÄúOpen Anyway‚Äù\n\n\n\n\n\n\n\n\nSetting up GitHub Credential on your local Git.\nStep 3. In Terminal, run the following commands one by one:\ngit config --global user.email \"YOUR_EMAIL_ADDRESS\"\ngit config --global user.name \"YOUR_USERNAME\"\nFor example, the email address for my GitHub account is bchoe@geneseo.edu, and my GitHub username is bcdanl, so that I ran below:\ngit config --global user.email \"bchoe@geneseo.edu\"\ngit config --global user.name \"bcdanl\"\n\nStep 4. Obtain a personal access token (PAT) from GitHub.\n\nIn RStudio Console, run the followings line by line:\n\ninstall.packages(\"usethis\")\nusethis::create_github_token()\n\nThen, click ‚ÄúGenerate token‚Äù in the pop-upped web browser.\nWe can think of GitHub‚Äôs personal access token as a password that expires. You can decide how long it remains valid. My recommendation is to set its expiration for May 31, 2025, or later.\n\n\n\n\n\nThen, copy the generated PAT, and paste it to your clipboard or R script.\n\n\nStep 5. Set the GitHub credential using the PAT.\n\nIn RStudio Console, run the followings line by line:\n\ninstall.packages(\"gitcreds\")\ngitcreds::gitcreds_set()\n\nYou will be asked to provide your PAT.\nPaste your PAT to the RStudio Console, and then hit Enter.\n\n\n\n\n\n\n\nNote\n\n\n\n\nIt does not harm to create multiple PAT for one GitHub account.\nAfter the PAT expires, you should repeat the following if you want to update your GitHub website:\n\n\nCreate a new PAT:\n\nusethis::create_github_token()\n\nReplace the current PAT with the new PAT:\n\ngitcreds::gitcreds_set()\n\nSelect the option 2: Replace these credentials by typing 2 and hitting Enter on R Console.\n\n\n\n\n\n\nEstablishing the Connection between GitHub repo and your local Git\nStep 6. Login to your GitHib and make the repository.\n\nFrom https://github.com, click the plus [+] icon in the upper right corner and select ‚ÄúNew repository‚Äù.\nName this repo USERNAME.github.io, which will be the domain for your website.\n\n\ne.g., If your GitHub username is abc9, the name of your repo should be abc9.github.io, not abc_9.github.io.\n\n\nThen, copy the web address of your GitHub repo, https://github.com/USERNAME/USERNAME.github.io\n\n\nFor example, the web address for Byeong-Hak‚Äôs GitHub repo is https://github.com/bcdanl/bcdanl.github.io.\n\n\nStep 7. Create a RStudio project with Version Control\n\n\n\n\nClick ‚ÄúProject (None)‚Äù at the top-right corner in RStudio.\nClick ‚ÄúNew Project‚Äù &gt; ‚ÄúVersion Control‚Äù &gt; ‚ÄúGit‚Äù\nPaste the web address of your GitHub repo to the Repository URL menu.\nClick ‚ÄúBrowse‚Äù to select the parent directory for your local project directory (I recommend ‚ÄúDocuments‚Äù folder.)\nClick ‚ÄúCreate‚Äù\n\n\n\n\n\n\n\nNote\n\n\n\nIf Step 7 does not work on your laptop, try below Steps 7-1 and 7-2 instead. If Step 7 DOES work well, skip Steps 7-1 and 7-2.\n\n\nStep 7-1. Use git clone to establish the connection between GitHub repo and your local laptop:\n\nChange directory to ‚ÄúDocuments‚Äù in Terminal using cd command.\n\ncd &lt;pathname of \"Documents\" directory&gt;\n\nHere, you need to know the pathname of ‚ÄúDocuments‚Äù directory.\nFor example, LAPTOP_USERNAME below is not your GitHub username but one for your local laptop.\n\nMac\ncd /Users/LAPTOP_USERNAME/Documents\nWindows\ncd C:/Users/LAPTOP_USERNAME/Documents\n\nUse git clone to creates a local copy of the GitHub Repository.\n\ngit clone &lt;repository-url&gt;\n\nFor example,\n\ngit clone https://github.com/USERNAME/USERNAME.github.io\n\nStep 7-2. Create a RStudio project from Existing Directory\n\nClick ‚ÄúProject (None)‚Äù at the top-right corner in RStudio.\nClick ‚ÄúNew Project‚Äù &gt; ‚ÄúExisting Directory‚Äù\nClick ‚ÄúBrowse‚Äù to select the local copy of the GitHub Repository\nClick ‚ÄúCreate Project‚Äù\n\n\n\n\nDownloading Website Template Files\nStep 8. Download the files of website template:\n\nGo to the following webpage: https://github.com/bcdanl/danl-website-template\nFrom the webpage above, click the green icon &lt; &gt; Code, and then click ‚ÄúDownload Zip‚Äù\nExtract the Zip file you have downloaded\nIf there are the files, .gitignore, .DS_Store, or *.Rproj, in the folder, delete all of them.\nMove all the files that were compressed in the Zip file to your local project directory, USERNAME.github.io.\n\n\nSelect all the files in the danl-website-template folder (Tip: Ctrl + A (Windows) / command + A (Mac) selects all files in a directory).\nThen, Ctrl + C (Windows) / command + C (Mac) to copy them.\nThen, go to your local project directory USERNAME.github.io.\nThen, Ctrl + V (Windows) / command + V (Mac) to paste them to your local project directory USERNAME.github.io.\n\n\nRemove the danl-website-template directory from your local project directory, if you have one.\n\n\nAll the website files should be located at the same level with the R Project file (USERNAME.github.io.Rproj), shown below.\n\n\n\n\n\n\n\nPushing the Website Files to the GitHub repository\n\n\n\nStep 8. Push the files to your GitHub repository\n\nOn Terminal within RStudio, execute the following 3-step git commands, which will stage, commit, and push all the files in the local working directory to your GitHub repository:\n\n\ngit add . adds changes in your local working directory (e.g., edited files, new files, deleted files) to the staging area, which is a temporary area where you can prepare your next commit\n\ngit add .\n\ngit commit -m \"...\" records the changes in the staging area as a new snapshot in the local working directory, along with a message describing the changes.\n\ngit commit -m \"any message to describe the changes\"\n\ngit push uploads the local changes to the online repository in GitHub.\n\ngit push\n\nStep 9. Check whether the files are well uploaded.\n\nGo to the webpages of your GitHub repository and your website:\n\nhttps://github.com/USERNAME/USERNAME.github.io.git\nhttps://USERNAME.github.io\nRefresh the webpages (Ctrl + R for Windows users; cmd + R for Mac users)\n\nAdd a URL for your website (https://YOUR_GITHUB_USERNAME.github.io/) in About section in your GihtHub repository webpage by clicking the setting. Below describes how to do it:\n\n\n\n\nDiscussion\nWelcome to our Classwork 1 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Classwork 1.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Classwork 1 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nAll comments will be stored here.\nLet‚Äôs collaborate and learn from each other!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-cw/danl-210-cw-03.html",
    "href": "danl-cw/danl-210-cw-03.html",
    "title": "Classwork 3",
    "section": "",
    "text": "_quarto.yml configures the website:\n\nIt determines the structure of the website.\n\ne.g., Navigation bar, themes, HTML options, etc.\n\nIf _quarto.yml is edited, use quarto render to render all qmd and ipynb files.\n\nindex.qmd renders index.html, the front page of the website.\n\nDo not create Quarto files something like index2.qmd within the working directory.\n\nblog-listing.qmd configures the blog listing page.\nposts directory includes sub-directories of blog posts.\nimg directory can be used to store picture files.\n\n\n\n\nA file in the working directory can have its own web address.\n\nFor example, if you have resume-example.pdf in your working directory, it has the web address, https://USERNAME.github.io/resume-example.pdf.\n\nWhen naming a file in the website, do not have any space in a file name!\nBe systematic when naming a series of files in the website.\n\nE.g., danl-210-cw-01.ipynb, danl-210-cw-02.ipynb, danl-210-cw-03.ipynb.\n\n\n\n\n\n\n\nRules\n\nOne blog post corresponds to:\n\n\nOne sub-directory in the posts directory.\nOne *.ipynb (or *.qmd) file.\n\n\nPut all files for one blog post (e.g., *.ipynb (or *.qmd), *.png) in one corresponding sub-directory in the posts directory.\nWhen inserting an image file to a blog post, use a relative path, i.e., a file name of the image file.\n\n\n\n\n\n\n\nDecorate your website:\n\n\nReplace YOUR NAME with your name in _quarto.yml and index.qmd.\nDescribe yourself in index.qmd.\nAdd the picture (png) file of your profile photo to img directory. Then correct img/profile.png in index.qmd accordingly.\nCorrect links for your resum√©, linkedin, email, and social media.\n\n\nAdd a menu of ‚ÄúProject‚Äù to the navigation bar using danl_proj_nba.ipynb.\nAdd a drop-down menu of ‚ÄúPython Data Analysis‚Äù to the navigation bar.\n\n\nUnder the menu of ‚ÄúPython Data Analysis‚Äù, add links for the following webpage:\n\nPandas Basics using pandas_basic.ipynb\nSeaborn Basics using seaborn_basic.ipynb\n\n\n\nUse the 3-step git commands (git add, git commit, and git push) to update your website.\n\n\n\n\n\n\nQuarto - Creating a Website\nQuarto - HTML Basics\nQuarto - HTML Code Blocks\nQuarto - HTML Theming\nQuarto - Creating a Blog"
  },
  {
    "objectID": "danl-cw/danl-210-cw-03.html#website-files",
    "href": "danl-cw/danl-210-cw-03.html#website-files",
    "title": "Classwork 3",
    "section": "",
    "text": "_quarto.yml configures the website:\n\nIt determines the structure of the website.\n\ne.g., Navigation bar, themes, HTML options, etc.\n\nIf _quarto.yml is edited, use quarto render to render all qmd and ipynb files.\n\nindex.qmd renders index.html, the front page of the website.\n\nDo not create Quarto files something like index2.qmd within the working directory.\n\nblog-listing.qmd configures the blog listing page.\nposts directory includes sub-directories of blog posts.\nimg directory can be used to store picture files.\n\n\n\n\nA file in the working directory can have its own web address.\n\nFor example, if you have resume-example.pdf in your working directory, it has the web address, https://USERNAME.github.io/resume-example.pdf.\n\nWhen naming a file in the website, do not have any space in a file name!\nBe systematic when naming a series of files in the website.\n\nE.g., danl-210-cw-01.ipynb, danl-210-cw-02.ipynb, danl-210-cw-03.ipynb."
  },
  {
    "objectID": "danl-cw/danl-210-cw-03.html#blogging",
    "href": "danl-cw/danl-210-cw-03.html#blogging",
    "title": "Classwork 3",
    "section": "",
    "text": "Rules\n\nOne blog post corresponds to:\n\n\nOne sub-directory in the posts directory.\nOne *.ipynb (or *.qmd) file.\n\n\nPut all files for one blog post (e.g., *.ipynb (or *.qmd), *.png) in one corresponding sub-directory in the posts directory.\nWhen inserting an image file to a blog post, use a relative path, i.e., a file name of the image file."
  },
  {
    "objectID": "danl-cw/danl-210-cw-03.html#practice-problems",
    "href": "danl-cw/danl-210-cw-03.html#practice-problems",
    "title": "Classwork 3",
    "section": "",
    "text": "Decorate your website:\n\n\nReplace YOUR NAME with your name in _quarto.yml and index.qmd.\nDescribe yourself in index.qmd.\nAdd the picture (png) file of your profile photo to img directory. Then correct img/profile.png in index.qmd accordingly.\nCorrect links for your resum√©, linkedin, email, and social media.\n\n\nAdd a menu of ‚ÄúProject‚Äù to the navigation bar using danl_proj_nba.ipynb.\nAdd a drop-down menu of ‚ÄúPython Data Analysis‚Äù to the navigation bar.\n\n\nUnder the menu of ‚ÄúPython Data Analysis‚Äù, add links for the following webpage:\n\nPandas Basics using pandas_basic.ipynb\nSeaborn Basics using seaborn_basic.ipynb\n\n\n\nUse the 3-step git commands (git add, git commit, and git push) to update your website."
  },
  {
    "objectID": "danl-cw/danl-210-cw-03.html#references",
    "href": "danl-cw/danl-210-cw-03.html#references",
    "title": "Classwork 3",
    "section": "",
    "text": "Quarto - Creating a Website\nQuarto - HTML Basics\nQuarto - HTML Code Blocks\nQuarto - HTML Theming\nQuarto - Creating a Blog"
  },
  {
    "objectID": "listing-danl-210-rw.html",
    "href": "listing-danl-210-rw.html",
    "title": "DANL 210 - Project",
    "section": "",
    "text": "Title\n\n\nDate\n\n\n\n\n\n\nUnifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis\n\n\nJanuary 22, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html",
    "href": "posts/py-basic/blog-python-basics.html",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\n\nCode\nprint('Hello, World!')\n\n\n\n\n\nIn Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\n\nCode\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n\n10.5\n\n\n\n\n\nPython supports the usual logical conditions from mathematics:\n\n\nCode\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\n\nThese conditions can be used in several ways, most commonly in ‚Äòif statements‚Äô and loops.\n\n\nCode\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')\n\n\n\n\n\nA function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n\nCode\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()\n\n\n\n\n\nA list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n\nCode\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#what-is-python",
    "href": "posts/py-basic/blog-python-basics.html#what-is-python",
    "title": "Python Basics",
    "section": "",
    "text": "Python is a high-level, interpreted programming language. This is a simple Python code:\n\n\nCode\nprint('Hello, World!')"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#variables-and-data-types",
    "href": "posts/py-basic/blog-python-basics.html#variables-and-data-types",
    "title": "Python Basics",
    "section": "",
    "text": "In Python, variables can store data of different types without explicitly declaring the type.\nFor example:\n\n\nCode\ninteger_variable = 10\nstring_variable = 'Hello'\nfloat_variable = 10.5\n\nfloat_variable\n\n\n10.5"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#control-structures",
    "href": "posts/py-basic/blog-python-basics.html#control-structures",
    "title": "Python Basics",
    "section": "",
    "text": "Python supports the usual logical conditions from mathematics:\n\n\nCode\n# Equals: a == b\n# Not Equals: a != b\n# Less than: a &lt; b\n# Less than or equal to: a &lt;= b\n# Greater than: a &gt; b\n# Greater than or equal to: a &gt;= b\n\n\nThese conditions can be used in several ways, most commonly in ‚Äòif statements‚Äô and loops.\n\n\nCode\n# if statement:\nif 5 &gt; 2:\n    print('Five is greater than two!')"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#functions",
    "href": "posts/py-basic/blog-python-basics.html#functions",
    "title": "Python Basics",
    "section": "",
    "text": "A function is a block of code which only runs when it is called.\nYou can pass data, known as parameters, into a function.\nA function can return data as a result.\n\n\nCode\n# Defining a function:\ndef my_function():\n    print('Hello from a function')\n\n# Calling a function:\nmy_function()"
  },
  {
    "objectID": "posts/py-basic/blog-python-basics.html#lists-and-dictionaries",
    "href": "posts/py-basic/blog-python-basics.html#lists-and-dictionaries",
    "title": "Python Basics",
    "section": "",
    "text": "A list is a collection which is ordered and changeable.\nA dictionary is a collection which is unordered, changeable and indexed.\n\n\nCode\n# List example:\nmy_list = ['apple', 'banana', 'cherry']\n\n# Dictionary example:\nmy_dict = {'name': 'John', 'age': 36}"
  },
  {
    "objectID": "posts/nba/nba.html#salary-distribution-among-teams",
    "href": "posts/nba/nba.html#salary-distribution-among-teams",
    "title": "NBA",
    "section": "Salary Distribution Among Teams",
    "text": "Salary Distribution Among Teams\nLet‚Äôs start with the salary distribution among teams using seaborn for visualization. ‚Äã‚Äã\n\n\nCode\n\n# Handle missing values in 'Salary' by replacing them with the median salary\nmedian_salary = nba['Salary'].median()\nnba['Salary'].fillna(median_salary, inplace=True)\n\n\n\n\nCode\n# Set the aesthetic style of the plots\nsns.set_style(\"whitegrid\")\n\n# Calculate total salary by team\nteam_salary = (\n    nba\n    .groupby('Team')['Salary']\n    .sum()\n    .reset_index()\n    .sort_values(by='Salary', ascending=False)\n)\n\n# Plot total salary by team\nplt.figure(figsize=(10, 8))\nsns.barplot(data = team_salary,\n            x = 'Salary', y = 'Team',\n            palette = 'coolwarm')\nplt.title('Total Salary Distribution Among NBA Teams')\nplt.xlabel('Total Salary')\nplt.ylabel('Team')\nplt.xticks(rotation=45)\nplt.show()\n\n\n\n\n\nThe visualization above displays the total salary distribution among NBA teams, with teams sorted by their total salary expenditure. This bar plot reveals which teams are the biggest spenders on player salaries and which are more conservative. The color gradient provides a visual cue to easily distinguish between the higher and lower spending teams. Portland Trail Blazers spent most in their players‚Äô salary, followed by Golden State Warriors and Philadelphia 76ers."
  },
  {
    "objectID": "posts/nba/nba.html#player-age-distribution",
    "href": "posts/nba/nba.html#player-age-distribution",
    "title": "NBA",
    "section": "Player Age Distribution",
    "text": "Player Age Distribution\nNext, let‚Äôs explore the Player Age Distribution across the NBA. We‚Äôll create a histogram to visualize how player ages are distributed, which will help us understand if the league trends younger, older, or has a balanced age mix. ‚Äã‚Äã\n\n\nCode\n# Convert 'Birthday' column to datetime format\nfrom dateutil import parser\nnba['Birthday'] = nba['Birthday'].apply(lambda x: parser.parse(x))\n\n# Now, let's calculate the age of each player\nnba['Age'] = (datetime.now() - nba['Birthday']).dt.days // 365\n\n# Plot the age distribution of NBA players\nplt.figure(figsize=(10, 6))\nsns.histplot(nba['Age'],\n             bins = 15,\n             kde = True,\n             color = 'skyblue')\nplt.title('Age Distribution of NBA Players')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()\n\n\n\n\n\n\nThe histogram above shows the age distribution of NBA players, with a kernel density estimate (KDE) overlay to indicate the distribution shape. The majority of players fall within a certain age range from 25 to 35, illustrating the league‚Äôs age dynamics. The plot helps identify the common ages for NBA players and whether there are significant numbers of very young or older players."
  },
  {
    "objectID": "posts/nba/nba.html#position-wise-salary-insights",
    "href": "posts/nba/nba.html#position-wise-salary-insights",
    "title": "NBA",
    "section": "Position-wise Salary Insights",
    "text": "Position-wise Salary Insights\nMoving on to Position-wise Salary Insights, we‚Äôll examine how average salaries differ across player positions. This analysis could reveal which positions are typically higher-paid, potentially reflecting their value on the basketball court. Let‚Äôs create a box plot to visualize the salary distribution for each position. ‚Äã‚Äã\n\n\nCode\n# Plot salary distribution by player position\nplt.figure(figsize=(10, 6))\nsns.boxplot(data = nba,\n            x = 'Position', y = 'Salary',\n            palette = 'Set2')\nplt.title('Salary Distribution by Position')\nplt.xlabel('Position')\nplt.ylabel('Salary')\nplt.show()\n\n\n\n\n\nThe box plot above illustrates the salary distribution by player position, showcasing the variation in salaries among different positions within the NBA. This visualization helps us understand which positions tend to have higher median salaries and the spread of salaries within each position, including outliers that represent exceptionally high or low salaries. While the positions of C and PG have the widest interquantiles of salaries, the positions of FC, F, G, and GF have the narrowest interquantiles of them."
  },
  {
    "objectID": "posts/nba/nba.html#top-10-highest-paid-players",
    "href": "posts/nba/nba.html#top-10-highest-paid-players",
    "title": "NBA",
    "section": "Top 10 Highest Paid Players",
    "text": "Top 10 Highest Paid Players\nLastly, we‚Äôll identify the Top 10 Highest Paid Players in the NBA. This analysis highlights the star earners of the league, providing insights into which players command the highest salaries and potentially why. Let‚Äôs extract and visualize this information. ‚Äã‚Äã\n\n\nCode\n# Identify the top 10 highest paid players\ntop_10_salaries = nba.sort_values(by='Salary', ascending=False).head(10)\n\n# Plot the top 10 highest paid players\nplt.figure(figsize=(12, 8))\nsns.barplot(data = top_10_salaries,\n            x = 'Salary', y = 'Name',\n            palette = 'viridis')\nplt.title('Top 10 Highest Paid NBA Players')\nplt.xlabel('Salary')\nplt.ylabel('Player')\nplt.show()\n\n\n\n\n\nThe bar chart above reveals the top 10 highest-paid NBA players, showcasing those who stand at the pinnacle of the league in terms of salary. Stephen Curry is the highest-paid NBA player, followed by Russel Westbrook and Chris Paul. This visualization not only highlights the star players who command the highest salaries but also may reflect their marketability, performance, and contribution to their respective teams."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#instructor-1",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#instructor-1",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nCurrent Appointment & Education\n\nName: Byeong-Hak Choe.\nAssistant Professor of Data Analytics and Economics, School of Business at SUNY Geneseo.\nPh.D.¬†in Economics from University of Wyoming.\nM.S. in Economics from Arizona State University.\nM.A.¬†in Economics from SUNY Stony Brook.\nB.A. in Economics & B.S. in Applied Mathematics from Hanyang University at Ansan, South Korea.\n\nMinor in Business Administration.\nConcentration in Finance."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#instructor-2",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#instructor-2",
    "title": "Lecture 1",
    "section": "Instructor",
    "text": "Instructor\nEconomics and Data Science\n\nChoe, B.H., Newbold, S. and James, A., ‚ÄúEstimating the Value of Statistical Life through Big Data‚Äù\n\nQuestion: How much is the society willing to pay to reduce the likelihood of fatality?\n\nChoe, B.H., ‚ÄúSocial Media Campaigns, Lobbying and Legislation: Evidence from #climatechange and Energy Lobbies.‚Äù\n\nQuestion: To what extent do social media campaigns compete with fossil fuel lobbying on climate change legislation?\n\nChoe, B.H. and Ore-Monago, T., 2024. ‚ÄúGovernance and Climate Finance in the Developing World‚Äù\n\nQuestion: In what ways and through what forms does poor governance act as a significant barrier to reducing greenhouse gas emissions in developing countries?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-1",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-1",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nEmail, Class & Office Hours\n\nEmail: bchoe@geneseo.edu\nClass Homepage:\n\nhttps://brightspace.geneseo.edu/\nhttp://bcdanl.github.io/210/\n\nOffice: South Hall 227B\nOffice Hours:\n\nMondays 5:00 P.M. ‚Äì 6:30 P.M.\n\nWednesdays 5:00 P.M. ‚Äì 6:30 P.M."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-2",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-2",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Description\n\nThis course is designed to provide a comprehensive overview of data handling techniques, focusing on practical application through case studies.\nKey topics include:\n\ndata loading, cleaning, transformation, merging, and reshaping;\ntechniques for slicing, dicing, and summarizing datasets;\ndata collection via web scraping and APIs.\n\nThese areas will be explored through detailed, real-world examples to address common data analysis challenges.\nThroughout the course, students will gain hands-on experience with Python and its data analysis libraries, along with practical applications of git and GitHub."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-3",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-3",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nRequired Materials\n\nPython for Data Analysis (3rd Edition) by Wes McKinney\n\nA free online version of this book is available."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-4",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-4",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nReference Materials\n\nGuide for Quarto\nPython Programming for Data Science by Tomas Beuzen\nCoding for Economists by Arthur Turrell\nPython for Econometrics in Economics by Fabian H. C. Raters\nQuantEcon DataScience - Python Fundamentals by Chase Coleman, Spencer Lyon, and Jesse Perla\nQuantEcon DataScience - pandas by Chase Coleman, Spencer Lyon, and Jesse Perla"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-5",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-5",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Requirements\n\nLaptop: You should bring your own laptop (Mac or Windows) to the classroom.\n\nThe minimum specification for your laptop in this course is 2+ core CPU, 4+ GB RAM, and 500+ GB disk storage.\n\nHomework: There will be six homework assignments.\nProject: There will be one project on a personal website.\nExams: There will be two Midterm Exams and one Final Exam.\n\nThe final exam is comprehensive.\n\nDiscussions: You are encouraged to participate in GitHub-based online discussions and class discussion, and office hours.\n\nCheckout the netiquette policy in the syllabus."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-6",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-6",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nPersonal Website\n\nYou will create your own website using Quarto, R Studio, and Git.\nYou will publish your homework assignments and team project on your website.\nYour website will be hosted in GitHub.\nThe basics in Markdown will be discussed.\nReferences:\n\nQuarto Guide"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-7",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-7",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nWhy Personal Website?\n\n\nHere are the example websites:\n\nByeong-Hak‚Äôs Website\nDANL Website Template\n\nProfessional Showcase: Display skills and projects\nVisibility and Networking: Increase online presence\nContent Sharing and Engagement: Publish articles, insights\nJob Opportunities: Attract potential employers and clients\nLong-term Asset: A growing repository of your career journey"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-8",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-8",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nTeam Project\n\nTeam formation is scheduled for late March.\n\nEach team must have one to two students.\n\nThe project report should include data collection and exploratory data analysis using summary statistics, visual representations, and data wrangling.\nThe document for the team project must be published in each member‚Äôs website.\nAny changes to team composition require approval from Byeong-Hak Choe."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-9",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-9",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nClass Schedule and Exams\n\nThere will be tentatively 42 class sessions.\nThe Midterm Exam I is scheduled on February 28, 2025, Friday, during the class time.\nThe Midterm Exam II is scheduled on April 9, 2025, Wednesday, during the class time.\nThe Final Exam is scheduled on May 14, Wednesday, 8:30 A.M.‚Äì10:30 A.M.\nNo class on\n\nMarch 17, 19, and 21 (Spring Break)\nApril 23 (GREAT Day)\n\nThe due for the team project is May 16, 2025, Friday, 11:59 P.M., Eastern Time"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-10",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-10",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents\n\n\n\n\n\n\n\n\nThe first part of the course covers Python basics and pandas basics."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-11",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-11",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents\n\n\n\n\n\n\n\n\nThe second part of the course covers data collection."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-12",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-12",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCourse Contents\n\n\n\n\n\n\n\n\nThe third part of the course covers advanced pandas."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-13",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-13",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n(\\text{Total Percentage Grade}) =&\\quad\\;\\, 0.05\\times(\\text{Attendance Score})\\notag\\\\\n&\\,+\\, 0.05\\times(\\text{Participation Score})\\notag\\\\\n&\\,+\\, 0.15\\times(\\text{Project and Website Score})\\notag\\\\\n&\\,+\\, 0.25\\times(\\text{Total Homework Score})\\notag\\\\\n&\\,+\\, 0.50\\times(\\text{Total Exam Score}).\\notag\n\\end{align}\n\\]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-14",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-14",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\nYou are allowed up to 5 absences without penalty.\n\nSend me an email if you have standard excused reasons (illness, family emergency, transportation problems, etc.).\n\nFor each absence beyond the initial five, there will be a deduction of 1% from the Total Percentage Grade.\nParticipation will be evaluated by quantity and quality of GitHub-based online discussions and in-person discussion.\nThe single lowest homework score will be dropped when calculating the total homework score."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-15",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-15",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n&(\\text{Midterm Exam Score}) \\\\\n=\\, &\\text{max}\\,\\left\\{0.50\\times(\\text{Midterm Exam I Score}) \\,+\\, 0.50\\times(\\text{Midterm Exam II Score})\\right.,\\notag\\\\\n&\\qquad\\;\\,\\left.0.25\\times(\\text{Midterm Exam I Score}) \\,+\\, 0.75\\times(\\text{Midterm Exam II Score})\\right\\}.\\notag\n\\end{align}\n\\]\n\nThe Midterm Exam Score is the maximum between\n\nthe simple average of the Midterm Exam I score and the Midterm Exam II Score and\nthe weighted average of them with one-fourth weight on the Midterm Exam I Score and three-third weight on the Midterm Exam II Score."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-16",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-16",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nGrading\n\\[\n\\begin{align}\n&(\\text{Total Exam Score}) \\\\\n=\\, &\\text{max}\\,\\left\\{0.50\\times(\\text{Midterm Exam Score}) \\,+\\, 0.50\\times(\\text{Final Exam Score})\\right.,\\notag\\\\\n&\\qquad\\;\\,\\left.0.25\\times(\\text{Midterm Exam Score}) \\,+\\, 0.75\\times(\\text{Final Exam Score})\\right\\}.\\notag\n\\end{align}\n\\]\n\nThe Total Exam Score is the maximum between\n\nthe simple average of the Midterm Exam Score and the Final Exam Score and\nthe weighted average of them with one-fourth weight on the Midterm Exam Score and three-third weight on the Final Exam Score."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-17",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-17",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nMake-up Policy\n\nMake-up exams will not be given unless you have either a medically verified excuse or an absence excused by the University.\nIf you cannot take exams because of religious obligations, notify me by email at least two weeks in advance so that an alternative exam time may be set.\nA missed exam without an excused absence earns a grade of zero.\nLate submissions for homework assignment will be accepted with a penalty.\nA zero will be recorded for a missed assignment."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-18",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-18",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAcademic Integrity and Plagiarism\n\nAll homework assignments and exams must be the original work by you.\nExamples of academic dishonesty include:\n\nrepresenting the work, thoughts, and ideas of another person as your own\nallowing others to represent your work, thoughts, or ideas as theirs, and\nbeing complicit in academic dishonesty by suspecting or knowing of it and not taking action.\n\nGeneseo‚Äôs Library offers frequent workshops to help you understand how to paraphrase, quote, and cite outside sources properly.\n\nSee https://www.geneseo.edu/library/library-workshops."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-19",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-19",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nAccessibility\n\nThe Office of Accessibility will coordinate reasonable accommodations for persons with physical, emotional, or cognitive disabilities to ensure equal access to academic programs, activities, and services at Geneseo.\nPlease contact me and the Office of Accessibility Services for questions related to access and accommodations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-20",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-20",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nWell-being\n\nYou are strongly encouraged to communicate your needs to faculty and staff and seek support if you are experiencing unmanageable stress or are having difficulties with daily functioning.\nLiz Felski, the School of Business Student Advocate (felski@geneseo.edu, South Hall 303), or the Dean of Students (585-245-5706) can assist and provide direction to appropriate campus resources.\nFor more information, see https://www.geneseo.edu/dean_students."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-21",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#syllabus-21",
    "title": "Lecture 1",
    "section": "Syllabus",
    "text": "Syllabus\nCareer Design\n\nTo get information about career development, you can visit the Career Development Events Calendar (https://www.geneseo.edu/career_development/events/calendar).\nYou can stop by South 112 to get assistance in completing your Handshake Profile https://app.joinhandshake.com/login.\n\nHandshake is ranked #1 by students as the best place to find full-time jobs.\n50% of the 2018-2020 graduates received a job or internship offer on Handshake.\nHandshake is trusted by all 500 of the Fortune 500."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#why-data-analytics",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#why-data-analytics",
    "title": "Lecture 1",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nFill in the gaps left by traditional business and economics classes.\n\nPractical skills that will benefit your future career.\nNeglected skills like how to actually find datasets in the wild and clean them.\n\nData analytics skills are largely distinct from (and complementary to) the core quantitative works familiar to business undergrads.\n\nData visualization, cleaning and wrangling; databases; machine learning; etc.\n\nIn short, we will cover things that I wish someone had taught me when I was undergraduate."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#you-at-the-end-of-this-course",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#you-at-the-end-of-this-course",
    "title": "Lecture 1",
    "section": "You, at the end of this course",
    "text": "You, at the end of this course"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#why-data-analytics-1",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#why-data-analytics-1",
    "title": "Lecture 1",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nData analysts use analytical tools and techniques to extract meaningful insights from data.\n\nSkills in data analytics are also useful for business analysts or market analysts.\n\nBreau of Labor Statistics forecasts that the projected growth rate of the employment in the industry related to data analytics from 2021 to 2031 is 36%.\n\nThe average growth rate for all occupations is 5%."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#the-state-of-the-art",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#the-state-of-the-art",
    "title": "Lecture 1",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\n\nData Science and Big Data Trend\nFrom 2008 to 2023\n\n\nProgrammers in 2025"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#the-state-of-the-art-1",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#the-state-of-the-art-1",
    "title": "Lecture 1",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\nUsers around the world have explored how to best utilize GPT for writing essays and programming codes.\n\n\n\n\nIs AI a threat to data analytics?\n\nFundamental understanding of the subject matter is still crucial for effectively utilizing AI‚Äôs capabilities.\n\n\n\n\n\nIf you use Generative AI such as ChatGPT, please try to understand what ChatGPT gives you.\n\nCopying and pasting it without any understanding harms your learning opportunity."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-git",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-git",
    "title": "Lecture 1",
    "section": "What is Git?",
    "text": "What is Git?\n\n\n\n\n\\(\\quad\\)\n\nGit is the most popular version control tool for any software development.\n\nIt tracks changes in a series of snapshots of the project, allowing developers to revert to previous versions, compare changes, and merge different versions.\nIt is the industry standard and ubiquitous for coding collaboration."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-github",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-github",
    "title": "Lecture 1",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\nGitHub is a web-based hosting platform for Git repositories to store, manage, and share code.\nOut class website is hosted on a GitHub repository.\nCourse contents will be posted not only in Brightspace but also in our GitHub repositories (‚Äúrepos‚Äù) and websites.\nGithub is useful for many reasons, but the main reason is how user friendly it makes uploading and sharing code."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-github-1",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-github-1",
    "title": "Lecture 1",
    "section": "What is GitHub?",
    "text": "What is GitHub?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-rstudio",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-rstudio",
    "title": "Lecture 1",
    "section": "What is RStudio?",
    "text": "What is RStudio?\n\nRStudio is an integrated development environment (IDE) mainly for R programming.\n\nAn IDE is a software application that provides comprehensive facilities (e.g., text code editor, graphical user interface (GUI)) to computer programmers for software development.\n\nRStudio is a user-friendly interface that makes using R easier and more interactive.\n\nIt provides a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging, and workspace management."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-python",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-python",
    "title": "Lecture 1",
    "section": "What is Python?",
    "text": "What is Python?\n\nPython is a versatile programming language known for its simplicity and readability.\nPython has become a dominant tool in various fields including data analysis, machine learning, and web development.\n\nIt is widely used among developers, data scientists, and researchers for building applications and performing data-driven tasks.\nPython is open source and has a vast ecosystem of libraries and frameworks."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-jupyter",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#what-is-jupyter",
    "title": "Lecture 1",
    "section": "What is Jupyter?",
    "text": "What is Jupyter?\n\nJupyter is an open-source IDE primarily for Python, though it supports many other languages.\n\nJupyter provides a notebook interface that allows users to write and execute code in a more interactive and visual format.\n\nJupyter Notebook (*.ipynb) is a user-friendly environment that enhances coding, data analysis, and visualization.\n\nIt offers a web-based interface that combines live code, equations, visualizations, and narrative text.\nJupyter Notebook is widely used for data science, machine learning, and research, enabling easy sharing and collaboration.\n\nWe will use a free cloud version of Jupyter, which is Google Colab."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-1",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-1",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nAnaconda\n\nTo install Anaconda, go to the following download page:\n\nhttps://www.anaconda.com/products/distribution.\nClick the ‚ÄúDownload‚Äù button."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-2",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-2",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR programming\n\nThe R language is available as a free download from the R Project website at:\n\nWindows: https://cran.r-project.org/bin/windows/base/\nMac: https://cran.r-project.org/bin/macosx/\nDownload the file of R that corresponds to your Mac OS (Big Sur, Apple silicon arm64, High Sierra, El Capitan, Mavericks, etc.)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-3",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-3",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR Studio\n\n\nThe RStudio Desktop is available as a free download from the following webpage:\n\nhttps://www.rstudio.com/products/rstudio/download/#download\n\n\n\n\n\n\nFor Mac users, try the following steps:\n\nRun RStudio-*.dmg file.\nFrom the Pop-up menu, click the RStudio icon.\nWhile clicking the RStudio icon, drag it to the Applications directory."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-4",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-4",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\nScript Pane is where you write R commands in a script file that you can save.\n\n\n\nAn R script is simply a text file containing R commands.\nRStudio will color-code different elements of your code to make it easier to read.\n\n\n\n\n\n\n\n\nTo open an R script,\n\nFile \\(&gt;\\) New File \\(&gt;\\) R Script\n\n\n\n\n\n\nTo save the R script,\n\nFile \\(&gt;\\) Save"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-5",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-5",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\nConsole Pane allows you to interact directly with the R interpreter and type commands where R will immediately execute them."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-6",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-6",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\nEnvironment Pane is where you can see the values of variables, data frames, and other objects that are currently stored in memory.\nType below in the Console Pane, and then hit Enter:\n\na &lt;- 1"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-7",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-7",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\nPlots Pane contains any graphics that you generate from your R code."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-8",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-8",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR Packages and tidyverse\n\nR packages are collections of R functions, compiled code, and data that are combined in a structured format.\n\n\n\nThe tidyverse is a collection of R packages designed for data science that share an underlying design philosophy, grammar, and data structures.\n\nThe tidyverse packages work harmoniously together to make data manipulation, exploration, and visualization more.\nWe will use several R packages from tidyverse throughout the course. (e.g., ggplot2, dplyr, tidyr)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-9",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-9",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nInstalling R packages with install.packages(\"packageName\")\n\nR packages can be easily installed from within R using functions install.packages(\"packageName\").\n\nTo install the R package tidyverse, type and run the following from R console:\n\n\n\ninstall.packages(\"tidyverse\")\n\nWhile running the above codes, you may encounter the question below from the R Console:\n\n\n\n\nMac: ‚ÄúDo you want to install from sources the packages which need compilation?‚Äù from Console Pane.\n\n\n\nWindows: ‚ÄúWould you like to use a personal library instead?‚Äù from Pop-up message.\n\n\n\n\nType no in the R Console, and then hit Enter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-10",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-10",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nLoading R packages with library(packageName)\n\nOnce installed, a package is loaded into an R session using library(packageName) so that its functions and data can be used.\n\nTo load the R package tidyverse, type and run the following command from a R script:\n\n\nlibrary(tidyverse)\ndf_mpg &lt;- mpg\n\n\nmpg is the data.frame provided by the R package ggplot2, one of the R pakcages in tidyverse."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-11",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#installing-the-tools-11",
    "title": "Lecture 1",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Options Setting\n\n\n\n\n\nThis option menu is found by menus as follows:\n\nTools \\(&gt;\\) Global Options\n\nCheck the boxes as in the left.\nChoose the option Never for  Save workspace to .RData on exit:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#building-a-personal-website-on-github",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#building-a-personal-website-on-github",
    "title": "Lecture 1",
    "section": "Building a Personal Website on GitHub",
    "text": "Building a Personal Website on GitHub\n\nFollow steps described in Classwork 1."
  },
  {
    "objectID": "danl-lec/danl-210-lec-01-2025-0122.html#lets-practice-markdown",
    "href": "danl-lec/danl-210-lec-01-2025-0122.html#lets-practice-markdown",
    "title": "Lecture 1",
    "section": "Let‚Äôs Practice Markdown!",
    "text": "Let‚Äôs Practice Markdown!\n\nJupyter Notebook, Quarto, and GitHub-based Discussion Boards use markdown as its underlying document syntax.\nLet‚Äôs do Classwork 2."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-1",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-1",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nVariables Are Names, Not Places\n\n\n\n\nA value is datum (literal) such as a number or text.\nThere are different types of values:\n\n352.3 is known as a float or double;\n22 is an integer;\n‚ÄúHello World!‚Äù is a string."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-2",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-2",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nValues, Variables, and Types\na = 10\nprint(a)\n\n\n\n\n\n\n\nA variable is a name that refers to a value.\n\nWe can think of a variable as a box that has a value, or multiple values, packed inside it.\n\nA variable is just a name!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-3",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-3",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nValues, Variables, and Types\n\n\nSometimes you will hear variables referred to as objects.\nEverything that is not a literal value, such as 10, is an object."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-4",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-4",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#variable-in-data.frame",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#variable-in-data.frame",
    "title": "Lecture 4",
    "section": "Variable in data.frame",
    "text": "Variable in data.frame\n\n\n\n\n\n\nDefinition: A data.frame is a table-like data structure used for storing data in a tabular format with rows and columns.\nStructure: Consists of:\n\nVariables (Columns)\nObservations (Rows)\nValues (Cells): Individual data points within each cell of the data.frame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-5",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-5",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nAssignment ( = )\n# Here we assign the integer value 5 to the variable x.\nx = 5   \n\n# Now we can use the variable x in the next line.\ny = x + 12  \ny\n\nIn Python, we use = to assign a value to a variable.\nIn math, = means equality of both sides.\nIn programs, = means assignment: assign the value on the right side to the variable on the left side."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-6",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-6",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nCode and comment style\n\nThe two main principles for coding and managing data are:\n\nMake things easier for your future self.\nDon‚Äôt trust your future self.\n\nThe # mark is Google Colab‚Äôs comment character.\n\nThe # character has many names: hash, sharp, pound, or octothorpe.\n# indicates that the rest of the line is to be ignored.\nWrite comments before the line that you want the comment to apply to.\n\nConsider adding more comments on code cells and their results using text cells."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-7",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-7",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nAssignment\n\nIn programming code, everything on the right side needs to have a value.\n\nThe right side can be a literal value, or a variable that has already been assigned a value, or a combination.\n\nWhen Python reads y = x + 12, it does the following:\n\nSees the = in the middle.\nKnows that this is an assignment.\nCalculates the right side (gets the value of the object referred to by x and adds it to 12).\nAssigns the result to the left-side variable, y."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-8",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-8",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nVariables Are Names, Not Places\nlist_example = [10, 1.23, \"like this\", True, None]\nprint(list_example)\ntype(list_example)\n\nThe most basic built-in data types that we‚Äôll need to know about are:\n\nintegers 10\nfloats 1.23\nstrings \"like this\"\nbooleans True\nnothing None\n\nPython also has a built-in type of data container called a list (e.g., [10, 15, 20]) that can contain anything, even different types"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-9",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-9",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nTypes\n\n\n\n\nThe second column (Type) contains the Python name of that type.\nThe third column (Mutable?) indicates whether the value can be changed after creation."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-10",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-10",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nBrackets\n\n\nThere are several kinds of brackets in Python, including [], {}, and ().\n\n\n[]{}()\n\n\nvector = ['a', 'b']\nvector[0]\n\n[] is used to denote a list or to signify accessing a position using an index.\n\n\n\n{'a', 'b'}  # set\n{'first_letter': 'a', 'second_letter': 'b'}  # dictionary\n\n{} is used to denote a set or a dictionary (with key-value pairs).\n\n\n\nnum_tup = (1, 2, 3)\nsum(num_tup)\n\n() is used to denote\n\na tuple, or\nthe arguments to a function, e.g., function(x) where x is the input passed to the function."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-11",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-11",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nOperators\nstring_one = \"This is an example \"\nstring_two = \"of string concatenation\"\nstring_full = string_one + string_two\nprint(string_full)\n\nAll of the basic operators we see in mathematics are available to use:\n\n\n\n\n+ for addition\n- for subtraction\n\n\n\n* for multiplication\n** for powers\n\n\n\n/ for division\n// for integer division\n\n\n\n\nThese work as you‚Äôd expect on numbers.\nThese operators are sometimes defined for other built-in data types too.\n\nWe can ‚Äòsum‚Äô strings (which really concatenates them)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-12",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-12",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nOperators\n\n\nlist_one = [\"apples\", \"oranges\"]\nlist_two = [\"pears\", \"satsumas\"]\nlist_full = list_one + list_two\nprint(list_full)\n\nIt works for lists too:\n\n\nstring = \"apples, \"\nprint(string * 3)\n\nWe can multiply strings!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-13",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-13",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nOperators\nQ. Classwork 4.1\nUsing Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-14",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-14",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nCasting Variables\n\n\norig_number = 4.39898498\ntype(orig_number)\n\nmod_number = int(orig_number)\nmod_number\ntype(mod_number)\n\n\n\nSometimes we need to explicitly cast a value from one type to another.\n\nWe can do this using built-in functions like str(), int(), and float().\nIf we try these, Python will do its best to interpret the input and convert it to the output type we‚Äôd like and, if they can‚Äôt, the code will throw a great big error."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-15",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-15",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nTuples and (im)mutability\n\n\nA tuple is an object that is defined by parentheses and entries that are separated by commas, for example (15, 20, 32). (They are of type tuple.)\nTuples are immutable, while lists are mutable.\nImmutable objects, such as tuples and strings, can‚Äôt have their elements changed, appended, extended, or removed.\n\nMutable objects, such as lists, can do all of these things.\n\nIn everyday programming, we use lists and dictionaries more than tuples."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-16",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-16",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nDictionaries\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"New York\": 36, \"Seoul\": 29}\n\ncities_to_temps.keys()\ncities_to_temps.values()\ncities_to_temps.items()\n\nAnother built-in Python type that is enormously useful is the dictionary.\n\nThis provides a mapping one set of variables to another (either one-to-one or many-to-one).\nIf you need to create associations between objects, use a dictionary.\n\nWe can obtain keys, values, or key-value paris from dictionaries."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-17",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-17",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nRunning on Empty\n\nBeing able to create empty containers is sometimes useful, especially when using loops.\nThe commands to create empty lists, tuples, dictionaries, and sets are lst = [], tup=(), dic={}, and st = set() respectively.\nQ. What is the type of an empty list?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-18",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-18",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\nname = \"Geneseo\"\nscore = 99\n\nif name == \"Geneseo\" and score &gt; 90:\n    print(\"Geneseo, you achieved a high score.\")\n\nif name == \"Geneseo\" or score &gt; 90:\n    print(\"You could be called Geneseo or have a high score\")\n\nif name != \"Geneseo\" and score &gt; 90:\n    print(\"You are not called Geneseo and you have a high score\")\n\nThe real power of conditions comes when we start to use them in more complex examples, such as if statements."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-19",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-19",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nOne of the most useful conditional keywords is in.\n\nThis one must pop up ten times a day in most coders‚Äô lives because it can pick out a variable or make sure something is where it‚Äôs supposed to be.\n\nQ. Check if ‚Äúa‚Äù is in the string ‚ÄúSun Devil Arena‚Äù using in. Is ‚Äúa‚Äù in ‚ÄúAnyone‚Äù?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-20",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-20",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nBooleans and Conditions\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nOne conditional construct we‚Äôre bound to use at some point, is the if-else chain:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-21",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-21",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nCasting Variables\n\n\norig_number = 4.39898498\ntype(orig_number)\n\nmod_number = int(orig_number)\nmod_number\ntype(mod_number)\n\n\n\nSometimes we need to explicitly cast a value from one type to another.\n\nWe can do this using built-in functions like str(), int(), and float().\nIf we try these, Python will do its best to interpret the input and convert it to the output type we‚Äôd like and, if they can‚Äôt, the code will throw a great big error."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-22",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-22",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nTuples and (im)mutability\n\n\nA tuple is an object that is defined by parentheses and entries that are separated by commas, for example (15, 20, 32). (They are of type tuple.)\nTuples are immutable, while lists are mutable.\nImmutable objects, such as tuples and strings, can‚Äôt have their elements changed, appended, extended, or removed.\n\nMutable objects, such as lists, can do all of these things.\n\nIn everyday programming, we use lists and dictionaries more than tuples."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-23",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-23",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nIndentation\n\nWe have seen that certain parts of the code examples are indented.\nCode that is part of a function, a conditional clause, or loop is indented.\nIndention is actually what tells the Python interpreter that some code is to be executed as part of, say, a loop and not to executed after the loop is finished."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-24",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-24",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nIndentation\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nHere‚Äôs a basic example of indentation as part of an if statement.\nThe standard practice for indentation is that each sub-statement should be indented by 4 spaces."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-25",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-25",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nDictionaries\ncities_to_temps = {\"Paris\": 28, \"London\": 22, \"New York\": 36, \"Seoul\": 29}\n\ncities_to_temps.keys()\ncities_to_temps.values()\ncities_to_temps.items()\n\nAnother built-in Python type that is enormously useful is the dictionary.\n\nThis provides a mapping one set of variables to another (either one-to-one or many-to-one).\nIf you need to create associations between objects, use a dictionary.\n\nWe can obtain keys, values, or key-value paris from dictionaries."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-26",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-26",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nRunning on Empty\n\nBeing able to create empty containers is sometimes useful, especially when using loops.\nThe commands to create empty lists, tuples, dictionaries, and sets are lst = [], tup=(), dic={}, and st = set() respectively.\nQ. What is the type of an empty list?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-27",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-27",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nSlicing Methods\n\n\n\n\nWith slicing methods, we can get subset of the data object.\nSlicing methods can apply for strings, lists, arrays, and DataFrames.\nThe above example describes indexing in Python"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-28",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-28",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nStrings\nstring = \"cheesecake\"\nprint( string[-4:] )\n\nFrom strings, we can access the individual characters via slicing and indexing.\n\n\n\nstring = \"cheesecake\"\nprint(\"String has length:\")\nprint( len(string) )\n\nlist_of_numbers = range(1, 20)\nprint(\"List of numbers has length:\")\nprint( len(list_of_numbers) )\n\n\n\nBoth lists and strings will allow us to use the len() command to get their length:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-29",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-29",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nString-related Functions\nDot operation\n\nIn Python, we can access attributes by using a dot notation (.).\nUnlike len(), some functions use a dot to access to strings.\nTo use those string functions, type (1) the name of the string, (2) a dot, (3) the name of the function, and (4) any arguments that the function needs:\n\nstring_name.some_function(arguments)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-30",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-30",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nString-related Functions\nSplit with split()\n\nWe can use the built-in string split() function to break a string into a list of smaller strings based on some separator.\n\nIf we don‚Äôt specify a separator, split() uses any sequence of white space characters‚Äînewlines, spaces, and tabs:\n\ntasks = 'get gloves,get mask,give cat vitamins,call ambulance'\ntasks.split(',')\ntasks.split()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-31",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-31",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nString-related Functions\nCombine by Using join()\n\njoin() collapses a list of strings into a single string.\n\ncrypto_list = ['Yeti', 'Bigfoot', 'Loch Ness Monster']\ncrypto_string = ', '.join(crypto_list)\nprint('Found and signing book deals:', crypto_string)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-32",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-32",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nStrings and Slicing\n\nWe can extract a substring (a part of a string) from a string by using a slice.\nWe define a slice by using square brackets ([]), a start index, an end index, and an optional step count between them.\n\nWe can omit some of these.\n\nThe slice will include characters from index start to one before end:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-33",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-33",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nGet a Substring with a Slice\n\n[:][ start :][: end ][ start : end ][ start : end : step ]\n\n\nletters = 'abcdefghij'\nletters[:]\n\n[:] extracts the entire sequence from start to end.\n\n\n\nletters = 'abcdefghij'\nletters[4:]\nletters[2:]\nletters[-3:]\nletters[-50:]\n\n[ start :] specifies from the start index to the end.\n\n\n\nletters = 'abcdefghij'\nletters[:3]\nletters[:-3]\nletters[:70]\n\n[: end ] specifies from the beginning to the end index minus 1.\n\n\n\nletters = 'abcdefghij'\nletters[2:5]\nletters[-26:-24]\nletters[35:37]\n\n[ start : end ] indicates from the start index to the end index minus 1.\n\n\n\nletters = 'abcdefghij'\nletters[2 : 6 : 2]   # From index 2 to 5, by steps of 2 characters\nletters[ : : 3]     # From the start to the end, in steps of 3 characters\nletters[ 6 : : 4 ]    # From index 19 to the end, by 4\nletters[ : 7 : 5 ]    # From the start to index 6 by 5:\nletters[-1 : : -1 ]   # Starts at the end and ends at the start\nletters[: : -1 ]\n\n[ start : end : step ] extracts from the start index to the end index minus 1, skipping characters by step."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-34",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-34",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nLists and Slicing\n\nPython is\n\na zero-indexed language (things start counting from zero);\nleft inclusive;\nright exclusive when we are specifying a range of values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-35",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-35",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nLists and Slicing\nlist_example = ['one', 'two', 'three']\nlist_example[ 0 : 1 ]\nlist_example[ 1 : 3 ]\n\n\n\n\nWe can think of items in a list-like object as being fenced in.\n\nThe index represents the fence post."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-36",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-36",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nLists and Slicing\n\n[index]slice\n\n\nGet an Item by [index]\nsuny = ['Geneseo', 'Brockport', 'Oswego', 'Binghamton', \n        'Stony Brook', 'New Paltz'] \n\nWe can extract a single value from a list by specifying its index:\n\n\n\nsuny[0]\nsuny[1]\nsuny[2]\nsuny[7]\n\nsuny[-1]\nsuny[-2]\nsuny[-3]\nsuny[-7]\n\n\n\n\nGet an Item with a Slice\n\nWe can extract a subsequence of a list by using a slice:\n\nsuny = ['Geneseo', 'Brockport', 'Oswego', 'Binghamton', \n        'Stony Brook', 'New Paltz'] \nsuny[0:2]    # A slice of a list is also a list.\n\n\nsuny[ : : 2]\nsuny[ : : -2]\nsuny[ : : -1]\n\nsuny[4 : ]\nsuny[-6 : ]\nsuny[-6 : -2]\nsuny[-6 : -4]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-37",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-37",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nLists and Slicing\n\nQ. Classwork 4.3"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-38",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-38",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nFunctions\nint(\"20\") \nfloat(\"14.3\")\nstr(5)\nint(\"xyz\")\n\nA function can take any number and type of input parameters and return any number and type of output results.\nPython ships with more than 65 built-in functions.\nPython also allows a user to define a new function.\nWe will mostly use built-in functions."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-39",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-39",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nFunctions, Arguments, and Parameters\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\")\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\", sep = \"!\")\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\", sep=\" \")\n\nWe invoke a function by entering its name and a pair of opening and closing parentheses.\nMuch as a cooking recipe can accept ingredients, a function invocation can accept inputs called arguments.\nWe pass arguments sequentially inside the parentheses (, separated by commas).\nA parameter is a name given to an expected function argument.\nA default argument is a fallback value that Python passes to a parameter if the function invocation does not explicitly provide one."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-40",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#python-basics-40",
    "title": "Lecture 4",
    "section": "Python Basics",
    "text": "Python Basics\nFunctions, Arguments, and Parameters\n\nQ. Classwork 4.4"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while",
    "title": "Lecture 4",
    "section": "Repeat with while",
    "text": "Repeat with while\n\n\ncount = 1        \nwhile count &lt;= 5:\n    print(count)\n    count += 1\n\n\nWe first assigned the value 1 to count.\nThe while loop compared the value of count to 5 and continued if count was less than or equal to 5.\nInside the loop, we printed the value of count and then incremented its value by one with the statement count += 1.\nPython goes back to the top of the loop, and again compares count with 5.\nThe value of count is now 2, so the contents of the while loop are again executed, and count is incremented to 3.\nThis continues until count is incremented from 5 to 6 at the bottom of the loop.\nOn the next trip to the top, count &lt;= 5 is now False, and the while loop ends."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while-1",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while-1",
    "title": "Lecture 4",
    "section": "Repeat with while",
    "text": "Repeat with while\nAsking the user for input\n\n\nstuff = input()\n# Type something and press Return/Enter on Console \n# before running print(stuff)\nprint(stuff)\n\n\nSometimes we would like to take the value for a variable from the user via their keyboard.\n\nThe input() function gets input from the keyboard.\nWhen the input() is called, the program stops and waits for the user to type something on Console (interactive Python interpreter).\nWhen the user presses Return or Enter on Console, the program resumes and input returns what the user typed as a string."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while-2",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while-2",
    "title": "Lecture 4",
    "section": "Repeat with while",
    "text": "Repeat with while\nCancel with break\n\n\nwhile True:\n    user_input = input(\"Enter 'yes' to continue or 'no' to stop: \")\n    if user_input.lower() == 'no':\n        print(\"Exiting the loop. Goodbye!\")\n        break\n    elif user_input.lower() == 'yes':\n        print(\"You chose to continue.\")\n    else:\n        print(\"Invalid input, please enter 'yes' or 'no'.\")\n\n\nWhile loop is used to execute a block of code repeatedly until given boolean condition evaluated to False.\n\nwhile True loop will run forever unless we write it with a break statement.\n\nIf we want to loop until something occurs, but we‚Äôre not sure when that might happen, we can use an infinite loop with a break statement."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while-3",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while-3",
    "title": "Lecture 4",
    "section": "Repeat with while",
    "text": "Repeat with while\nSkip Ahead with continue\n\n\nwhile True:\n    value = input(\"Integer, please [q to quit]: \")\n    if value == 'q': # quit\n        break\n    number = int(value)\n    if number % 2 == 0: # an even number\n        continue\n    print(number, \"squared is\", number*number)\n\n\nSometimes, we don‚Äôt want to break out of a loop but just want to skip ahead to the next iteration for some reason.\nThe continue statement is used to skip the rest of the code inside a loop for the current iteration only."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while-4",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#repeat-with-while-4",
    "title": "Lecture 4",
    "section": "Repeat with while",
    "text": "Repeat with while\nCheck break Use with else\n\nWe can consider using while with else when we‚Äôve coded a while loop to check for something, and breaking as soon as it‚Äôs found. \n\nnumbers = [1, 3, 5]\nposition = 0\n\nwhile position &lt; len(numbers):\n    number = numbers[position]\n    if number &gt; 4:  # Condition changed to checking if the number is greater than 4\n        print('Found a number greater than 4:', number)\n        break\n    position += 1\nelse:  # break not called\n    print('No number greater than 4 found')\n\nConsider it a break checker."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in",
    "title": "Lecture 4",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\n\nSometimes we want to loop through a set of things such as a string of text, a list of words or a list of numbers.\n\nWhen we have a list of things to loop through, we can construct a for loop.\nA for loop makes it possible for you to traverse data structures without knowing how large they are or how they are implemented."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-1",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-1",
    "title": "Lecture 4",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\n\nLet‚Äôs see two ways to walk through a string here:\n\n\n\nword = 'thud'\noffset = 0\nwhile offset &lt; len(word):\n    print(word[offset])\n    offset += 1\n\nword = 'thud'\nfor letter in word:\n    print(letter)\n\n\n\nWhich one do you prefer?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-2",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-2",
    "title": "Lecture 4",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nCancel with break\nword = 'thud'\nfor letter in word:\n    if letter == 'u':\n        break\n    print(letter)\n\nA break in a for loop breaks out of the loop, as it does for a while loop:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-3",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-3",
    "title": "Lecture 4",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nSkip with continue\nword = 'thud'\nfor letter in word:\n    if letter == 'u':\n        continue\n    print(letter)\n\nInserting a continue in a for loop jumps to the next iteration of the loop, as it does for a while loop."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-4",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-4",
    "title": "Lecture 4",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nGenerate Number Sequences with range()\n\nThe range() function returns a stream of numbers within a specified range, without first having to create and store a large data structure such as a list or tuple.\n\nThis lets us create huge ranges without using all the memory in our computers and crashing our program.\nrange() returns an iterable object, so we need to step through the values with for ‚Ä¶ in, or convert the object to a sequence like a list."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-5",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-5",
    "title": "Lecture 4",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nfor ‚Ä¶ in range()\n\n\nfor x in range(0, 3):\n    print(x)\nlist( range(0, 3) )\n\n\nWe use range() similar to how we use slices: range( start, stop, step ).\n\nIf we omit start, the range begins at 0.\nThe only required value is stop; as with slices, the last value created will be just before stop.\nThe default value of step is 1, but we can change it."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-6",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#iterate-with-for-and-in-6",
    "title": "Lecture 4",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nCheck break Use with else\n\nSimilar to while, for has an optional else that checks whether the for completed normally.\n\nIf break was not called, the else statement is run.\n\n\nword = 'thud'\nfor letter in word:\n    if letter == 'x':\n        print(\"Eek! An 'x'!\")\n        break\n    print(letter)\nelse:\n    print(\"No 'x' in there.\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#loop-with-while-and-for-1",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#loop-with-while-and-for-1",
    "title": "Lecture 4",
    "section": "Loop with while and for",
    "text": "Loop with while and for\nClass Exercises\n\nQ. Classwork 4.5\nQ. Classwork 4.6"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-1",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-1",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nException handlers"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-2",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-2",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nException handlers\n\nIn some languages, errors are indicated by special function return values.\n\nPython uses exceptions: code that is executed when an associated error occurs.\n\nWhen we run code that might fail under some circumstances, we also need appropriate exception handlers to intercept any potential errors.\n\nAccessing a list or tuple with an out-of-range position, or a dictionary with a nonexistent key."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-3",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-3",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nErrors\nshort_list = [1, 2, 3]\nposition = 5\nshort_list[position]\n\nIf we don‚Äôt provide your own exception handler, Python prints an error message and some information about where the error occurred and then terminates the program:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-4",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-4",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nshort_list = [1, 2, 3]\nposition = 5\n\ntry:\n    short_list[position]\nexcept:\n    print('Need a position between 0 and', len(short_list)-1, ' but got',\n    position)\n\nRather than leaving things to chance, use try to wrap your code, and except to provide the error handling:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-5",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-5",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nshort_list = [1, 2, 3]\nposition = 5\ntry:\n    short_list[position]\nexcept:\n    print('Need a position between 0 and', len(short_list)-1, ' but got',\n    position)\n\nThe code inside the try block is run.\n\nIf there is an error, an exception is raised and the code inside the except block runs.\n\nIf there are no errors, the except block is skipped."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-6",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-6",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\n\nSpecifying a plain except with no arguments, as we did here, is a catchall for any exception type.\nIf more than one type of exception could occur, it‚Äôs best to provide a separate exception handler for each.\nWe get the full exception object in the variable name if we use the form:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-7",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-7",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\nshort_list = [1, 2, 3]\nwhile True:\n    value = input('Position [q to quit]? ')\n    if value == 'q':\n        break\n    try:\n        position = int(value)\n        print(short_list[position])\n    except IndexError as err:\n        print('Bad index:', position)\n    except Exception as other:\n        print('Something else broke:', other)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-8",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-8",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\n\nThe example looks for an IndexError first, because that‚Äôs the exception type raised when we provide an illegal position to a sequence.\nIt saves an IndexError exception in the variable err, and any other exception in the variable other.\nThe example prints everything stored in other to show what you get in that object.\n\nInputting position 3 raised an IndexError as expected.\nEntering two annoyed the int() function, which we handled in our second, catchall except code."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-9",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#handle-errors-with-try-and-except-9",
    "title": "Lecture 4",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nClass Exercises\n\nQ. Classwork 4.7"
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#importing-modules-packages-and-libraries-1",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#importing-modules-packages-and-libraries-1",
    "title": "Lecture 4",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\n\nA module is basically a bunch of related codes saved in a file with the extension .py.\nA package is basically a directory of a collection of modules.\nA library is a collection of packages\nWe refer to code of other modules/pacakges/libraries by using the Python import statement.\n\nThis makes the code and variables in the imported module available to our programming codes.\nWe can use the as keyword when importing the modules using their canonical names.\n\nQ. Classwork 4.8"
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#building-a-personal-website-on-github",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#building-a-personal-website-on-github",
    "title": "Lecture 3",
    "section": "Building a Personal Website on GitHub",
    "text": "Building a Personal Website on GitHub\n\nFollow steps described in Classwork 1."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#lets-practice-markdown",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#lets-practice-markdown",
    "title": "Lecture 3",
    "section": "Let‚Äôs Practice Markdown!",
    "text": "Let‚Äôs Practice Markdown!\n\nJupyter Notebook, Quarto, and GitHub-based Discussion Boards use markdown as its underlying document syntax.\nLet‚Äôs do Classwork 2."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nYAML\n\n\n\n\n\n\nAn YAML (yet another markup language) header surrounded by ---.\n\nIt is commonly used for document configuration (e.g., title, author, date, style, ‚Ä¶)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html-1",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html-1",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nKnitting / Rendering\n\n\nWhen we knit the document, Quarto sends the .qmd file to jupyter/knitr, which executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output.\nThe markdown file (*.md) generated by jupyter/knitr is then processed by pandoc, which is responsible for creating the output file."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html-2",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html-2",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nMarkdown, Jupyter Notebook, and HTML\n\nThe very original version of Markdown was invented mainly to write HTML content more easily.\n\nFor example, - SOME_TEXT in ‚Äú.md‚Äù is equivalent to &lt;ul&gt;&lt;li&gt; SOME_TEXT &lt;/li&gt; in ‚Äù.html‚Äù\n\nPandoc makes it possible to convert a Markdown document to a large variety of output formats, such as HTML."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html-3",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html-3",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nMarkdown, Jupyter Notebook, and HTML\n---\ntitle: \"Habits\"\nauthor: YOUR_NAME\ndate: January 27, 2025\nformat: \n  html\n---\n\nTo create an HTML document from Jupyter Notebook, we specify the html output format in the YAML metadata of our document.\n\nBy default, format: html is set.\n\nOpen an empty Jupyter Notebook file from Google Colab (or VSCode).\n\nCreate the first cell that is Text.\nType the above YAML metadata to the first Text cell."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html-4",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#getting-started-with-jupyter-notebook-and-html-4",
    "title": "Lecture 3",
    "section": "Getting Started with Jupyter Notebook and HTML",
    "text": "Getting Started with Jupyter Notebook and HTML\nMarkdown, Jupyter Notebook, and HTML\n---\ntitle: \"Python Basics\"\nauthor: YOUR_NAME\ndate: \"2025-01-27\"\n---\n\nDownload the Jupyter Notebook file, danl-210-python-basic.ipynb from Brightspace, and open it from Google Colab (or VSCode if you prefer).\nThe above syntax is part of YAML metadata in danl-210-python-basic.ipynb.\n\nYAML should be always in the first cell, and the first cell should be text, not code.\n\nIn YAML, indentation really matters!\n\ntab (or four spaces) defines a level in YAML."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-_quarto.yml",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-_quarto.yml",
    "title": "Lecture 3",
    "section": "Quarto Website: _quarto.yml",
    "text": "Quarto Website: _quarto.yml\n\n\n---\nproject:\n  type: website\n\nwebsite:\n  title: \"YOUR NAME\"\n  navbar:\n    left:\n      - text: Project\n        href: danl_proj_nba.ipynb\n      - text: Blog\n        href: blog-listing.qmd\n\nformat:\n  html:\n    theme: cosmo\n    css: styles.css\n    toc: false\n---\n\nThe _quarto.yml file configures the website settings.\nIndentation matters!\n\n\n\n\nIn RStudio, open the project USERNAME.github.io.Rporj.\n\nClick Project: (None) at the top-right corner.\nClick USERNAME.github.io.Rproj.\n\n_quarto.yml configures a website, and provides various options for HTML documents within the website."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nCustom CSS\n\nCascading Style Sheets (CSS) is used to format the layout of a webpage (color, font, text size, background, display, etc.).\n\nHTML will format the architecture of the house.\nCSS will be the carpet and walls to decorate the house.\nJavaScript adds interactive elements in the house, such as opening doors and lighting.\n\nWe are not front-end web developers.\n\nWe will not cover the use of CSS and JavaScript."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-1",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-1",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nRendering\n\n\nThe Render button (command/Ctrl + shift + K) renders a single Quarto document file (e.g., index.qmd) to create an output document.\nquarto render from Terminal renders ALL Quarto documents and Jupyter Notebook files in your local working directory:\n\nquarto render\n\nquarto render should be used if there is any change in _quarto.yml.\n\n\n\n\n\nTip\n\n\n\nEdit _quarto.yml, *.qmd, or *.ipynb files ONLY from your local laptop or Google Colab.\n\nDo not edit them from your GitHub repo for the website."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-2",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-2",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nAdding *.ipynb to a Quarto website\n\nBy default, quarto render doesn‚Äôt execute any code in .ipynb notebooks.\nquarto render renders .ipynb notebooks, so that corresponding html files are rendered.\n\nIf you need to update cell outputs in *.ipynb, run that *.ipynb on Google Colab, save the notebook, and download it to your local working directory."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-3",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-3",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nAppearance and Style\n\ntheme specifies the Bootstrap theme to use for the page (themes are drawn from the Bootswatch theme library).\n\nValid themes include default, bootstrap, cerulean, cosmo, darkly, flatly, journal, lumen, paper, readable, sandstone, simplex, spacelab, united, and yeti.\n\nhighlight-style specifies the code highlighting style.\n\nSupported styles include default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, and textmate."
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-4",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-4",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nAbout\n\nYour index.qmd sets a front page about you.\n\nDetails in about pages are available here:\nhttps://quarto.org/docs/websites/website-about.html.\n\nQuarto includes 5 built in templates:\n\njolla\ntrestles\nsolana\nmarquee\nbroadside"
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-5",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-5",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nIcons and Emojis\n\nA ton of Bootstrap icons are available here:\n\nhttps://icons.getbootstrap.com.\n\nA ton of markdown emojis are available here üòÑ:\n\nhttps://github.com/ikatyang/emoji-cheat-sheet\nhttps://gist.github.com/rxaviers/7360908"
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-6",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-6",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nNaviation and Adding Pages\nleft:\n  - text: Project\n    href: danl_proj_nba.ipynb\n  - text: Blog\n    href: blog-listing.qmd\n\nWe can add a new page to the website through navbar in _quarto.yml"
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-7",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-7",
    "title": "Lecture 3",
    "section": "Quarto Website",
    "text": "Quarto Website\nNaviation and Adding Pages\nleft:\n  - text: \"Python Data Analysis\"\n    menu:\n      - pandas_basic.ipynb\n      - seaborn_basic.ipynb\n\nWe can also create a drop-down menu by including a menu\nMore details about navbar are available here:\n\nhttps://quarto.org/docs/websites/website-navigation.html"
  },
  {
    "objectID": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-basics",
    "href": "danl-lec/danl-210-lec-03-2025-0127.html#quarto-website-basics",
    "title": "Lecture 3",
    "section": "Quarto Website Basics",
    "text": "Quarto Website Basics\n\nLet‚Äôs do Classwork 3."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#why-data-analytics",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#why-data-analytics",
    "title": "Lecture 2",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nFill in the gaps left by traditional business and economics classes.\n\nPractical skills that will benefit your future career.\nNeglected skills like how to actually find datasets in the wild and clean them.\n\nData analytics skills are largely distinct from (and complementary to) the core quantitative works familiar to business undergrads.\n\nData visualization, cleaning and wrangling; databases; machine learning; etc.\n\nIn short, we will cover things that I wish someone had taught me when I was undergraduate."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#you-at-the-end-of-this-course",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#you-at-the-end-of-this-course",
    "title": "Lecture 2",
    "section": "You, at the end of this course",
    "text": "You, at the end of this course"
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#why-data-analytics-1",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#why-data-analytics-1",
    "title": "Lecture 2",
    "section": "Why Data Analytics?",
    "text": "Why Data Analytics?\n\nData analysts use analytical tools and techniques to extract meaningful insights from data.\n\nSkills in data analytics are also useful for business analysts or market analysts.\n\nBreau of Labor Statistics forecasts that the projected growth rate of the employment in the industry related to data analytics from 2021 to 2031 is 36%.\n\nThe average growth rate for all occupations is 5%."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#the-state-of-the-art",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#the-state-of-the-art",
    "title": "Lecture 2",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\n\nData Science and Big Data Trend\nFrom 2008 to now\n\n\nProgrammers in 2025"
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#the-state-of-the-art-1",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#the-state-of-the-art-1",
    "title": "Lecture 2",
    "section": "The State of the Art",
    "text": "The State of the Art\nGenerative AI and ChatGPT\n\nUsers around the world have explored how to best utilize GPT for writing essays and programming codes.\n\n\n\n\nIs AI a threat to data analytics?\n\nFundamental understanding of the subject matter is still crucial for effectively utilizing AI‚Äôs capabilities.\n\n\n\n\n\nIf you use Generative AI such as ChatGPT, please try to understand what ChatGPT gives you.\n\nCopying and pasting it without any understanding harms your learning opportunity."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-git",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-git",
    "title": "Lecture 2",
    "section": "What is Git?",
    "text": "What is Git?\n\n\n\n\n\\(\\quad\\)\n\nGit is the most popular version control tool for any software development.\n\nIt tracks changes in a series of snapshots of the project, allowing developers to revert to previous versions, compare changes, and merge different versions.\nIt is the industry standard and ubiquitous for coding collaboration."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-github",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-github",
    "title": "Lecture 2",
    "section": "What is GitHub?",
    "text": "What is GitHub?\n\nGitHub is a web-based hosting platform for Git repositories to store, manage, and share code.\nOut class website is hosted on a GitHub repository.\nCourse contents will be posted not only in Brightspace but also in our GitHub repositories (‚Äúrepos‚Äù) and websites.\nGithub is useful for many reasons, but the main reason is how user friendly it makes uploading and sharing code."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-github-1",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-github-1",
    "title": "Lecture 2",
    "section": "What is GitHub?",
    "text": "What is GitHub?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-python",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-python",
    "title": "Lecture 2",
    "section": "What is Python?",
    "text": "What is Python?\n\nPython is a versatile programming language known for its simplicity and readability.\nPython has become a dominant tool in various fields including data analysis, machine learning, and web development.\n\nIt is widely used among developers, data scientists, and researchers for building applications and performing data-driven tasks.\nPython is open source and has a vast ecosystem of libraries and frameworks."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-jupyter",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-jupyter",
    "title": "Lecture 2",
    "section": "What is Jupyter?",
    "text": "What is Jupyter?\n\nJupyter is an open-source integrated development environment (IDE) primarily for Python, though it supports many other languages.\n\nAn IDE is a software application that provides comprehensive facilities (e.g., text code editor, graphical user interface (GUI)) to users for a programming-related project.\nJupyter provides a notebook interface that allows users to write and execute code in a more interactive and visual format."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-jupyter-notebook",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-jupyter-notebook",
    "title": "Lecture 2",
    "section": "What is Jupyter Notebook?",
    "text": "What is Jupyter Notebook?\n\nJupyter Notebook (*.ipynb) is a user-friendly environment that enhances coding, data analysis, and visualization.\n\nIt offers a web-based interface that combines live code, equations, visualizations, and narrative text.\nJupyter Notebook is widely used for data science, machine learning, and research, enabling easy sharing and collaboration.\n\nWe will use Google Colab, a free cloud version of Jupyter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-rstudio",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#what-is-rstudio",
    "title": "Lecture 2",
    "section": "What is RStudio?",
    "text": "What is RStudio?\n\nRStudio is an IDE mainly for R programming.\nRStudio is a user-friendly interface that makes using R easier and more interactive.\n\nIt provides a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging, and workspace management.\n\nWe will use RStudio to manage a personal website, where HTML files are rendered from Quarto Document and Jupyter Notebook."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-1",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-1",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR programming\n\nThe R language is available as a free download from the R Project website at:\n\nWindows: https://cran.r-project.org/bin/windows/base/\nMac: https://cran.r-project.org/bin/macosx/\nDownload the file of R that corresponds to your Mac OS (Big Sur, Apple silicon arm64, High Sierra, El Capitan, Mavericks, etc.)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-2",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-2",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR Studio\n\n\nThe RStudio Desktop is available as a free download from the following webpage:\n\nhttps://www.rstudio.com/products/rstudio/download/#download\n\n\n\n\n\n\nFor Mac users, try the following steps:\n\nRun RStudio-*.dmg file.\nFrom the Pop-up menu, click the RStudio icon.\nWhile clicking the RStudio icon, drag it to the Applications directory."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-3",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-3",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\n\nScript Pane is where you write R commands in a script file that you can save.\n\nAn R script is simply a text file containing R commands.\nRStudio will color-code different elements of your code to make it easier to read.\n\n\n\n\n\n\n\n\nTo open an R script,\n\nFile \\(&gt;\\) New File \\(&gt;\\) R Script\n\n\n\n\nTo save the R script,\n\nFile \\(&gt;\\) Save"
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-4",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-4",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\n\nConsole Pane allows you to interact directly with the R interpreter and type commands where R will immediately execute them."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-5",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-5",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\n\nEnvironment Pane is where you can see the values of variables, data frames, and other objects that are currently stored in memory.\nType below in the Console Pane, and then hit Enter:\n\n\na &lt;- 1"
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-6",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-6",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Environment\n\n\n\n\n\n\nPlots Pane contains any graphics that you generate from your R code."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-7",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-7",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nR Packages and tidyverse\n\nR packages are collections of R functions, compiled code, and data that are combined in a structured format.\n\n\n\nThe tidyverse is a collection of R packages designed for data science that share an underlying design philosophy, grammar, and data structures.\n\nThe tidyverse packages work harmoniously together to make data manipulation, exploration, and visualization more.\nWe will use several R packages from tidyverse throughout the course. (e.g., ggplot2, dplyr, tidyr)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-8",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-8",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nInstalling R packages with install.packages(\"packageName\")\n\n\nR packages can be easily installed from within R using functions install.packages(\"packageName\").\n\nTo install the R package tidyverse, type and run the following from R console:\n\n\n\ninstall.packages(\"tidyverse\")\n\nWhile running the above codes, you may encounter the question below from the R Console:\n\n\n\n\nMac: ‚ÄúDo you want to install from sources the packages which need compilation?‚Äù from Console Pane.\n\n\n\nWindows: ‚ÄúWould you like to use a personal library instead?‚Äù from Pop-up message.\n\n\n\n\nType no in the R Console, and then hit Enter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-9",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-9",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nLoading R packages with library(packageName)\n\n\nOnce installed, a package is loaded into an R session using library(packageName) so that its functions and data can be used.\n\nTo load the R package tidyverse, type and run the following command from a R script:\n\n\n\nlibrary(tidyverse)\ndf_mpg &lt;- ggplot2::mpg\n\nmpg is the data.frame provided by the R package ggplot2, one of the R pakcages in tidyverse."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-10",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-10",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nRStudio Options Setting\n\n\n\n\n\nThis option menu is found by menus as follows:\n\nTools \\(&gt;\\) Global Options\n\nCheck the boxes as in the left.\nChoose the option Never for  Save workspace to .RData on exit:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-11",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#installing-the-tools-11",
    "title": "Lecture 2",
    "section": "Installing the Tools",
    "text": "Installing the Tools\nAnaconda\n\nTo install Anaconda, go to the following download page:\n\nhttps://www.anaconda.com/products/distribution.\nClick the ‚ÄúDownload‚Äù button.\n\nTo work on web-scrapping and APIs, we will use Spyder IDE provided by Anaconda."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#building-a-personal-website-on-github",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#building-a-personal-website-on-github",
    "title": "Lecture 2",
    "section": "Building a Personal Website on GitHub",
    "text": "Building a Personal Website on GitHub\n\nFollow steps described in Classwork 1."
  },
  {
    "objectID": "danl-lec/danl-210-lec-02-2025-0124.html#lets-practice-markdown",
    "href": "danl-lec/danl-210-lec-02-2025-0124.html#lets-practice-markdown",
    "title": "Lecture 2",
    "section": "Let‚Äôs Practice Markdown!",
    "text": "Let‚Äôs Practice Markdown!\n\nJupyter Notebook, Quarto, and GitHub-based Discussion Boards use markdown as its underlying document syntax.\nLet‚Äôs do Classwork 2."
  },
  {
    "objectID": "danl-rw/danl-210-project.html#project",
    "href": "danl-rw/danl-210-project.html#project",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "Project",
    "text": "Project\n\nPublish the webpage of your data analysis project on your website, hosted on GitHub.\n\nYour data analysis should focus on the agenda, ‚ÄúUnifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis‚Äù.\nUse either a Jupyter Notebook or a Quarto document to present your work.\nThe due for the project is May 16, 2025, Friday, 11:59 P.M."
  },
  {
    "objectID": "danl-rw/danl-210-project.html#project-data",
    "href": "danl-rw/danl-210-project.html#project-data",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "Project Data",
    "text": "Project Data\n\nBelow is the esg_proj DataFrame, which provides a list of companies and associated information\n\n\nimport pandas as pd\nesg_proj = pd.read_csv(\"https://bcdanl.github.io/data/stock_esg_list.csv\")\n\n\n\n\n\n\n\nVariable Description\n\nSymbol: a company‚Äôs ticker;\nCompany Name: a company name;\nSector: a sector a company belongs to;\nIndustry: an industry a company belongs to;\nCountry: a country a company belongs to;\nMarket Cap: a company‚Äôs market capitalization as of December 20, 2024 (Source: Nasdaq‚Äôs Stock Screener).\n\nA company‚Äôs market capitalization is the value of the company that is traded on the stock market, calculated by multiplying the total number of shares by the present share price."
  },
  {
    "objectID": "danl-rw/danl-210-project.html#project-tasks",
    "href": "danl-rw/danl-210-project.html#project-tasks",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "Project Tasks",
    "text": "Project Tasks\n\nData Collection\n\n\nyfinance\n\nUtilize the yfinance library, an unofficial API for accessing Yahoo! Finance data.\n\nFor each company listed in the esg_proj DataFrame, you should retrieve the following:\n\nDaily historical stock data spanning from January 1, 2024, to March 31, 2025.\nQuarterly income statements covering the period from March 31, 2024, to March 31, 2025 (encompassing five quarters).\nQuarterly balance sheets for the same period as the income statements.\n\n\n\n\n\nselenium\n\nEmploy the Python selenium library to gather ESG Risk Ratings, along with the Controversy Level from the Sustainability Section of each company‚Äôs webpage on Yahoo! Finance, such as:\n\nAgilent Technologies (A)\nAlcoa Corporation (AA)\n\nEnsure robust error and exception handling during data collection from the Sustainability Section on Yahoo! Finance:\n\nTo avoid being blocked by Yahoo! Finance for automated browsing activities, please manage the Chrome driver by launching and quitting it after processing every 20 companies‚Äô Sustainability Sections.\nUse time.sleep() for each visit of the Sustainability Section webpage.\nSome companies may lack available data on Environmental Risk Score, Social Risk Score, Governance Risk Score, and/or Controversy Level.\nYahoo! Finance intermittently switches between its new and classic website layouts, affecting the HTML DOM structure of the Sustainability Section.\n\n\nYou can check the new and classic layouts of Yahoo! Finance by selecting the corresponding options from the navigation bar on their website.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis\n\nBelow are the key components in the data analysis webpage.\n\nTitle: A clear and concise title that gives an idea of the project topics.\nIntroduction:\n\nBackground: Provide context for the research questions, explaining why they are significant, relevant, or interesting.\nStatement of the Problem: Clearly articulate the specific problem or issue the project will address.\n\nData Collection: Use a Python script (*.py) to write the code and the comment on how to retrieve financial, accounting, and ESG data using Python yfinance and selenium.\n\nDo NOT provide your code for data collection in your webpage. You should submit your Python script for data collection to Brightspace.\n\nDescriptive Statistics\n\n\nProvide both grouped and un-grouped descriptive statistics and distribution plots for the ESG data and the finance/accounting data\nProvide correlation heat maps using corr() and seaborn.heatmap(). Below provides the Python code for creating a correlation heatmap.\n\n\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Sample DataFrame with varied correlations\ndata = {\n    'Revenue': [100, 200, 300, 400, 500],  \n    'Profit': [20, 40, 60, 80, 100],       \n    'n_Employee': [50, 45, 40, 35, 30], \n    'n_Customer': [10, 11, 12, 13, 14]  \n}\n\n# Create a DataFrame from the dictionary\ndf = pd.DataFrame(data)\n\n# Calculate the correlation matrix of the DataFrame\ncorr = df.corr()\n\n# Set up the matplotlib figure size\nplt.figure(figsize=(8, 6))\n\n# Generate a heatmap in seaborn:\n# - 'corr' is the correlation matrix\n# - 'annot=True' enables annotations inside the squares with the correlation values\n# - 'cmap=\"coolwarm\"' assigns a color map from cool to warm (blue to red)\n# - 'fmt=\".2f\"' formats the annotations to two decimal places\n# - 'linewidths=.5' adds lines between each cell\nsns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n\n# Title of the heatmap\nplt.title('Correlation Heatmap with Varied Correlations')\n\n# Display the heatmap\nplt.show()\n\n\n\n\n\nExploratory Data Analysis:\n\nList the questions you aim to answer.\nAddress the questions through data visualization with seaborn (or lets-plot) and pandas methods and attributes.\n\nSignificance of the Project:\n\nExplain its implications for real-world applications, business strategies, or public policy.\n\nReferences\n\nList all sources cited in the project.\nLeave a web address of the reference if that is from the web.\nIndicate if the code and the write-up are guided by generative AI, such as ChatGPT. There will be no penalties on using any generative AI.\nClearly state if the code and the write-up result from collaboration with colleagues. There will be no penalties for collaboration, provided that the shared portions are clearly indicated."
  },
  {
    "objectID": "danl-rw/danl-210-project.html#rubric-for-the-project",
    "href": "danl-rw/danl-210-project.html#rubric-for-the-project",
    "title": "Unifying Environmental, Social, and Governance (ESG) Metrics with Financial Analysis",
    "section": "Rubric for the Project",
    "text": "Rubric for the Project\n\nHere is the link to the PDF file of the rubric for the project web-page.\n\n\nRubric for Quality of Data Collection\n\n\n\n\n\n\n\n\nEvaluation\nDescription\nCriteria\n\n\n\n\n1 (Very Deficient)\n- Very poorly implemented- Data is unreliable.\n- Ineffective use of yfinance, resulting in incomplete or inaccurate financial data.- Poor web scraping practices with selenium, leading to unreliable or incorrect data from Yahoo Finance.- Inadequate use of pandas, resulting in poorly structured DataFrames.\n\n\n2 (Somewhat Deficient)\n- Somewhat effective implementation- Data has minor reliability issues.\n- Basic use of yfinance with minor inaccuracies in data retrieval.- Basic web scraping with selenium that sometimes fails to capture all relevant data accurately.- Basic use of pandas, but with occasional issues in data structuring.\n\n\n3 (Acceptable)\n- Competently implemented- Data is mostly reliable.\n- Competent use of yfinance to retrieve most financial data accurately.- Effective web scraping with selenium, capturing most required data from Yahoo Finance.- Adequate use of pandas to structure data in a mostly logical format.\n\n\n4 (Very Good)\n- Well-implemented and organized- Data is reliable.\n- Advanced use of yfinance to reliably and accurately fetch financial data.- Thorough web scraping with selenium that consistently captures accurate and complete data from Yahoo Finance.- Skillful use of pandas for clear and logical data structuring.\n\n\n5 (Outstanding)\n- Exceptionally implemented- Data is highly reliable.\n- Expert use of yfinance to obtain comprehensive and precise financial data.- Expert web scraping with selenium, capturing detailed and accurate data from Yahoo Finance without fail.- Expert use of pandas to create exceptionally well-organized DataFrames that facilitate easy analysis."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Diving into the complex world of what people like in their beer, the beer_markets.csv dataset comes across as a goldmine of data, showing us the detailed interactions between buyers and their favorite beers. This dataset covers everything from how much and at what price people are buying beer to how deals and brand loyalty influence their decisions, across different types of people and places. As we start digging into this dataset, we aim to uncover the patterns that show what really influences the modern beer drinker‚Äôs choices, offering up valuable insights for marketers, industry watchers, and beer lovers. By breaking down the data, our exploration will shine a light on the factors that drive consumer behavior in the beer market, giving us a full picture of the trends that shape this lively industry.\nCode\n# Creating an interactive table\n!pip install itables\nfrom itables import init_notebook_mode\nfrom itables import show\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\nshow(beer_data)\n\n\n\n\n\n\n\n    \n      \n      hh\n      _purchase_desc\n      quantity\n      brand\n      dollar_spent\n      beer_floz\n      price_per_floz\n      container\n      promo\n      market\n      buyertype\n      income\n      childrenUnder6\n      children6to17\n      age\n      employment\n      degree\n      cow\n      race\n      microwave\n      dishwasher\n      tvcable\n      singlefamilyhome\n      npeople\n    \n  Loading... (need help?)\nCode\n# Setting up the visualization settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\nCode\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let‚Äôs calculate the average quantity purchased and average spending per purchase. For this, we‚Äôll consider each row in the dataset as a separate purchase and compute the averages accordingly.\nCode\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean',\n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we‚Äôll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we‚Äôll sum up the spending in each market and visualize it.\nCode\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 18))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let‚Äôs move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI‚Äôll start by analyzing spending by age group.\n\n\nCode\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n\nCode\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let‚Äôs look at spending by race to complete the demographic analysis.\n\n\nCode\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let‚Äôs proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe‚Äôll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we‚Äôll visualize how the price is sensitive to the quantity purchased by brand.\n\n\nCode\n# Ensure there's no entries with 0 for 'price_per_floz' or 'quantity' to avoid log(0) issues\nfiltered_data = beer_data[(beer_data['price_per_floz'] &gt; 0) & (beer_data['quantity'] &gt; 0)]\n\n# Calculate log values for both 'price_per_floz' and 'quantity'\nfiltered_data['log_price_per_floz'] = np.log(filtered_data['price_per_floz'])\nfiltered_data['log_quantity'] = np.log(filtered_data['quantity'])\n\n# Use seaborn to create a scatterplot with fitted lines, facetted by 'brand'\ng = sns.lmplot(data=filtered_data, x='log_quantity', y='log_price_per_floz', col='brand', col_wrap=4, height=3, line_kws={'color': 'red'}, scatter_kws={'alpha':0.5}, aspect = .75)\n\n# Adjusting plot aesthetics\ng.set_titles(\"{col_name}\")\ng.set_axis_labels(\"Log of Quantity\", \"Log of Price per Floz\")\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Log of Price per Floz vs. Log of Quantity')\n\nplt.show()\n\n\n\n\n\nHere‚Äôs the scatterplot with fitted straight lines for the log of price_per_floz versus the log of quantity, facetted by brands. Each subplot represents a different brand, showing the relationship between these two logarithmic variables along with a fitted line to illustrate the trend within each brand‚Äôs data.\n\n\nCode\n# Adjust the facetting to split rows by 'brand' and columns by 'promo' for a more detailed comparative analysis\ng = sns.lmplot(data=filtered_data, x='log_quantity', y='log_price_per_floz', row='brand', col='promo', height=3, aspect=.75, line_kws={'color': 'red'}, scatter_kws={'alpha':0.5})\n\n# Adjusting plot aesthetics\ng.set_titles(\"Brand: {row_name}\\n Promo: {col_name}\")\ng.set_axis_labels(\"Log of Quantity\", \"Log of Price per Floz\")\nplt.subplots_adjust(top=0.9, wspace = .4, hspace = .4)\ng.fig.suptitle('Log of Price per Floz vs. Log of Quantity')\n\nplt.show()\n\n\n\n\n\nThe scatterplot has been reorganized to split rows by brand and columns by promo status, offering a comprehensive view across different brands and their promotional status. Each subplot now provides a clear comparison of the log of price_per_floz versus the log of quantity for purchases made on promotion versus those that were not, across various beer brands.\nThis layout facilitates an easier comparison across brands and how promotion impacts the relationship between quantity and price per fluid ounce within each brand.\nLastly, let‚Äôs move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact-on-quantity-purchased",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact-on-quantity-purchased",
    "title": "Beer Markets",
    "section": "Promotional Impact on Quantity Purchased",
    "text": "Promotional Impact on Quantity Purchased\nWe‚Äôll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We‚Äôll do this for each brand to see which brands are most affected by promotions.\nLet‚Äôs begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n\nCode\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn‚Äôt. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "danl-cw/danl-210-cw-04.html",
    "href": "danl-cw/danl-210-cw-04.html",
    "title": "Classwork 4",
    "section": "",
    "text": "Using Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-210-cw-04.html#question-1",
    "href": "danl-cw/danl-210-cw-04.html#question-1",
    "title": "Classwork 4",
    "section": "",
    "text": "Using Python operations only, calculate below: \\[\\frac{2^5}{7 \\cdot (4 - 2^3)}\\]\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-210-cw-04.html#question-2",
    "href": "danl-cw/danl-210-cw-04.html#question-2",
    "title": "Classwork 4",
    "section": "Question 2",
    "text": "Question 2\nFor each expression below, what is the value of the expression? Explain thoroughly.\n\n20 == '20'\n\n\nx = 4.0\ny = .5\n\nx &lt; y or 3*y &lt; x\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-210-cw-04.html#question-3",
    "href": "danl-cw/danl-210-cw-04.html#question-3",
    "title": "Classwork 4",
    "section": "Question 3",
    "text": "Question 3\n\nfare = \"$10.00\"\ntip = \"2.00$\"\ntax = \"$ 0.80\"\n\nWrite a Python code that uses slicing and the print() function to print out the following message:\n\nThe total trip cost is: $12.80\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-210-cw-04.html#question-4",
    "href": "danl-cw/danl-210-cw-04.html#question-4",
    "title": "Classwork 4",
    "section": "Question 4",
    "text": "Question 4\n\nlist_variable = [100, 144, 169, 1000, 8]\n\nWrite a Python code that uses print() and max() functions to print out the largest value in the list, list_variable, as follows:\n\nThe largest value in the list is: 1000\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-210-cw-04.html#question-5",
    "href": "danl-cw/danl-210-cw-04.html#question-5",
    "title": "Classwork 4",
    "section": "Question 5",
    "text": "Question 5\n\nvals = [3, 2, 1, 0]\n\n\nUse a while loop to print each value of the list [3, 2, 1, 0], one at a time.\nUse a for loop to print each value of the list [3, 2, 1, 0], one at a time.\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-210-cw-04.html#question-6",
    "href": "danl-cw/danl-210-cw-04.html#question-6",
    "title": "Classwork 4",
    "section": "Question 6",
    "text": "Question 6\n\nAssign the value 7 to the variable guess_me, and the value 1 to the variable number.\nWrite a while loop that compares number with guess_me.\n\nPrint ‚Äòtoo low‚Äô if number is less than guess me.\nIf number equals guess_me, print ‚Äòfound it!‚Äô and then exit the loop.\nIf number is greater than guess_me, print ‚Äòoops‚Äô and then exit the loop.\nIncrement number at the end of the loop.\n\nWrite a for loop that compares number with guess_me.\n\nPrint ‚Äòtoo low‚Äô if number is less than guess me.\nIf number equals guess_me, print ‚Äòfound it!‚Äô and then exit the loop.\nIf number is greater than guess_me, print ‚Äòoops‚Äô and then exit the loop.\nIncrement number at the end of the loop.\n\n\n\nAnswer"
  },
  {
    "objectID": "danl-cw/danl-210-cw-02.html",
    "href": "danl-cw/danl-210-cw-02.html",
    "title": "Classwork 2",
    "section": "",
    "text": "Markdown is a lightweight markup language with plain-text formatting syntax. Its main goal is to be readable and easy to write, even when viewed as plain text. Markdown is widely used for creating formatted text on the web and in various applications such as Quarto.\n\n\n\n\nHeadings are created by adding one or more # symbols before your heading text. The number of # symbols indicates the level of the heading.\n# Heading 1\n## Heading 2\n### Heading 3\n\n\n\nYou can make text bold by wrapping it with two asterisks **, and italic by using one asterisk *.\n*italic* or _italic_\n**bold** or __bold__\n\n\n\nUnordered lists are created using *, -, or +, while ordered lists are numbered.\n- Item 1\n- Item 2\n  - Subitem 2.1\n  - Subitem 2.2\n1. First item\n2. Second item\n\n\n\nLinks are created using [Link Text](URL)\n[DANL 210](https://bcdanl.github.io/210)\n\n\n\nImages are created using ![Alt Text](Image URL).\n![Geneseo Logo](https://bcdanl.github.io/img/geneseo-logo.gif)\n\n\n\n\n\n\n&gt; Be yourself. Everyone else is already taken. - Oscar Wilde.\n\n\n\n\nA ton of markdown emojis are available here üòÑ (:smile:)\n\nhttps://github.com/ikatyang/emoji-cheat-sheet\n\n\n\n\n\nCode blocks are created by using triple backticks (```). Optionally, you can specify the language for syntax highlighting.\n```\n\"string\"\n```\n```python\n# Python code block\nimport numpy as np\n```\n\n\n\n\n\nDo the following tasks on this Classwork 2 Discussion Board:\n\nBasic Syntax: Write a comment with a heading, an unordered list, an ordered list, a link, and an image.\nAdvanced Syntax: Write a comment that includes a Python code block, a blockquote, and an emoji.\n\n\n\n\n\n\nQuarto Markdown Basics\nStart writing on GitHub"
  },
  {
    "objectID": "danl-cw/danl-210-cw-02.html#basic-syntax",
    "href": "danl-cw/danl-210-cw-02.html#basic-syntax",
    "title": "Classwork 2",
    "section": "",
    "text": "Headings are created by adding one or more # symbols before your heading text. The number of # symbols indicates the level of the heading.\n# Heading 1\n## Heading 2\n### Heading 3\n\n\n\nYou can make text bold by wrapping it with two asterisks **, and italic by using one asterisk *.\n*italic* or _italic_\n**bold** or __bold__\n\n\n\nUnordered lists are created using *, -, or +, while ordered lists are numbered.\n- Item 1\n- Item 2\n  - Subitem 2.1\n  - Subitem 2.2\n1. First item\n2. Second item\n\n\n\nLinks are created using [Link Text](URL)\n[DANL 210](https://bcdanl.github.io/210)\n\n\n\nImages are created using ![Alt Text](Image URL).\n![Geneseo Logo](https://bcdanl.github.io/img/geneseo-logo.gif)"
  },
  {
    "objectID": "danl-cw/danl-210-cw-02.html#advanced-syntax",
    "href": "danl-cw/danl-210-cw-02.html#advanced-syntax",
    "title": "Classwork 2",
    "section": "",
    "text": "&gt; Be yourself. Everyone else is already taken. - Oscar Wilde.\n\n\n\n\nA ton of markdown emojis are available here üòÑ (:smile:)\n\nhttps://github.com/ikatyang/emoji-cheat-sheet\n\n\n\n\n\nCode blocks are created by using triple backticks (```). Optionally, you can specify the language for syntax highlighting.\n```\n\"string\"\n```\n```python\n# Python code block\nimport numpy as np\n```"
  },
  {
    "objectID": "danl-cw/danl-210-cw-02.html#practice-problems",
    "href": "danl-cw/danl-210-cw-02.html#practice-problems",
    "title": "Classwork 2",
    "section": "",
    "text": "Do the following tasks on this Classwork 2 Discussion Board:\n\nBasic Syntax: Write a comment with a heading, an unordered list, an ordered list, a link, and an image.\nAdvanced Syntax: Write a comment that includes a Python code block, a blockquote, and an emoji."
  },
  {
    "objectID": "danl-cw/danl-210-cw-02.html#references",
    "href": "danl-cw/danl-210-cw-02.html#references",
    "title": "Classwork 2",
    "section": "",
    "text": "Quarto Markdown Basics\nStart writing on GitHub"
  },
  {
    "objectID": "index-home.html",
    "href": "index-home.html",
    "title": "Byeong-Hak Choe",
    "section": "",
    "text": "Hello! üëã\nI am an assistant professor of data analytics and economics at School of Business at SUNY Geneseo.\nMy research interests lie in economics of the environment and climate change."
  },
  {
    "objectID": "index-home.html#research",
    "href": "index-home.html#research",
    "title": "Byeong-Hak Choe",
    "section": "Research",
    "text": "Research\n\nWorking papers\n1Ô∏è‚É£ Social Media Campaign, Lobbying, and Legislation: Evidence from #cliamtechange and Energy Lobbies\n2Ô∏è‚É£ Climate Finance under Conflicts and Renegotiations: A Dynamic Contract Approach\n\n\nWork in progress\nüåü ‚ÄòHiding Behind a Small Cake‚Äô in an Online Dictator Game: The Way You Hide Matters!, (with TabareÃÅ Capitan (1st author) , Jason Shogren, and Benjamin White).\nüåü Estimating the Value of Statistical Life through Big Data, (with Stephen Newbold and Alexander James).\n\n\nBook chapters\nüí° Governance and Climate Finance in the Developing World (with Tilsa Or√©-Monago).\n-¬†In Wu, F., Zhang, D., and Ji, Q. (Eds.), Climate Finance: Supporting a Sustainable Energy Transition, Chapter 7, Springer Nature (July, 2024)."
  },
  {
    "objectID": "danl-qa/danl-210-qa.html",
    "href": "danl-qa/danl-210-qa.html",
    "title": "DANL 210 - Discussion and Q & A Board",
    "section": "",
    "text": "Welcome to our Discussion and Q & A Board! üëã \nThis space is designed for you to engage with your classmates about the course materials.\nWhether you are looking to delve deeper into the slides, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions to Byeong-Hak (@bcdanl) or your classmates or need clarification on any points, don‚Äôt hesitate to ask here.\nLet‚Äôs collaborate and learn from each other!\nPlease note that all our comments are recorded in here, regardless of whether comments are displayed in this page or not.\n\n\n\n Back to top"
  },
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Big & tiny insights through data",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nNBA\n\n\n3 min\n\n\n\nByeong-Hak Choe\n\n\nFebruary 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython Basics\n\n\n1 min\n\n\n\nByeong-Hak Choe\n\n\nFebruary 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeer Markets\n\n\n5 min\n\n\n\nByeong-Hak Choe\n\n\nNovember 2, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n1 min\n\n\n\nByeong-Hak Choe\n\n\nOctober 27, 2023\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "listing-danl-210-qa.html",
    "href": "listing-danl-210-qa.html",
    "title": "DANL 210 - Q & A",
    "section": "",
    "text": "Title\n\n\nSubtitle\n\n\nDate\n\n\n\n\n\n\nDANL 210 - Discussion and Q & A Board\n\n\nundefined\n\n\nJanuary 21, 2025\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-1",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\n10 == 20\n10 == '10'\n\nBoolean data have either True or False value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-2",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-2",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\n\n\n\n\n\n\n\n\nExisting booleans can be combined, which create a boolean when executed."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-3",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-3",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nConditions are expressions that evaluate as booleans."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-4",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-4",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nboolean_condition1 = 10 == 20\nprint(boolean_condition1)\n\nboolean_condition2 = 10 == '10'\nprint(boolean_condition2)\n\nThe == is an operator that compares the objects on either side and returns True if they have the same values\nQ. What does not (not True) evaluate to?\nQ. Classwork 4.2"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-5",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-5",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nname = \"Geneseo\"\nscore = 99\n\nif name == \"Geneseo\" and score &gt; 90:\n    print(\"Geneseo, you achieved a high score.\")\n\nif name == \"Geneseo\" or score &gt; 90:\n    print(\"You could be called Geneseo or have a high score\")\n\nif name != \"Geneseo\" and score &gt; 90:\n    print(\"You are not called Geneseo and you have a high score\")\n\nThe real power of conditions comes when we start to use them in more complex examples, such as if statements."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-6",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-6",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nname_list = [\"Lovelace\", \"Smith\", \"Hopper\", \"Babbage\"]\n\nprint(\"Lovelace\" in name_list)\n\nprint(\"Bob\" in name_list)\n\nOne of the most useful conditional keywords is in.\n\nThis one must pop up ten times a day in most coders‚Äô lives because it can pick out a variable or make sure something is where it‚Äôs supposed to be.\n\nQ. Check if ‚Äúa‚Äù is in the string ‚ÄúSun Devil Arena‚Äù using in. Is ‚Äúa‚Äù in ‚ÄúAnyone‚Äù?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-7",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-7",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nscore = 98\n\nif score == 100:\n    print(\"Top marks!\")\nelif score &gt; 90 and score &lt; 100:\n    print(\"High score!\")\nelif score &gt; 10 and score &lt;= 90:\n    pass\nelse:\n    print(\"Better luck next time.\")\n\nOne conditional construct we‚Äôre bound to use at some point, is the if-else chain:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-8",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-8",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nIndentation\n\nWe have seen that certain parts of the code examples are indented.\nCode that is part of a function, a conditional clause, or loop is indented.\nIndention is actually what tells the Python interpreter that some code is to be executed as part of, say, a loop and not to executed after the loop is finished."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-9",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#booleans-conditions-and-if-statements-9",
    "title": "Lecture 5",
    "section": "Booleans, Conditions, and if Statements",
    "text": "Booleans, Conditions, and if Statements\nIndentation\nx = 10\n\nif x &gt; 2:\n    print(\"x is greater than 2\")\n\nHere‚Äôs a basic example of indentation as part of an if statement.\nThe standard practice for indentation is that each sub-statement should be indented by 4 spaces."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\n\n\n\n\nWith slicing methods, we can get subset of the data object.\nSlicing methods can apply for strings, lists, arrays, and DataFrames.\nThe above example describes indexing in Python"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-1",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nStrings\nstring = \"cheesecake\"\nprint( string[-4:] )\n\nFrom strings, we can access the individual characters via slicing and indexing.\n\n\n\nstring = \"cheesecake\"\nprint(\"String has length:\")\nprint( len(string) )\n\nlist_of_numbers = range(1, 20)\nprint(\"List of numbers has length:\")\nprint( len(list_of_numbers) )\n\n\n\nBoth lists and strings will allow us to use the len() command to get their length:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-2",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-2",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nString-related Functions\nDot operation\n\nIn Python, we can access attributes by using a dot notation (.).\nUnlike len(), some functions use a dot to access to strings.\nTo use those string functions, type (1) the name of the string, (2) a dot, (3) the name of the function, and (4) any arguments that the function needs:\n\nstring_name.some_function(arguments)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-3",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-3",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nString-related Functions\nSplit with split()\n\nWe can use the built-in string split() function to break a string into a list of smaller strings based on some separator.\n\nIf we don‚Äôt specify a separator, split() uses any sequence of white space characters‚Äînewlines, spaces, and tabs:\n\ntasks = 'get gloves,get mask,give cat vitamins,call ambulance'\ntasks.split(',')\ntasks.split()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-4",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-4",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nString-related Functions\nCombine by Using join()\n\njoin() collapses a list of strings into a single string.\n\ncrypto_list = ['Yeti', 'Bigfoot', 'Loch Ness Monster']\ncrypto_string = ', '.join(crypto_list)\nprint('Found and signing book deals:', crypto_string)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-5",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-5",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nStrings and Slicing\n\nWe can extract a substring (a part of a string) from a string by using a slice.\nWe define a slice by using square brackets ([]), a start index, an end index, and an optional step count between them.\n\nWe can omit some of these.\n\nThe slice will include characters from index start to one before end:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-6",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-6",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nGet a Substring with a Slice\n\n[:][ start :][: end ][ start : end ][ start : end : step ]\n\n\nletters = 'abcdefghij'\nletters[:]\n\n[:] extracts the entire sequence from start to end.\n\n\n\nletters = 'abcdefghij'\nletters[4:]\nletters[2:]\nletters[-3:]\nletters[-50:]\n\n[ start :] specifies from the start index to the end.\n\n\n\nletters = 'abcdefghij'\nletters[:3]\nletters[:-3]\nletters[:70]\n\n[: end ] specifies from the beginning to the end index minus 1.\n\n\n\nletters = 'abcdefghij'\nletters[2:5]\nletters[-26:-24]\nletters[35:37]\n\n[ start : end ] indicates from the start index to the end index minus 1.\n\n\n\nletters = 'abcdefghij'\nletters[2 : 6 : 2]   # From index 2 to 5, by steps of 2 characters\nletters[ : : 3]     # From the start to the end, in steps of 3 characters\nletters[ 6 : : 4 ]    # From index 19 to the end, by 4\nletters[ : 7 : 5 ]    # From the start to index 6 by 5:\nletters[-1 : : -1 ]   # Starts at the end and ends at the start\nletters[: : -1 ]\n\n[ start : end : step ] extracts from the start index to the end index minus 1, skipping characters by step."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-7",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-7",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nLists\n\nPython is\n\na zero-indexed language (things start counting from zero);\nleft inclusive;\nright exclusive when we are specifying a range of values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-8",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-8",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nLists\nlist_example = ['one', 'two', 'three']\nlist_example[ 0 : 1 ]\nlist_example[ 1 : 3 ]\n\n\n\n\nWe can think of items in a list-like object as being fenced in.\n\nThe index represents the fence post."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-9",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-9",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\nLists\n\n[index]Slicing Methods\n\n\nGet an Item by [index]\nsuny = ['Geneseo', 'Brockport', 'Oswego', 'Binghamton', \n        'Stony Brook', 'New Paltz'] \n\nWe can extract a single value from a list by specifying its index:\n\n\n\nsuny[0]\nsuny[1]\nsuny[2]\nsuny[7]\n\nsuny[-1]\nsuny[-2]\nsuny[-3]\nsuny[-7]\n\n\n\n\nGet an Item with a Slice\n\nWe can extract a subsequence of a list by using a slice:\n\nsuny = ['Geneseo', 'Brockport', 'Oswego', 'Binghamton', \n        'Stony Brook', 'New Paltz'] \nsuny[0:2]    # A slice of a list is also a list.\n\n\nsuny[ : : 2]\nsuny[ : : -2]\nsuny[ : : -1]\n\nsuny[4 : ]\nsuny[-6 : ]\nsuny[-6 : -2]\nsuny[-6 : -4]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-11",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#slicing-methods-11",
    "title": "Lecture 5",
    "section": "Slicing Methods",
    "text": "Slicing Methods\n\nQ. Classwork 4.3"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#functions-arguments-and-parameters-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#functions-arguments-and-parameters-1",
    "title": "Lecture 5",
    "section": "Functions, Arguments, and Parameters",
    "text": "Functions, Arguments, and Parameters\nFunctions\nint(\"20\") \nfloat(\"14.3\")\nstr(5)\nint(\"xyz\")\n\nA function can take any number and type of input parameters and return any number and type of output results.\nPython ships with more than 65 built-in functions.\nPython also allows a user to define a new function.\nWe will mostly use built-in functions."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#functions-arguments-and-parameters-2",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#functions-arguments-and-parameters-2",
    "title": "Lecture 5",
    "section": "Functions, Arguments, and Parameters",
    "text": "Functions, Arguments, and Parameters\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\")\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\", sep = \"!\")\nprint(\"Cherry\", \"Strawberry\", \"Key Lime\", sep=\" \")\n\nWe invoke a function by entering its name and a pair of opening and closing parentheses.\nMuch as a cooking recipe can accept ingredients, a function invocation can accept inputs called arguments.\nWe pass arguments sequentially inside the parentheses (, separated by commas).\nA parameter is a name given to an expected function argument.\nA default argument is a fallback value that Python passes to a parameter if the function invocation does not explicitly provide one."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#functions-arguments-and-parameters-3",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#functions-arguments-and-parameters-3",
    "title": "Lecture 5",
    "section": "Functions, Arguments, and Parameters",
    "text": "Functions, Arguments, and Parameters\n\nQ. Classwork 4.4"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while",
    "title": "Lecture 5",
    "section": "Repeat with while",
    "text": "Repeat with while\n\n\ncount = 1        \nwhile count &lt;= 5:\n    print(count)\n    count += 1\n\n\nWe first assigned the value 1 to count.\nThe while loop compared the value of count to 5 and continued if count was less than or equal to 5.\nInside the loop, we printed the value of count and then incremented its value by one with the statement count += 1.\nPython goes back to the top of the loop, and again compares count with 5.\nThe value of count is now 2, so the contents of the while loop are again executed, and count is incremented to 3.\nThis continues until count is incremented from 5 to 6 at the bottom of the loop.\nOn the next trip to the top, count &lt;= 5 is now False, and the while loop ends."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while-1",
    "title": "Lecture 5",
    "section": "Repeat with while",
    "text": "Repeat with while\nAsking the user for input\n\n\nstuff = input()\n# Type something and press Return/Enter on Console \n# before running print(stuff)\nprint(stuff)\n\n\nSometimes we would like to take the value for a variable from the user via their keyboard.\n\nThe input() function gets input from the keyboard.\nWhen the input() is called, the program stops and waits for the user to type something on Console (interactive Python interpreter).\nWhen the user presses Return or Enter on Console, the program resumes and input returns what the user typed as a string."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while-2",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while-2",
    "title": "Lecture 5",
    "section": "Repeat with while",
    "text": "Repeat with while\nCancel with break\n\n\nwhile True:\n    user_input = input(\"Enter 'yes' to continue or 'no' to stop: \")\n    if user_input.lower() == 'no':\n        print(\"Exiting the loop. Goodbye!\")\n        break\n    elif user_input.lower() == 'yes':\n        print(\"You chose to continue.\")\n    else:\n        print(\"Invalid input, please enter 'yes' or 'no'.\")\n\n\nWhile loop is used to execute a block of code repeatedly until given boolean condition evaluated to False.\n\nwhile True loop will run forever unless we write it with a break statement.\n\nIf we want to loop until something occurs, but we‚Äôre not sure when that might happen, we can use an infinite loop with a break statement."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while-3",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while-3",
    "title": "Lecture 5",
    "section": "Repeat with while",
    "text": "Repeat with while\nSkip Ahead with continue\n\n\nwhile True:\n    value = input(\"Integer, please [q to quit]: \")\n    if value == 'q': # quit\n        break\n    number = int(value)\n    if number % 2 == 0: # an even number\n        continue\n    print(number, \"squared is\", number*number)\n\n\nSometimes, we don‚Äôt want to break out of a loop but just want to skip ahead to the next iteration for some reason.\nThe continue statement is used to skip the rest of the code inside a loop for the current iteration only."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while-4",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#repeat-with-while-4",
    "title": "Lecture 5",
    "section": "Repeat with while",
    "text": "Repeat with while\nCheck break Use with else\n\nWe can consider using while with else when we‚Äôve coded a while loop to check for something, and breaking as soon as it‚Äôs found. \n\nnumbers = [1, 3, 5]\nposition = 0\n\nwhile position &lt; len(numbers):\n    number = numbers[position]\n    if number &gt; 4:  # Condition changed to checking if the number is greater than 4\n        print('Found a number greater than 4:', number)\n        break\n    position += 1\nelse:  # break not called\n    print('No number greater than 4 found')\n\nConsider it a break checker."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\n\nSometimes we want to loop through a set of things such as a string of text, a list of words or a list of numbers.\n\nWhen we have a list of things to loop through, we can construct a for loop.\nA for loop makes it possible for you to traverse data structures without knowing how large they are or how they are implemented."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-1",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\n\nLet‚Äôs see two ways to walk through a string here:\n\n\n\nword = 'thud'\noffset = 0\nwhile offset &lt; len(word):\n    print(word[offset])\n    offset += 1\n\nword = 'thud'\nfor letter in word:\n    print(letter)\n\n\n\nWhich one do you prefer?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-2",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-2",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nCancel with break\nword = 'thud'\nfor letter in word:\n    if letter == 'u':\n        break\n    print(letter)\n\nA break in a for loop breaks out of the loop, as it does for a while loop:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-3",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-3",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nSkip with continue\nword = 'thud'\nfor letter in word:\n    if letter == 'u':\n        continue\n    print(letter)\n\nInserting a continue in a for loop jumps to the next iteration of the loop, as it does for a while loop."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-4",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-4",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nGenerate Number Sequences with range()\n\nThe range() function returns a stream of numbers within a specified range, without first having to create and store a large data structure such as a list or tuple.\n\nThis lets us create huge ranges without using all the memory in our computers and crashing our program.\nrange() returns an iterable object, so we need to step through the values with for ‚Ä¶ in, or convert the object to a sequence like a list."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-5",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-5",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nfor ‚Ä¶ in range()\n\n\nfor x in range(0, 3):\n    print(x)\nlist( range(0, 3) )\n\n\nWe use range() similar to how we use slices: range( start, stop, step ).\n\nIf we omit start, the range begins at 0.\nThe only required value is stop; as with slices, the last value created will be just before stop.\nThe default value of step is 1, but we can change it."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-6",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#iterate-with-for-and-in-6",
    "title": "Lecture 5",
    "section": "Iterate with for and in",
    "text": "Iterate with for and in\nCheck break Use with else\n\nSimilar to while, for has an optional else that checks whether the for completed normally.\n\nIf break was not called, the else statement is run.\n\n\nword = 'thud'\nfor letter in word:\n    if letter == 'x':\n        print(\"Eek! An 'x'!\")\n        break\n    print(letter)\nelse:\n    print(\"No 'x' in there.\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#loop-with-while-and-for-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#loop-with-while-and-for-1",
    "title": "Lecture 5",
    "section": "Loop with while and for",
    "text": "Loop with while and for\nClass Exercises\n\nQ. Classwork 4.5\nQ. Classwork 4.6"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-1",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nException handlers"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-2",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-2",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nException handlers\n\nIn some languages, errors are indicated by special function return values.\n\nPython uses exceptions: code that is executed when an associated error occurs.\n\nWhen we run code that might fail under some circumstances, we also need appropriate exception handlers to intercept any potential errors.\n\nAccessing a list or tuple with an out-of-range position, or a dictionary with a nonexistent key."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-3",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-3",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nErrors\nshort_list = [1, 2, 3]\nposition = 5\nshort_list[position]\n\nIf we don‚Äôt provide your own exception handler, Python prints an error message and some information about where the error occurred and then terminates the program:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-4",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-4",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nshort_list = [1, 2, 3]\nposition = 5\n\ntry:\n    short_list[position]\nexcept:\n    print('Need a position between 0 and', len(short_list)-1, ' but got',\n    position)\n\nRather than leaving things to chance, use try to wrap your code, and except to provide the error handling:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-5",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-5",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nshort_list = [1, 2, 3]\nposition = 5\ntry:\n    short_list[position]\nexcept:\n    print('Need a position between 0 and', len(short_list)-1, ' but got',\n    position)\n\nThe code inside the try block is run.\n\nIf there is an error, an exception is raised and the code inside the except block runs.\n\nIf there are no errors, the except block is skipped."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-6",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-6",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\n\nSpecifying a plain except with no arguments, as we did here, is a catchall for any exception type.\nIf more than one type of exception could occur, it‚Äôs best to provide a separate exception handler for each.\nWe get the full exception object in the variable name if we use the form:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-7",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-7",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\nshort_list = [1, 2, 3]\nwhile True:\n    value = input('Position [q to quit]? ')\n    if value == 'q':\n        break\n    try:\n        position = int(value)\n        print(short_list[position])\n    except IndexError as err:\n        print('Bad index:', position, '-', err)\n    except Exception as other:\n        print('Something else broke:', other)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-8",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-8",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nexcept type\n\nThe example looks for an IndexError first, because that‚Äôs the exception type raised when we provide an illegal position to a sequence.\nIt saves an IndexError exception in the variable err, and any other exception in the variable other.\nThe example prints everything stored in other to show what you get in that object.\n\nInputting position 3 raised an IndexError as expected.\nEntering two annoyed the int() function, which we handled in our second, catchall except code."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-9",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#handle-errors-with-try-and-except-9",
    "title": "Lecture 5",
    "section": "Handle Errors with try and except",
    "text": "Handle Errors with try and except\nClass Exercises\n\nQ. Classwork 4.7"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-1",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\npandas\n\n\n\n\npandas provides Series and DataFrames which are used to store data in an easy-to-use format."
  },
  {
    "objectID": "danl-lec/danl-210-lec-04-2025-0131.html#google-colab-settings",
    "href": "danl-lec/danl-210-lec-04-2025-0131.html#google-colab-settings",
    "title": "Lecture 4",
    "section": "Google Colab Settings",
    "text": "Google Colab Settings\nTurn off AI Assistance\n\nOn Google Colab\n\nFrom the top-right corner, click ‚öôÔ∏è\nClick ‚ÄúAI Assistance‚Äù from the side menu.\nDisable all options."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#modifying-a-list",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#modifying-a-list",
    "title": "Lecture 5",
    "section": "Modifying a List",
    "text": "Modifying a List\nAdding Items\n\nappend(): Adds an item to the end of the list.\n\nmy_list = [1, 2, 3]\nmy_list.append(4)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#modifying-a-list-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#modifying-a-list-1",
    "title": "Lecture 5",
    "section": "Modifying a List",
    "text": "Modifying a List\nDeleting Items\n\nremove(): Deletes the first occurrence of value in the list.\n\nmy_list = [1, 2, 3, 4, 2]\nmy_list.remove(2)\n\nList Comprehension: Removes items based on a condition.\n\nmy_list = [1, 2, 3, 4, 2]\nmy_list = [x for x in my_list if x != 2]  \n\ndel statement: Deletes an item by index or a slice of items.\n\nmy_list = [1, 2, 3, 4]\ndel my_list[1] \ndel my_list[1:3]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#modifying-a-dictionary",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#modifying-a-dictionary",
    "title": "Lecture 5",
    "section": "Modifying a Dictionary",
    "text": "Modifying a Dictionary\nAdding/Updating Items\n\nupdate(): Adds new key-value pairs or updates existing ones.\n\nmy_dict = {'a': 1, 'b': 2}\nmy_dict.update({'c': 3})  \nmy_dict.update({'a': 10})"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#modifying-a-dictionary-1",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#modifying-a-dictionary-1",
    "title": "Lecture 5",
    "section": "Modifying a Dictionary",
    "text": "Modifying a Dictionary\nDeleting Items\n\nDictionary Comprehension: Removes items based on a condition.\n\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\nmy_dict = {k: v for k, v in my_dict.items() if v != 2}  \n\ndel statement: Deletes an item by key.\n\nmy_dict = {'a': 1, 'b': 2, 'c': 3}\ndel my_dict['b']"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#list-comprehension",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#list-comprehension",
    "title": "Lecture 5",
    "section": "List Comprehension",
    "text": "List Comprehension\nWhat is List Comprehension?\n\nA concise way to create or modify lists.\nSyntax: [expression for item in iterable if condition]\n\n\nCreating a List of Squares:\n\nsquares = [x**2 for x in range(5)]\n\nFiltering Items:\n\nnumbers = [1, 2, 3, 4, 5, 6]\nevens = [x for x in numbers if x != 2]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#dictionary-comprehension",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#dictionary-comprehension",
    "title": "Lecture 5",
    "section": "Dictionary Comprehension",
    "text": "Dictionary Comprehension\nWhat is Dictionary Comprehension?\n\nA concise way to create or modify dictionaries.\nSyntax: {key_expression: value_expression for item in iterable if condition}\n\n\nCreating a Dictionary of Squares:\n\nsquares_dict = {x: x**2 for x in range(5)}\n\nFiltering Dictionary Items:\n\n   my_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n   filtered_dict = {k: v for k, v in my_dict.items() if v != 2}\n\nSwapping Keys and Values:\n\noriginal_dict = {'a': 1, 'b': 2, 'c': 3}\nswapped_dict = {v: k for k, v in original_dict.items()}"
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html",
    "href": "danl-hw/danl-210-hw-01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Please submit your Jupyter Notebook for Part 3 in Homework 1 to Brightspace with the name below:\n\ndanl-210-hw1-LASTNAME-FIRSTNAME.ipynb\n( e.g., danl-210-hw1-choe-byeonghak.ipynb )\n\nThe due is February 17, 2025, 10:30 A.M.\nPlease send Byeong-Hak an email (bchoe@geneseo.edu) if you have any questions."
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-0.",
    "href": "danl-hw/danl-210-hw-01.html#question-0.",
    "title": "Homework 1",
    "section": "Question 0.",
    "text": "Question 0.\nProvide your GitHub username.\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-1",
    "href": "danl-hw/danl-210-hw-01.html#question-1",
    "title": "Homework 1",
    "section": "Question 1",
    "text": "Question 1\n\nQ1a\n\nCreate a list of integers from 1 to 10.\nAppend the number 11 to the list and remove the number 5.\n\n\n\n\nQ1b\n\nConsider the following dictionary of three employees and their salaries:\n\ndict_salaries = {'Alice': 50000, 'Bob': 60000, 'Charlie': 70000}\n\nAdd a new employee 'Dana' with a salary of 65000.\nUpdate 'Alice'‚Äôs salary to 55000.\nPrint all employee names and their salaries."
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-2",
    "href": "danl-hw/danl-210-hw-01.html#question-2",
    "title": "Homework 1",
    "section": "Question 2",
    "text": "Question 2\n\nQ2a\n\nAssign a variable salary to 75000.\nUse an if-elif-else statement to print:\n\n'Low' if salary is less than 50,000\n'Medium' if salary is between 50,000 and 99,999\n'High' if salary is 100,000 or more\n\n\n\n\n\nQ2b\n\nAssign two variables, role and salary, to 'Manager' and 85000, respectively.\nUse nested if-else statements to print:\n\n'Eligible for bonus' if the role is 'Manager' and the salary is greater than 80,000.\n'Eligible for raise' if the role is 'Analyst' and the salary is less than 60,000.\n'No action needed' for all other cases."
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-3",
    "href": "danl-hw/danl-210-hw-01.html#question-3",
    "title": "Homework 1",
    "section": "Question 3",
    "text": "Question 3\n\nQ3a\n\nConsider the following list of salaries:\n\nlist_salaries = [45000, 60000, 75000, 120000, 30000]\n\nCalculate the average salary.\nUse a for loop to print whether each salary is 'Above Average' or 'Below Average'.\n\n\n\n\nQ3b\n\nStart with a salary of 50000.\nUse a while loop to increase the salary by 5000 each year until it exceeds 80000.\nPrint the salary after each increment.\n\n\n\n\nQ3c\n\nConsider the following dictionary of employee salaries:\n\nsalaries = {'Alice': 50000, 'Bob': 60000, 'Charlie': 70000, 'Dana': 45000}\n\nUse a for loop to print the names of employees who earn more than 55000.\n\n\n\n\nQ3d\ndata_list = [42, 3.14, 'Data Analytics', True, None, [1, 2, 3], {'key': 'value'}, (4, 5)]\n\nGiven the list above, print the data type of each element using the type() function in a for loop. In the loop:\n\nConvert the integer 42 to a string.\nConvert the float 3.14 to a string, then back to a float.\nConvert the boolean True to an integer."
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-4",
    "href": "danl-hw/danl-210-hw-01.html#question-4",
    "title": "Homework 1",
    "section": "Question 4",
    "text": "Question 4\n\nQ4a\nConsider the variables a and b:\na = 10\nb = 0\n\nUse a try-except block to print the result of a / b.\n\nIf there is an error, print 'Cannot divide by zero!'.\n\n\n\n\n\nQ4b\n\nConsider the following dictionary of salaries with some missing (None) values:\n\nsalaries = {'Alice': 50000, 'Bob': None, 'Charlie': 70000, 'Dana': None, 'Eve': 80000}\n\nUse a for loop with a try-except block to calculate the total of non-missing salaries."
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-5",
    "href": "danl-hw/danl-210-hw-01.html#question-5",
    "title": "Homework 1",
    "section": "Question 5",
    "text": "Question 5\n\nImport the math library and calculate the square root of 81 using the sqrt() function provided by the math library."
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-6",
    "href": "danl-hw/danl-210-hw-01.html#question-6",
    "title": "Homework 1",
    "section": "Question 6",
    "text": "Question 6\n\nImport the math library and calculate the square root of 81 using the sqrt() function provided by the math library."
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-7",
    "href": "danl-hw/danl-210-hw-01.html#question-7",
    "title": "Homework 1",
    "section": "Question 7",
    "text": "Question 7\n\nWrite a Python code to import the sqrt() function from the math module.\nAfter importing sqrt(), how do you use it to find the square root of 16?\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#question-0",
    "href": "danl-hw/danl-210-hw-01.html#question-0",
    "title": "Homework 1",
    "section": "Question 0",
    "text": "Question 0\nProvide your GitHub username."
  },
  {
    "objectID": "danl-hw/danl-210-hw-01.html#quesiton-6",
    "href": "danl-hw/danl-210-hw-01.html#quesiton-6",
    "title": "Homework 1",
    "section": "Quesiton 6",
    "text": "Quesiton 6\n\nImport the math library and calculate the square root of 81 using the sqrt() function, which is provided by the math library."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-2",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-2",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nnumpy\n\n\n\n\nnumpy, numerical Python, provides the array block (np.array()) for doing fast and efficient computations;"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-3",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-3",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nmatplotlib and seaborn\n\n\n\n\nmatplotlib provides graphics. The most important submodule would be matplotlib.pyplot.\nseaborn provides a general improvement in the default appearance of matplotlib-produced plots."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-4",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-4",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nimport statement\n\nA module is basically a bunch of related codes saved in a file with the extension .py.\nA package is basically a directory of a collection of modules.\nA library is a collection of packages\nWe refer to code of other module/package/library by using the Python import statement.\n\nimport LIBRARY_NAME\n\nThis makes the code and variables in the imported module available to our programming codes."
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-5",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-5",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\nimport statement\n\n\nas\n\nWe can use the as keyword when importing the module/package/library using its canonical names.\n\nimport LIBRARY as SOMETHING_SHORT\n\nfrom\n\nWe can use the from keyword when specifying Python module/package/library from which we want to import something.\n\nfrom LIBRARY import FUNCTION, PACKAGE, MODULE"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-6",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries-6",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\n\nWe can use the as keyword when importing the module/package/library using its canonical names.\n\nimport LIBRARY/MODULE as SOMETHING_SHORT\n\nWe can use the from keyword when specifying Python module/package/library from which we want to import something.\n\nfrom LIBRARY import FUNCTION/PACKAGE/MODULE\n\nTo install a library LIBRARY on your Google Colab or Anaconda Python, run:\n\npip install LIBRARY\n\nQ. Classwork 4.8"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#python-basics",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#python-basics",
    "title": "Lecture 5",
    "section": "Python Basics",
    "text": "Python Basics\nInstalling Modules, Packages, and Libraries\nTo install a module module_name on your Anaconda Python, open your Anaconda Prompt or Terminal and run:\npip install module_name\nTo install a module module_name on your Google Colab, run:\n!pip install module_name\n\nQ. Classwork 4.8"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#importing-modules-packages-and-libraries",
    "title": "Lecture 5",
    "section": "Importing Modules, Packages, and Libraries",
    "text": "Importing Modules, Packages, and Libraries\n\nPython is a general-purpose programming language and is not specialized for numerical or statistical computation.\nThe core libraries that enable Python to store and analyze data efficiently are:\n\npandas\nnumpy\nmatplotlib and seaborn"
  },
  {
    "objectID": "danl-lec/danl-210-lec-05-2025-0203.html#installing-modules-packages-and-libraries",
    "href": "danl-lec/danl-210-lec-05-2025-0203.html#installing-modules-packages-and-libraries",
    "title": "Lecture 5",
    "section": "Installing Modules, Packages, and Libraries",
    "text": "Installing Modules, Packages, and Libraries\npip tool\n\n\n\nTo install a library LIBRARY on your Google Colab, run:\n\n!pip install LIBRARY\n\n\nTo install a library LIBRARY on your Anaconda Python, open your Spyder IDE, Anaconda Prompt, or Terminal and run:\n\npip install LIBRARY\n\n\n\nQ. Classwork 4.8"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#workflow-for-file-management-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#workflow-for-file-management-1",
    "title": "Lecture 6",
    "section": "Workflow for File Management",
    "text": "Workflow for File Management\n\nSave your Jupyter Notebook for each class to a dedicated directory in your local laptop, Google Drive, or a new GitHub repo.\n\nGo to File and select Save ‚Ä¶/ ( e.g., danl-210-lec-08-2025-0210.ipynb)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#workflow-for-file-management-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#workflow-for-file-management-2",
    "title": "Lecture 6",
    "section": "Workflow for File Management",
    "text": "Workflow for File Management\nYour Personal Website\n\nIn your local website project directory, avoid having\n\nAny file that exceeds 30 MB in size;\n.ipynb files you do not use for your website.\n\nYour website project directory should include files specifically dedicated to your website."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#workflow-for-file-management-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#workflow-for-file-management-3",
    "title": "Lecture 6",
    "section": "Workflow for File Management",
    "text": "Workflow for File Management\nJupyter Notebooks for Your Webpage\n\nRun Python code cells in a Jupyter Notebook (.ipynb) on Google Colab. Then, download the Jupyter Notebook from Google Colab.\nUse the Finder/File Explorer to move the Jupyter Notebook file (.ipynb) to your website project directory. (If it is for a blog post, create a subdirectory in the posts directory, and move it to the subdirectory.)\nEdit _quarto.yml properly. Save the changes by clicking the floppy disk icon (üíæ).\nOn Terminal, run quarto render.\nOnce quarto render completes, view the index.html in your website working directory to see the HTML output.\nAfter confirming the HTML output, use the 3-step git commands (add-commit-push) on Terminal to update your online website."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-1",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLearning Objectives\n\nDealing with Missing Values\nDealing wit Duplicates\nReshaping DataFrames with .melt() and .pivot()\nJoining DataFrames with .merge()\nConcatenating DataFrames"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-2",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLearning Objectives\n\nDealing with Missing Values\nDealing wit Duplicates\nReshaping DataFrames with .melt() and .pivot()\nJoining DataFrames with .merge()\nConcatenating DataFrames"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-3",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 1-3 in Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-4",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-4",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMethod Chaining\n(\n    nba\n    .sort_values(['Salary'])\n    .head(5)\n)\n\n\nDataFrame has various methods that modify the existing DataFrame.\nMethod Chaining: We can call methods sequentially without the need to store intermediate results."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-5",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-5",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 4-7 in Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-6",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-6",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Question 1 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-7",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-7",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 2-6 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-8",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-8",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-9",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-9",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDataFrame Terminologies: Variables, Observations, and Values\n\n\n\n\nEach variable is a column.\nEach observation is a row.\nEach value is a cell."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-10",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-10",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDataFrame Terminologies: Dot Operators, Methods and Attributes\n\nThe dot operator (DataFrame.) is used for an attribute or a method on objects.\nA method (DataFrame.method()) is a function that we can call on a DataFrame to perform operations, modify data, or derive insights.\n\ne.g., nba.info()\n\nAn attribute (DataFrame.attribute) is a property that provides information about the DataFrame‚Äôs structure or content without modifying it.\n\ne.g., nba.dtype"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-11",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-11",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nGetting a Summary of a DataFrame with .info()\n\n\nnba.info()    # method\n\nnba.shape     # attribute\nnba.dtypes    # attribute\nnba.columns   # attribute\nnba.count()   # method\n\n\n\nEvery DataFrame object has a .info() method that provides a summary of a DataFrame:\n\nVariable names (.columns)\nNumber of variables/observations (.shape)\nData type of each variable (.dtypes)\nNumber of non-missing values in each variable (.count())\n\nPandas often displays missing values as NaN."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-12",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-12",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nGetting a Summary of a DataFrame with .describe()\nnba.describe()\nnba.describe(include='all')\n\n.describe() method generates descriptive statistics that summarize the central tendency, dispersion, and distribution of each variable.\n\nIt can also process string-type variables if specified explicitly (include='all')."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-13",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-13",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSelecting a Variable by its Name\nnba_player_name_1 = nba['Name']   # Series\nnba_player_name_1\n\nnba_player_name_2 = nba[ ['Name'] ]   # DataFrame\nnba_player_name_2\n\nIf we want only a specific variable from a DataFrame, we can access the variable with its name using squared brackets, [ ].\n\nDataFrame[ 'var_1' ]\nDataFrame[ ['var_1'] ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-14",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-14",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSelecting Multiple Variables by their Names\nnba_player_name_team = nba[ ['Name', 'Team'] ]\nnba_player_name_team\n\nIn order to specify multiple variables by their names, we need to pass in a Python list between the square brackets.\n\nDataFrame[ ['var_1', 'var_2', ... ] ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-15",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-15",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSelecting Multiple Variables with select_dtypes()\n# To include only string variables\nnba.select_dtypes(include = \"object\")\n\n# To exclude string and integer variables\nnba.select_dtypes(exclude = [\"object\", \"int\"])\n\nWe can use the select_dtypes() method to select columns based on their data types.\n\nThe method accepts two parameters, include and exclude."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-16",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-16",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nCounting with .count()\n\n\nnba['Salary'].count()\nnba[['Salary']].count()\n\n\n\nThe .count() counts the number of non-missing values in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-17",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-17",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nCounting with .value_counts()\n\n\nnba['Team'].value_counts()\n\nnba[['Team']].value_counts()\n\n\n\nThe .value_counts() counts the number of occurrences of each unique value in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-18",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-18",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nCounting with .nunique()\n\n\nnba[['Team']].nunique()\n\nnba.nunique()\n\n\n\nThe .nunique() counts the number of unique values in each variable in a DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#advanced-pandas",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#advanced-pandas",
    "title": "Lecture 6",
    "section": "Advanced Pandas",
    "text": "Advanced Pandas\n\nGroup Operations with groupby()\nVisualizing DataFrames with seaborn"
  },
  {
    "objectID": "danl-cw/danl-210-cw-05.html",
    "href": "danl-cw/danl-210-cw-05.html",
    "title": "Classwork 5",
    "section": "",
    "text": "Direction\n\n\n\nThe nfl.csv file (with its pathname https://bcdanl.github.io/data/nfl.csv) contains a list of players in the National Football League with similar Name, Team, Position, Birthday, and Salary variables in the nba.csv file.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 1\n\nHow can we read the nfl.csv file, and assign it to a DataFrame object, nfl?\nWhat is an effective way to convert the values in its Birthday variable to datetimes?\n\nAnswer:\n\n\n\nQuestion 2\n\nHow many observations are in nfl?\nWhat are the mean, median, standard deviation, minimum, and maximum of Salary in nfl?\n\nAnswer:\n\n\n\nQuestion 3\n\nHow can we count the number of players per team in nfl?\nHow many unique teams are in nfl?\n\nAnswer:\n\n\n\nQuestion 4\n\nWho are the five highest-paid players?\nWho is the oldest player?\n\nAnswer:\n\n\n\nQuestion 5\nHow can we sort the DataFrame first by Team in alphabetical order and then by Salary in descending order?\nAnswer:\n\n\n\nQuestion 6\nHow do we set the player names as the DataFrame index?\nAnswer:\n\n\n\nQuestion 7\nWho is the oldest player on the Kansas City Chiefs roster, and what is his birthday?\nAnswer:\n\n\n\nDiscussion\nWelcome to our Classwork 5 Discussion Board! üëã \nThis space is designed for you to engage with your classmates about the material covered in Classwork 5.\nWhether you are looking to delve deeper into the content, share insights, or have questions about the content, this is the perfect place for you.\nIf you have any specific questions for Byeong-Hak (@bcdanl) regarding the Classwork 5 materials or need clarification on any points, don‚Äôt hesitate to ask here.\nAll comments will be stored here.\nLet‚Äôs collaborate and learn from each other!\n\n\n\n\n Back to top"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-19",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-19",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 1-3 in Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-20",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-20",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\n\n\nLet‚Äôs read nba.csv as nba.\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])\n                  \n# Below is to view the nba DataFrame and to get a summary of it\nnba\nnba.info()\nnba.describe( include=\"all\" )"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-21",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-21",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with sort_values()\n# The two lines below are equivalent\nnba.sort_values([\"Name\"])\nnba.sort_values(by = [\"Name\"])\n\n\nThe sort_values() method‚Äôs first parameter, by, accepts the variables that pandas should use to sort the DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-22",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-22",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with sort_values()\nnba.sort_values([\"Name\"], ascending = False)\n\n\nThe sort_values() method‚Äôs ascending parameter determines the sort order.\n\nascending has a default argument of True.\nBy default, pandas will sort:\n\nA variable of numbers in increasing order;\nA variable of strings in alphabetical order;\nA variable of datetimes in chronological order."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-23",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-23",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMethod Chaining\n(\n    nba\n    .sort_values(['Salary'])\n    .head(5)\n)\n\n\nDataFrame has various methods that modify the existing DataFrame.\nMethod Chaining: We can call methods sequentially without the need to store intermediate results."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-24",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-24",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(5, 'Salary')\nnba.nlargest(5, 'Salary')\n\nnsmallest() are useful to get the first n observations ordered by a variable in ascending order.\nnlargest() are useful to get the first n observations ordered by a variable in descending order."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-25",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-25",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(4, 'Salary', keep = \"all\")\nnba.nlargest(4, 'Salary', keep = \"all\")\n\nkeep = \"all\" keeps all duplicates, even it means selecting more than n observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-26",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-26",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values([\"Team\", \"Name\"])\nnba.sort_values(by = [\"Team\", \"Name\"])\n\nWe can sort a DataFrame by multiple columns by passing a list to the by parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-27",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-27",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = False)\n\nWe can pass a single Boolean to the ascending parameter to apply the same sort order to each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-28",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-28",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = [False, True])\n\nIf we want to sort each variable in a different order, we can pass a Boolean list to the ascending parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-29",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-29",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Multiple Variables with sort_values()\nQ. Which players on each team are paid the most?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-30",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-30",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSorting by Row Index with sort_index()\n\n\n# Below lines are equivalent\nnba.sort_index()\nnba.sort_index(ascending = True)\n\nnba.sort_index(ascending = False)\n\n\n\nHow can we return it to its original form of DataFrame?\nOur nba DataFrame still has its numeric index labels.\nsort_index() sorts observations by their index labels (row names)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-31",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-31",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nChanging the Order of Variables with sort_index()\n# The two lines below are equivalent\nnba.sort_index(axis = \"columns\")\nnba.sort_index(axis = 1)\n\nThe sort_index() method can also be used to change the order of variables in an alphabetical order.\n\nWe need to add an axis parameter and pass it an argument of \"columns\" or 1."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-32",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-32",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSetting a New Index\n\nWe can use the set_index() method when we want to change the current index of a DataFrame to one or more existing columns.\n\nThis is particularly useful when:\n\nWe have a column that uniquely identifies each observation (e.g., ID);\nWe sometimes want to use an unique identifier as the index for more efficient data wrangling."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-33",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-33",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nSetting a New Index with set_index()\n# The two lines below are equivalent\nnba.set_index(keys = \"Name\")\nnba.set_index(\"Name\")\n\nThe set_index() method returns a new DataFrame with a given column set as the index.\n\nIts first parameter, keys, accepts the column name."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-34",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-34",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRe-setting an Index with reset_index()\nnba2 = nba.set_index(\"Name\")\nnba2.reset_index(inplace=True)    # Useful for the method chaining\n\nWe use the reset_index() method:\n\nWhen we want to convert the index back into a DataFrame column;\nWhen we need to reset the index to the default integer index.\n\nNote: With inplace=True, the operation alters the original DataFrame directly."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-35",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-35",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\n\n\nLet‚Äôs read nba.csv as nba.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-36",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-36",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations/Values\n\nWe can extract observations, variables, and values from a DataFrame by using the loc[] and iloc[] accessors.\n\nThese accessors work well when we know the index labels and positions of the observations/variables we want to target."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-37",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-37",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations by .loc[ Index Labels ]\n\n\nLet‚Äôs consider the nba with the Name index.\n\n# The two lines below are equivalent\nnba = nba.set_index(\"Name\")\nnba.set_index(\"Name\", inplace = True)\n\nBelow extracts observations:\n\n\nnba.loc[ \"LeBron James\" ]\nnba.loc[ [\"Kawhi Leonard\", \"Paul George\"] ]\n\nThe .loc attribute extracts an observation by index label (row name)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-38",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-38",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations by .loc[ Index Labels ]\n(\n    nba\n    .sort_index()\n    .loc[\"Otto Porter\":\"Patrick Beverley\"]\n)\n\nWhat is the above code doing?\n\nNote: Both the starting value and the ending value are inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-39",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-39",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations by .loc[ Index Labels ]\n\n\n(\n    nba\n    .sort_index()\n    .loc[\"Zach Collins\":]\n)\n\n(\n    nba\n    .sort_index()\n    .loc[:\"Al Horford\"]\n)\n\n\n\nWe can use loc[:] to pull rows:\n\nFrom the middle of the DataFrame to its end;\nFrom the beginning of the DataFrame to a specific index label."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-40",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-40",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Observations by .iloc[ Index Positions ]\n\n\nnba.iloc[ 300 ]\nnba.iloc[ [100, 200, 300, 400] ]\n\nnba.iloc[400:404]\nnba.iloc[:2]\nnba.iloc[447:]\nnba.iloc[-10:-6]\nnba.iloc[0:10:2] # every other rows\n\n\n\nThe .iloc (index location) attribute locates rows by index position.\n\nThis can be helpful when the position of rows has significance in our data set.\nWe pass integers.\n\nThe .iloc[:] is similar to the slicing syntax with strings/lists.\n\nThe end value is NOT inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-41",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-41",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-42",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-42",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.loc[\n    \"LeBron James\",\n    \"Team\"\n]\n\nnba.loc[\n     \"James Harden\", \n      [\"Position\", \"Birthday\"] \n]\n\nnba.loc[\n    [\"Russell Westbrook\", \"Anthony Davis\"],\n     [\"Team\", \"Salary\"]\n]\n\nnba.loc[\n    \"Joel Embiid\", \n    \"Position\":\"Salary\"\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .loc, we have to provide the column names."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-43",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-43",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLocating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.iloc[\n    57, \n    3\n]\n\nnba.iloc[\n    100:104, \n    :3\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .iloc, we have to provide the column position."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-44",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-44",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMathematical Operations\nnba.max()\nnba.min()\n\nThe max() method returns a Series with the maximum value from each variable.\nThe min() method returns a Series with the minimum value from each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-45",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-45",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMathematical Operations\n\n\nnba.sum()\nnba.mean()\nnba.median()\nnba.quantile(0.75) # 0 to 1\nnba.std()\n\nnba.sum(numeric_only = True)\nnba.mean(numeric_only = True)\nnba.median(numeric_only = True)\nnba.quantile(0.75, numeric_only=True)\nnba.std(numeric_only = True)\n\n\n\nThe sum()/mean()/median() method returns a Series with the sum/mean/median of the values in each variable.\nThe quantile() method returns a Series with the percentile value of the values in each variable (e.g., 25th, 75th, 90th percentile).\nThe std() method returns a Series with the standard deviation of the values in each variable.\nTo limit the operation to numeric volumes, we can pass True to the sum()/mean()/median()/std() method‚Äôs numeric_only parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-46",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-46",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nVectorized Operations\nnba[\"Salary_2x\"] = nba[\"Salary\"] + nba[\"Salary\"]\nnba[\"Name_w_Position\"] = nba[\"Name\"] + \" (\" + nba[\"Position\"] + \")\"\nnba[\"Salary_minus_Mean\"] = nba[\"Salary\"] - nba[\"Salary\"].mean()\n\npandas performs a vectorized operation on Series or a variable in DataFrame.\n\nThis means an element-by-element operation.\nThis enables us to apply functions and perform operations on the data efficiently, without the need for explicit loops."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-47",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-47",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRenaming Variables with nba.columns\n\n\nDo you recall the .columns attribute?\n\nnba.columns\n\nWe can rename any or all of a DataFrame‚Äôs columns by assigning a list of new names to the attribute:\n\nnba.columns = [\"Team\", \"Position\", \"Date of Birth\", \"Income\"]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-48",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-48",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRenaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )\nnba.rename( columns = { \"Date of Birth\": \"Birthday\" } )\n\nThe above rename() method renames the variable Date of Birth to Birthday."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-49",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-49",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRenaming rows with rename( index = { \"Existing One\" : \"New One\" } )\nnba = nba.rename(\n    index = { \"LeBron James\": \"LeBron Raymone James\" }\n)\n\nThe above rename() method renames the observation LeBron James to LeBron Raymone James."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-50",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-50",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nAdding and Removing Variables\n\n\nHere we use [] to add variables:\n\nnba['Salary_k'] = nba['Salary'] / 1000\nnba['Salary_2x'] = nba['Salary'] + nba['Salary']\nnba['Salary_3x'] = nba['Salary'] * 3"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-51",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-51",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRemoving Variables with drop(columns = ... )\n\n\nWe can use .drop(columns = ...) to drop variables:\n\nnba.drop(columns = \"Salary_k\")\nnba.drop(columns = [\"Salary_2x\", \"Salary_3x\"])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-52",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-52",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nRelocating Variables with .columns.get_loc(), .pop(), and .insert()\nref_var = nba.columns.get_loc('Team') \nvar_to_move = nba.pop('Salary')\nnba.insert(ref_var, 'Salary', var_to_move) # insert() directly alters 'nba'\n\nStep 1. DataFrame.columns.get_loc('Reference_Var')\n\nGet the integer position (right before the reference variable, ‚ÄòReference_Var‚Äô)\n\nStep 2. DataFrame.pop('Some_Var_To_Move')\n\nRemove the variable we want to relocate from the DataFrame and store it in a Series\n\nStep 3. DataFrame.insert(ref_var, 'Some_Var_To_Move', var_to_move)\n\nInsert the variable back into the DataFrame right after the reference variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-53",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-53",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-54",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-54",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\n\n\nWhat values are in the Mgmt variable?\n\n\nemp[\"Mgmt\"].astype(bool)\n\nThe astype() method converts a Series‚Äô values to a different data type.\n\nIt can accept a single argument: the new data type."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-55",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-55",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Mgmt\"] = emp[\"Mgmt\"].astype(bool)\n\nThe above code overwrites the Mgmt variable with our new Series of Booleans."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-56",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-56",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Salary\"].astype(int)\n\nThe above code tries to coerce the Salary variable‚Äôs values to integers with the astype() method.\n\nPandas is unable to convert the NaN values to integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-57",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-57",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFill Missing Values with the fillna() method\nemp[\"Salary\"].fillna(0)\n\nThe fillna() method replaces a Series‚Äô missing values with the argument we pass in.\nThe above example provides a fill value of 0.\n\nNote that our choice of value can distort the data; 0 is passed solely for the sake of example."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-58",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-58",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFill Missing Values with the fillna() method\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0).astype(int)\n\nThe above code overwrites the Salary variable with our new Series of integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-59",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-59",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n\nPandas includes a special data type called a category,\n\nIt is ideal for a variable consisting of a small number of unique values relative to its total size.\nE.g., gender, weekdays, blood types, planets, and income groups."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-60",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-60",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the pd.to_datetime() method\n# Below two are equivalent:\nemp[\"Start Date\"] = pd.to_datetime(emp[\"Start Date\"])\nemp[\"Start Date\"] = emp[\"Start Date\"].astype('datetime64')\n\nThe pd.to_datetime() function is used to convert a Series, DataFrame, or a single variable of a DataFrame from its current data type into datetime format."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-61",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-61",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nConverting Data Types with the astype() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\n\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0)\nemp = emp.astype({'Mgmt': 'bool', \n                  'Salary': 'int',\n                  'Gender': 'category',\n                  'Start Date': 'datetime64'})\n\nWe can provide a dictionary of variable-type pairs to astype()."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-62",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-62",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Question 1 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-63",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-63",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-64",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-64",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with ‚ÄúDonna‚Äù.\n\npandas performs a vectorized operation (element-by-element operation) on Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-65",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-65",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-66",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-66",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[ donnas ]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-67",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-67",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\n\n\nWhat if we want to extract a subset of employees who are not on the ‚ÄúMarketing‚Äù team?\n\n\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not ‚ÄúMarketing‚Äù, and False indicates the Team value is ‚ÄúMarketing‚Äù"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-68",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-68",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\n\n\nWhat if we want to retrieve all the managers in the company?\n\nManagers have a value of True in the Mgmt variable.\n\n\n\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-69",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-69",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-70",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-70",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ] # '|' is 'or' opeartor\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria.\nWhat if our next report asked for employees from 30 teams instead of three?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-71",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-71",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[ on_star_teams ]\n\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, array, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-72",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-72",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition\n\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000.\n\n\n\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ] # '&' is 'and' opeartor\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-73",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-73",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[ between_90k_and_100k ]\n\nA slightly cleaner solution is to use a method called between().\n\nIt returns a Boolean Series where True denotes that an observation‚Äôs value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-74",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-74",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[ name_starts_with_t ]\n\nWe can also apply the between() method to string variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-75",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-75",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nFiltering by a Condition with the query() method!\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 & `First Name` == 'Douglas'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\n\nquery() accepts a string value that describes filtering conditions.\n\nWhen using the query() method, if we have variable names with spaces, we can wrap the variable names in backtick (`)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-76",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-76",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 2-6 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-77",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-77",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-78",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-78",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-79",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-79",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation‚Äôs value is missing.\n\nIs a value of a variable ‚ÄúXYZ‚Äù missing?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-80",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-80",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation‚Äôs value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-81",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-81",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-82",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-82",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-83",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-83",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter‚Äôs default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-84",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-84",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-85",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-85",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-86",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-86",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Missing Values: The dropna() method with thresh\nemp.dropna(thresh = 4)\n\nThe thresh parameter specifies a minimum threshold of non-missing values that an observation must have for pandas to keep it."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-87",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-87",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-88",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-88",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method‚Äôs keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value.\n\nQ. How can we keep observations with the first occurrences of a value in the Team variable?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-89",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-89",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-90",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-90",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-91",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-91",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation‚Äôs uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-92",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-92",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-93",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-93",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nDealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value‚Äôs last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of ‚ÄúDouglas‚Äù and a Gender of ‚ÄúMale‚Äù. Then check which ‚ÄúDouglas‚Äù is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-94",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics-94",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-1",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nTidy DataFrames\n\n\n\n\nThere are three interrelated rules that make a DataFrame tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-2",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nA DataFrame can be given in a format unsuited for the analysis that we would like to perform on it.\n\nA DataFrame may have larger structural problems that extend beyond the data.\nPerhaps the DataFrame stores its values in a format that makes it easy to extract a single row but difficult to aggregate the data.\n\nReshaping a DataFrame means manipulating it into a different shape.\nIn this section, we will discuss pandas techniques for molding a DataFrame into the shape we desire."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-3",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nmelt() and pivot()\n\n\n\n\nmelt() makes DataFrame longer.\npivot() and pivot_table() make DataFrame wider."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-4",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-4",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-5",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-5",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-6",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-6",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet‚Äôs do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-7",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-7",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nMake DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-8",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-8",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nMake DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the ‚Äúidentifier‚Äù."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-9",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-9",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nMake DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-10",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-10",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nMake DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\",\n          value_vars = ['Miami', 'Rochester'])\n)\n\n\nmelt() can take a few parameters:\n\nvalue_vars parameter allows us to select which specific columns we want to ‚Äúmelt‚Äù.\nBy default, it will melt all the columns not specified in the id_vars parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-11",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-11",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nMake DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the new variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-12",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-12",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-13",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-13",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-14",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#reshaping-dataframes-14",
    "title": "Lecture 6",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet‚Äôs do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-1",
    "title": "Lecture 6",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more DataFrames based on common data values in those DataFrames.\n\nThis task is known in the database world as performing a ‚Äújoin.‚Äù\nWe can do this with the merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-2",
    "title": "Lecture 6",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\n\nThe variables that are used to connect each pair of tables are called keys."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-1",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nInner Join\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n# the default value for 'how' is 'inner'\n# so it doesn't actually need to be specified\nmerge_inner = pd.merge(x, y, on='key', how='inner')\nmerge_inner_x = x.merge(y, on='key', how='inner')\nmerge_inner_x_how = x.merge(y, on='key')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-2",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLeft Join\n\nA left join keeps all observations in x.\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-3",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nRight Join\n\nA right join keeps all observations in y.\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-4",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-4",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nOuter (Full) Join\n\nA full join keeps all observations in x and y.\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-1",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\n\nConcatenation can be thought of as appending a row or column to our data.\n\nThis approach is possible if our data was split into parts or if we performed a calculation that we want to append to our existing data set.\n\nLet‚Äôs consider the following example DataFrames:\n\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-2",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nConcatenating the DataFrames on top of each other uses the concat() method.\n\nAll of the DataFrames to be concatenated are passed in a list.\n\n\nrow_concat = pd.concat([df1, df2, df3])\nrow_concat"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-3",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nLet‚Äôs consider a new Series and concatenate it with df1:\n\n# create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\nnew_row_series\n\n\n# attempt to add the new row to a dataframe\ndf = pd.concat([df1, new_row_series])\ndf\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-4",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-4",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nTo fix the problem, we need turn our Series into a DataFrame.\n\nThis data frame contains one row of data, and the column names are the ones the data will bind to.\n\n\nnew_row_df = pd.DataFrame(\n  # note the double brackets to create a \"row\" of data\n  data =[[\"n1\", \"n2\", \"n3\", \"n4\"]],\n  columns =[\"A\", \"B\", \"C\", \"D\"],\n)\n\ndf = pd.concat([df1, new_row_df])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-5",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-5",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nConcatenating columns is very similar to concatenating rows.\n\nThe main difference is the axis parameter in the concat() method.\nThe default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion.\nIf we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\n\n\ncol_concat = pd.concat([df1, df2, df3], axis = \"columns\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-6",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-6",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nWe can use ignore_index=True to reset the column indices, so that we do not have duplicated column names.\n\npd.concat([df1, df2, df3], axis=\"columns\", ignore_index=True)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-7",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-7",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet‚Äôs do Part 3 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-8",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-8",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nConcatenate with Different Indices\n\n\nWe can set join = 'inner' to keep only the columns that are shared among the data sets.\n\npd.concat([df1, df2, df3], join ='inner')\n\nIf we use the DataFrames that have columns in common, only the columns that all of them share will be returned.\n\npd.concat([df1, df3], join ='inner',  ignore_index =False)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-9",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-9",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nConcatenate with Different Indices\n\n\nLet‚Äôs modify our DataFrames further.\n\n# re-indexing the rows of our DataFrames\ndf1.index = [0, 1, 2, 3]\ndf2.index = [4, 5, 6, 7]\ndf3.index = [0, 2, 5, 7]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-10",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-10",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nConcatenate with Different Indices\n\n\nWhen we concatenate along axis=\"columns\" (axis=1), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.\n\ncol_concat = pd.concat([df1, df2, df3], axis=\"columns\")\n\nJust as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using join=\"inner\".\n\npd.concat([df1, df3], axis =\"columns\", join='inner')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#concatenating-rows-and-columns",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#concatenating-rows-and-columns",
    "title": "Lecture 6",
    "section": "Concatenating Rows and Columns",
    "text": "Concatenating Rows and Columns\nLet‚Äôs do Part 3 of Classwork 7!"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html",
    "href": "danl-cw/danl-210-cw-07.html",
    "title": "Classwork 7",
    "section": "",
    "text": "Make ny_pincp longer.\n\nny_pincp = pd.read_csv('https://bcdanl.github.io/data/NY_pinc_wide.csv')\n\n\n\n\n\n  \n\n\n\n\n\n\n\nMake a wide-form DataFrame of covid whose variable names are from countriesAndTerritories and values are from cases.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#question-1",
    "href": "danl-cw/danl-210-cw-07.html#question-1",
    "title": "Classwork 7",
    "section": "",
    "text": "Make ny_pincp longer.\n\nny_pincp = pd.read_csv('https://bcdanl.github.io/data/NY_pinc_wide.csv')"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#question-2",
    "href": "danl-cw/danl-210-cw-07.html#question-2",
    "title": "Classwork 7",
    "section": "",
    "text": "Make a wide-form DataFrame of covid whose variable names are from countriesAndTerritories and values are from cases.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#variables-in-flights-dataframe",
    "href": "danl-cw/danl-210-cw-07.html#variables-in-flights-dataframe",
    "title": "Classwork 7",
    "section": "Variables in flights DataFrame",
    "text": "Variables in flights DataFrame\n\nyear, month, day: Date of departure.\ndep_time, arr_time: Actual departure and arrival times (format HHMM or HMM), local tz.\nsched_dep_time, sched_arr_time: Scheduled departure and arrival times (format HHMM or HMM), local tz.\ndep_delay, arr_delay: Departure and arrival delays, in minutes. Negative times represent early departures/arrivals.\ncarrier: Two letter carrier abbreviation. See airlines DataFrame to get full names.\nflight: Flight number.\ntailnum: Plane tail number. See planes DataFrame for additional metadata.\norigin, dest: Origin and destination. See airports DataFrame for additional metadata.\nair_time: Amount of time spent in the air, in minutes.\ndistance: Distance between airports, in miles.\nhour, minute: Time of scheduled departure broken into hour and minutes.\ntime_hour: Scheduled date and hour of the flight as a datetime64. Along with origin, can be used to join flights data to weather DataFrame"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#question-3",
    "href": "danl-cw/danl-210-cw-07.html#question-3",
    "title": "Classwork 7",
    "section": "Question 3",
    "text": "Question 3\n\nMerge flights with weather.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#question-4",
    "href": "danl-cw/danl-210-cw-07.html#question-4",
    "title": "Classwork 7",
    "section": "Question 4",
    "text": "Question 4\n\nIdentify the full name of the airline with the highest average dep_delay, considering only positive delays.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#question-5",
    "href": "danl-cw/danl-210-cw-07.html#question-5",
    "title": "Classwork 7",
    "section": "Question 5",
    "text": "Question 5\n\nFind the airline that has the largest proportion of flights with longer than 30-minute dep_delay.\nHint: numpy.where() is like an if-else statement, which can be very useful:\n\n\nimport pandas as pd\nimport numpy as np\n\n# Sample DataFrame with temperatures\ndf = pd.DataFrame({\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Temperature (C)': [12, 22, 7, 25, 30]\n})\n\n# Categorize temperatures using numpy.where\ndf['Category'] = np.where(df['Temperature (C)'] &lt; 10, 'Cold', 'Not Cold'))\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#question-6",
    "href": "danl-cw/danl-210-cw-07.html#question-6",
    "title": "Classwork 7",
    "section": "Question 6",
    "text": "Question 6\n\nWrite a Pandas code to join the two given DataFrames along rows and assign all data.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#question-7",
    "href": "danl-cw/danl-210-cw-07.html#question-7",
    "title": "Classwork 7",
    "section": "Question 7",
    "text": "Question 7\n\nWrite a Pandas code to join the two given DataFrames along columns and assign all data.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.html#question-8",
    "href": "danl-cw/danl-210-cw-07.html#question-8",
    "title": "Classwork 7",
    "section": "Question 8",
    "text": "Question 8\n\nConsider the following Pandas Series:\n\n\ns6 = pd.Series(['S6', 'Scarlette Fisher', 205], index=['student_id', 'name', 'marks'])\n\nWrite a Pandas code to append rows to the DataFrame student_data1.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html",
    "href": "danl-cw/danl-210-cw-06.html",
    "title": "Classwork 6",
    "section": "",
    "text": "The netflix.csv file (with its pathname https://bcdanl.github.io/data/netflix.csv) contains a list of 6,000 titles that were available to watch in November 2019 on the video streaming service Netflix. It includes four variables: the video‚Äôs title, director, the date Netflix added it (date_added), and its type (category)."
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#direction",
    "href": "danl-cw/danl-210-cw-06.html#direction",
    "title": "Classwork 6",
    "section": "",
    "text": "The netflix.csv file (with its pathname https://bcdanl.github.io/data/netflix.csv) contains a list of 6,000 titles that were available to watch in November 2019 on the video streaming service Netflix. It includes four variables: the video‚Äôs title, director, the date Netflix added it (date_added), and its type (category)."
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#question-1",
    "href": "danl-cw/danl-210-cw-06.html#question-1",
    "title": "Classwork 6",
    "section": "Question 1",
    "text": "Question 1\nOptimize the DataFrame for limited memory use and maximum utility by using the astype() method.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#question-2",
    "href": "danl-cw/danl-210-cw-06.html#question-2",
    "title": "Classwork 6",
    "section": "Question 2",
    "text": "Question 2\nFind all observations with a director of ‚ÄúMartin Scorsese‚Äù.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#question-3",
    "href": "danl-cw/danl-210-cw-06.html#question-3",
    "title": "Classwork 6",
    "section": "Question 3",
    "text": "Question 3\nFind all observations with a title of ‚ÄúLimitless‚Äù and a type of ‚ÄúMovie‚Äù.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#question-4",
    "href": "danl-cw/danl-210-cw-06.html#question-4",
    "title": "Classwork 6",
    "section": "Question 4",
    "text": "Question 4\nFind all observations with either a date_added of ‚Äú2018-06-15‚Äù or a director of ‚ÄúBong Joon Ho‚Äù.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#question-5",
    "href": "danl-cw/danl-210-cw-06.html#question-5",
    "title": "Classwork 6",
    "section": "Question 5",
    "text": "Question 5\nFind all observations with a director of ‚ÄúEthan Coen‚Äù, ‚ÄúJoel Coen‚Äù, and ‚ÄúQuentin Tarantino‚Äù.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#question-6",
    "href": "danl-cw/danl-210-cw-06.html#question-6",
    "title": "Classwork 6",
    "section": "Question 6",
    "text": "Question 6\nFind all observations with a date_added value between January 1, 2019 and February 1, 2019.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#question-7",
    "href": "danl-cw/danl-210-cw-06.html#question-7",
    "title": "Classwork 6",
    "section": "Question 7",
    "text": "Question 7\nDrop all observations with a NaN value in the director variable.\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-06.html#question-8",
    "href": "danl-cw/danl-210-cw-06.html#question-8",
    "title": "Classwork 6",
    "section": "Question 8",
    "text": "Question 8\nIdentify the days when Netflix added only one movie to its catalog.\nAnswer:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-11",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-concatenation-11",
    "title": "Lecture 6",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet‚Äôs do Part 3 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#data-collection",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#data-collection",
    "title": "Lecture 6",
    "section": "Data Collection",
    "text": "Data Collection\nLearning Objectives\n\nScrapping web tables with .read_html()\nScrapping web data with selenium\nCollecting web data with Application Programming Interfaces (APIs)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-group-operations-and-data-visualization",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-group-operations-and-data-visualization",
    "title": "Lecture 6",
    "section": "Pandas Group Operations and Data Visualization",
    "text": "Pandas Group Operations and Data Visualization\nLearning Objectives\n\nUsing Custom Functions and Anonymous Functions\nGrouping DataFrames with groupby(), .agg(), and .transform()\nVisualizing DataFrames with seaborn"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html",
    "title": "Lecture 6",
    "section": "",
    "text": "Save your Jupyter Notebook for each class to a dedicated directory in your local laptop, Google Drive, or a new GitHub repo.\n\nGo to File and select Save ‚Ä¶/ ( e.g., danl-210-lec-08-2025-0210.ipynb)\n\n\n\n\n\n\n\n\nIn your local website project directory, avoid having\n\nAny file that exceeds 30 MB in size;\n.ipynb files you do not use for your website.\n\nYour website project directory should include files specifically dedicated to your website.\n\n\n\n\n\n\n\n\nRun Python code cells in a Jupyter Notebook (.ipynb) on Google Colab. Then, download the Jupyter Notebook from Google Colab.\nUse the Finder/File Explorer to move the Jupyter Notebook file (.ipynb) to your website project directory. (If it is for a blog post, create a subdirectory in the posts directory, and move it to the subdirectory.)\nEdit _quarto.yml properly. Save the changes by clicking the floppy disk icon (üíæ).\nOn Terminal, run quarto render.\nOnce quarto render completes, view the index.html in your website working directory to see the HTML output.\nAfter confirming the HTML output, use the 3-step git commands (add-commit-push) on Terminal to update your online website."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-group-operations-data-visualization",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-group-operations-data-visualization",
    "title": "Lecture 6",
    "section": "Pandas Group Operations & Data Visualization",
    "text": "Pandas Group Operations & Data Visualization\nLearning Objectives\n\nUsing Custom Functions and Anonymous Functions\nGrouping DataFrames with groupby(), .agg(), and .transform()\nVisualizing DataFrames with seaborn"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-5",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-5",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: one-to-many\n\nOne DataFrame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key':[1, 2, 2, 3],\n    'val_x':['x1', 'x2', 'x3', 'x4']})\n\ny = pd.DataFrame({\n    'key':[1, 2],\n    'val_y':['y1', 'y2'] })\none_to_many = x.merge(y, on='key', \n                         how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-6",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-6",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: many-to-many\n\nBoth DataFrames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key':[1, 2, 2, 3],\n  'val_x':['x1','x2','x3','x4']})\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', \n                          how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-7",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-7",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDefining the key columns\n\n\nIf the left and right columns do not have the same name for the key variables, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = \n  x.merge(y, left_on = 'key_x', \n             right_on = 'key_y', \n             how = 'left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-8",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#joining-dataframes-with-merge-8",
    "title": "Lecture 6",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLet‚Äôs do Part 2 of Classwork 7!"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html",
    "href": "danl-cw/danl-210-cw-07.knit.html",
    "title": "Classwork 7",
    "section": "",
    "text": "Make ny_pincp longer.\n\nny_pincp = pd.read_csv('https://bcdanl.github.io/data/NY_pinc_wide.csv')\n\n\n\n\n\n  \n\n\n\n\n\n\n\nMake a wide-form DataFrame of covid whose variable names are from countriesAndTerritories and values are from cases.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#question-1",
    "href": "danl-cw/danl-210-cw-07.knit.html#question-1",
    "title": "Classwork 7",
    "section": "",
    "text": "Make ny_pincp longer.\n\nny_pincp = pd.read_csv('https://bcdanl.github.io/data/NY_pinc_wide.csv')"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#question-2",
    "href": "danl-cw/danl-210-cw-07.knit.html#question-2",
    "title": "Classwork 7",
    "section": "",
    "text": "Make a wide-form DataFrame of covid whose variable names are from countriesAndTerritories and values are from cases.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#variables-in-flights-dataframe",
    "href": "danl-cw/danl-210-cw-07.knit.html#variables-in-flights-dataframe",
    "title": "Classwork 7",
    "section": "Variables in flights DataFrame",
    "text": "Variables in flights DataFrame\n\nyear, month, day: Date of departure.\ndep_time, arr_time: Actual departure and arrival times (format HHMM or HMM), local tz.\nsched_dep_time, sched_arr_time: Scheduled departure and arrival times (format HHMM or HMM), local tz.\ndep_delay, arr_delay: Departure and arrival delays, in minutes. Negative times represent early departures/arrivals.\ncarrier: Two letter carrier abbreviation. See airlines DataFrame to get full names.\nflight: Flight number.\ntailnum: Plane tail number. See planes DataFrame for additional metadata.\norigin, dest: Origin and destination. See airports DataFrame for additional metadata.\nair_time: Amount of time spent in the air, in minutes.\ndistance: Distance between airports, in miles.\nhour, minute: Time of scheduled departure broken into hour and minutes.\ntime_hour: Scheduled date and hour of the flight as a datetime64. Along with origin, can be used to join flights data to weather DataFrame"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#question-3",
    "href": "danl-cw/danl-210-cw-07.knit.html#question-3",
    "title": "Classwork 7",
    "section": "Question 3",
    "text": "Question 3\n\nMerge flights with weather.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#question-4",
    "href": "danl-cw/danl-210-cw-07.knit.html#question-4",
    "title": "Classwork 7",
    "section": "Question 4",
    "text": "Question 4\n\nIdentify the full name of the airline with the highest average dep_delay, considering only positive delays.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#question-5",
    "href": "danl-cw/danl-210-cw-07.knit.html#question-5",
    "title": "Classwork 7",
    "section": "Question 5",
    "text": "Question 5\n\nFind the airline that has the largest proportion of flights with longer than 30-minute dep_delay.\nHint: numpy.where() is like an if-else statement, which can be very useful:\n\n\nimport pandas as pd\nimport numpy as np\n\n# Sample DataFrame with temperatures\ndf = pd.DataFrame({\n    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n    'Temperature (C)': [12, 22, 7, 25, 30]\n})\n\n# Categorize temperatures using numpy.where\ndf['Category'] = np.where(df['Temperature (C)'] &lt; 10, 'Cold', 'Not Cold'))\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#question-6",
    "href": "danl-cw/danl-210-cw-07.knit.html#question-6",
    "title": "Classwork 7",
    "section": "Question 6",
    "text": "Question 6\n\nWrite a Pandas code to join the two given DataFrames along rows and assign all data.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#question-7",
    "href": "danl-cw/danl-210-cw-07.knit.html#question-7",
    "title": "Classwork 7",
    "section": "Question 7",
    "text": "Question 7\n\nWrite a Pandas code to join the two given DataFrames along columns and assign all data.\n\nAnswer:"
  },
  {
    "objectID": "danl-cw/danl-210-cw-07.knit.html#question-8",
    "href": "danl-cw/danl-210-cw-07.knit.html#question-8",
    "title": "Classwork 7",
    "section": "Question 8",
    "text": "Question 8\n\nConsider the following Pandas Series:\n\n\ns6 = pd.Series(['S6', 'Scarlette Fisher', 205], index=['student_id', 'name', 'marks'])\n\nWrite a Pandas code to append rows to the DataFrame student_data1.\nAnswer:"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#series-and-dataframe",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#series-and-dataframe",
    "title": "Lecture 6",
    "section": "Series and DataFrame",
    "text": "Series and DataFrame\n\n\n\n\nSeries: a collection of a one-dimensional object containing a sequence of values.\nDataFrame: a collection of Series columns with an index."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#importing-a-data-set-with-read_csv",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#importing-a-data-set-with-read_csv",
    "title": "Lecture 6",
    "section": "Importing a data set with read_csv()",
    "text": "Importing a data set with read_csv()\n\n\nA CSV (comma-separated values) is a plain-text file that uses a comma to separate values (e.g., nba.csv).\nThe CSV is widely used for storing data, and we will use this throughout the module.\nWe use the read_csv() function to load a CSV data file.\n\nimport pandas as pd\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")\ntype(nba)\nnba\n\n\nThe DataFrame is the workhorse of the pandas library and the data structure."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#importing-a-data-set-with-read_csv-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#importing-a-data-set-with-read_csv-1",
    "title": "Lecture 6",
    "section": "Importing a data set with read_csv()",
    "text": "Importing a data set with read_csv()\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])\nnba\n\nWe can use the parse_dates parameter to coerce the values into datetimes."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#loading-data-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#loading-data-1",
    "title": "Lecture 6",
    "section": "Loading Data",
    "text": "Loading Data\nMounting Google Drive on Google Colab\n\n\nfrom google.colab import drive, files\ndrive.mount('/content/drive')\nfiles.upload()\n\ndrive.mount('/content/drive')\n\nTo mount your Google Drive on Google colab:\n\nfiles.upload()\n\nTo initiate uploading a file on Google Drive:\n\n\n\n\nTo find a pathname of a CSV file in Google Drive:\n\nClick üìÅ from the sidebar menu\ndrive ‚û°Ô∏è MyDrive ‚Ä¶\nHover a mouse cursor on the CSV file\nClick the vertical dots\nClick ‚ÄúCopy path‚Äù"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#loading-data-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#loading-data-2",
    "title": "Lecture 6",
    "section": "Loading Data",
    "text": "Loading Data\nColab‚Äôs Interactive DataFrame Display\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()  # Enabling an interactive DataFrame display\nnba\n\nColab includes an extension that renders pandas DataFrames into interactive displays."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#loading-data-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#loading-data-3",
    "title": "Lecture 6",
    "section": "Loading Data",
    "text": "Loading Data\nAnother Interactive DataFrame Display\n# !pip install itables\nfrom itables import init_notebook_mode, show\ninit_notebook_mode(all_interactive=False)\nshow(nba)\n\nitables provides similar interactive displays for DataFrames.\n\nFor a blog post, itables‚Äòs interactive displays may work better than google.colab‚Äô ones."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dataframe-terminologies-variables-observations-and-values",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dataframe-terminologies-variables-observations-and-values",
    "title": "Lecture 6",
    "section": "DataFrame Terminologies: Variables, Observations, and Values",
    "text": "DataFrame Terminologies: Variables, Observations, and Values\n\n\n\n\nEach variable is a column.\nEach observation is a row.\nEach value is a cell."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dataframe-terminologies-dot-operators-methods-and-attributes",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dataframe-terminologies-dot-operators-methods-and-attributes",
    "title": "Lecture 6",
    "section": "DataFrame Terminologies: Dot Operators, Methods and Attributes",
    "text": "DataFrame Terminologies: Dot Operators, Methods and Attributes\n\nThe dot operator (DataFrame.) is used for an attribute or a method on objects.\nA method (DataFrame.METHOD()) is a function that we can call on a DataFrame to perform operations, modify data, or derive insights.\n\ne.g., nba.info()\n\nAn attribute (DataFrame.ATTRIBUTE) is a property that provides information about the DataFrame‚Äôs structure or content without modifying it.\n\ne.g., nba.dtype"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#getting-a-summary-of-a-dataframe-with-.info",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#getting-a-summary-of-a-dataframe-with-.info",
    "title": "Lecture 6",
    "section": "Getting a Summary of a DataFrame with .info()",
    "text": "Getting a Summary of a DataFrame with .info()\n\n\nnba.info()    # method\n\nnba.shape     # attribute\nnba.dtypes    # attribute\nnba.columns   # attribute\nnba.count()   # method\n\n\n\nEvery DataFrame object has a .info() method that provides a summary of a DataFrame:\n\nVariable names (.columns)\nNumber of variables/observations (.shape)\nData type of each variable (.dtypes)\nNumber of non-missing values in each variable (.count())\n\nPandas often displays missing values as NaN."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#getting-a-summary-of-a-dataframe-with-.describe",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#getting-a-summary-of-a-dataframe-with-.describe",
    "title": "Lecture 6",
    "section": "Getting a Summary of a DataFrame with .describe()",
    "text": "Getting a Summary of a DataFrame with .describe()\nnba.describe()\nnba.describe(include='all')\n\n.describe() method generates descriptive statistics that summarize the central tendency, dispersion, and distribution of each variable.\n\nIt can also process string-type variables if specified explicitly (include='all')."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#selecting-a-variable-by-its-name",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#selecting-a-variable-by-its-name",
    "title": "Lecture 6",
    "section": "Selecting a Variable by its Name",
    "text": "Selecting a Variable by its Name\nnba_player_name_s = nba['Name']   # Series\nnba_player_name_s\n\nnba_player_name_df = nba[ ['Name'] ]   # DataFrame\nnba_player_name_df\n\nIf we want only a specific variable from a DataFrame, we can access the variable with its name using squared brackets, [ ].\n\nDataFrame[ 'var_1' ]\nDataFrame[ ['var_1'] ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#selecting-multiple-variables-by-their-names",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#selecting-multiple-variables-by-their-names",
    "title": "Lecture 6",
    "section": "Selecting Multiple Variables by their Names",
    "text": "Selecting Multiple Variables by their Names\nnba_player_name_team = nba[ ['Name', 'Team'] ]\nnba_player_name_team\n\nIn order to specify multiple variables by their names, we need to pass in a Python list between the square brackets.\n\nDataFrame[ ['var_1', 'var_2', ... ] ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#selecting-multiple-variables-with-select_dtypes",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#selecting-multiple-variables-with-select_dtypes",
    "title": "Lecture 6",
    "section": "Selecting Multiple Variables with select_dtypes()",
    "text": "Selecting Multiple Variables with select_dtypes()\n# To include only string variables\nnba.select_dtypes(include = \"object\")\n\n# To exclude string and integer variables\nnba.select_dtypes(exclude = [\"object\", \"int\"])\n\nWe can use the select_dtypes() method to select columns based on their data types.\n\nThe method accepts two parameters, include and exclude."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#counting-with-.count",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#counting-with-.count",
    "title": "Lecture 6",
    "section": "Counting with .count()",
    "text": "Counting with .count()\n\n\nnba['Salary'].count()\nnba[['Salary']].count()\n\n\n\nThe .count() counts the number of non-missing values in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#counting-with-.value_counts",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#counting-with-.value_counts",
    "title": "Lecture 6",
    "section": "Counting with .value_counts()",
    "text": "Counting with .value_counts()\n\n\nnba['Team'].value_counts()\n\nnba[['Team']].value_counts()\n\n\n\nThe .value_counts() counts the number of occurrences of each unique value in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#counting-with-.nunique",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#counting-with-.nunique",
    "title": "Lecture 6",
    "section": "Counting with .nunique()",
    "text": "Counting with .nunique()\n\n\nnba[['Team']].nunique()\n\nnba.nunique()\n\n\n\nThe .nunique() counts the number of unique values in each variable in a DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-methods-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-methods-1",
    "title": "Lecture 6",
    "section": "Sorting Methods",
    "text": "Sorting Methods\n\n\nLet‚Äôs read nba.csv as nba.\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])\n                  \n# Below is to view the nba DataFrame and to get a summary of it\nnba\nnba.info()\nnba.describe( include=\"all\" )"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-a-single-variable-with-sort_values",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-a-single-variable-with-sort_values",
    "title": "Lecture 6",
    "section": "Sorting by a Single Variable with sort_values()",
    "text": "Sorting by a Single Variable with sort_values()\n# The two lines below are equivalent\nnba.sort_values([\"Name\"])\nnba.sort_values(by = [\"Name\"])\n\n\nThe sort_values() method‚Äôs first parameter, by, accepts the variables that pandas should use to sort observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-a-single-variable-with-sort_values-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-a-single-variable-with-sort_values-1",
    "title": "Lecture 6",
    "section": "Sorting by a Single Variable with sort_values()",
    "text": "Sorting by a Single Variable with sort_values()\nnba.sort_values([\"Name\"], ascending = False)\n\n\nThe sort_values() method‚Äôs ascending parameter determines the sort order.\n\nascending has a default argument of True.\nBy default, pandas will sort:\n\nA variable of numbers in increasing order;\nA variable of strings in alphabetical order;\nA variable of datetimes in chronological order."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest",
    "title": "Lecture 6",
    "section": "Sorting by a Single Variable with nsmallest() and nlargest()",
    "text": "Sorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(5, 'Salary')\nnba.nlargest(5, 'Salary')\n\nnsmallest() are useful to get the first n observations ordered by a variable in ascending order.\nnlargest() are useful to get the first n observations ordered by a variable in descending order."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest-1",
    "title": "Lecture 6",
    "section": "Sorting by a Single Variable with nsmallest() and nlargest()",
    "text": "Sorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(4, 'Salary', keep = \"all\")\nnba.nlargest(4, 'Salary', keep = \"all\")\n\nkeep = \"all\" keeps all duplicates, even it means selecting more than n observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-multiple-variables-with-sort_values",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-multiple-variables-with-sort_values",
    "title": "Lecture 6",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values([\"Team\", \"Name\"])\nnba.sort_values(by = [\"Team\", \"Name\"])\n\nWe can sort a DataFrame by multiple columns by passing a list to the by parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-multiple-variables-with-sort_values-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-multiple-variables-with-sort_values-1",
    "title": "Lecture 6",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = False)\n\nWe can pass a single Boolean to the ascending parameter to apply the same sort order to each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-multiple-variables-with-sort_values-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-multiple-variables-with-sort_values-2",
    "title": "Lecture 6",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = [False, True])\n\nIf we want to sort each variable in a different order, we can pass a Boolean list to the ascending parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-multiple-variables-with-sort_values-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-multiple-variables-with-sort_values-3",
    "title": "Lecture 6",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nQ. Which players on each team are paid the most?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-row-index-with-sort_index",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#sorting-by-row-index-with-sort_index",
    "title": "Lecture 6",
    "section": "Sorting by Row Index with sort_index()",
    "text": "Sorting by Row Index with sort_index()\n\n\n# Below lines are equivalent\nnba.sort_index()\nnba.sort_index(ascending = True)\n\nnba.sort_index(ascending = False)\n\n\n\nIf we assigned nba to nba DataFrame sorted by ‚ÄúName‚Äù, how can we return it to its original form of DataFrame?\n\nOur nba DataFrame still has its numeric index labels.\nsort_index() sorts observations by their index labels (row names)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#relocating-variables-with-sort_index",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#relocating-variables-with-sort_index",
    "title": "Lecture 6",
    "section": "Relocating Variables with sort_index()",
    "text": "Relocating Variables with sort_index()\n# The two lines below are equivalent\nnba.sort_index(axis = \"columns\")\nnba.sort_index(axis = 1)\n\nThe sort_index() method can also be used to change the order of variables in an alphabetical order.\n\nWe need to add an axis parameter and pass it an argument of \"columns\" or 1."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#setting-a-new-index-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#setting-a-new-index-1",
    "title": "Lecture 6",
    "section": "Setting a New Index",
    "text": "Setting a New Index\n\nWe can use the set_index() method when we want to change the current index of a DataFrame to one or more existing columns.\n\nThis is particularly useful when:\n\nWe have a column that uniquely identifies each observation (e.g., ID);\nWe sometimes want to use an unique identifier as the index for more efficient data wrangling."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#setting-a-new-index-with-set_index",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#setting-a-new-index-with-set_index",
    "title": "Lecture 6",
    "section": "Setting a New Index with set_index()",
    "text": "Setting a New Index with set_index()\n# The two lines below are equivalent\nnba.set_index(keys = \"Name\")\nnba.set_index(\"Name\")\n\nThe set_index() method returns a new DataFrame with a given column set as the index.\n\nIts first parameter, keys, accepts the column name."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#re-setting-an-index-with-reset_index",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#re-setting-an-index-with-reset_index",
    "title": "Lecture 6",
    "section": "Re-setting an Index with reset_index()",
    "text": "Re-setting an Index with reset_index()\nnba2 = nba.set_index(\"Name\")\nnba2.reset_index(inplace=True)    # Useful for the method chaining\n\nWe use the reset_index() method:\n\nWhen we want to convert the index back into a DataFrame column;\nWhen we need to reset the index to the default integer index.\n\nNote: With inplace=True, the operation alters the original DataFrame directly."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-1",
    "title": "Lecture 6",
    "section": "Locating Observations",
    "text": "Locating Observations\n\n\nLet‚Äôs read nba.csv as nba.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observationsvalues",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observationsvalues",
    "title": "Lecture 6",
    "section": "Locating Observations/Values",
    "text": "Locating Observations/Values\n\nWe can extract observations, variables, and values from a DataFrame by using the loc[] and iloc[] accessors.\n\nThese accessors work well when we know the index labels and positions of the observations/variables we want to target."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.loc-index-labels",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.loc-index-labels",
    "title": "Lecture 6",
    "section": "Locating Observations by .loc[ Index Labels ]",
    "text": "Locating Observations by .loc[ Index Labels ]\n\n\nLet‚Äôs consider the nba with the Name index.\n\n# The two lines below are equivalent\nnba = nba.set_index(\"Name\")\nnba.set_index(\"Name\", inplace = True)\n\nBelow extracts observations:\n\n\nnba.loc[ \"LeBron James\" ]\nnba.loc[ [\"Kawhi Leonard\", \"Paul George\"] ]\n\nThe .loc attribute extracts an observation by index label (row name)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.loc-index-labels-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.loc-index-labels-1",
    "title": "Lecture 6",
    "section": "Locating Observations by .loc[ Index Labels ]",
    "text": "Locating Observations by .loc[ Index Labels ]\n(\n    nba\n    .sort_index()\n    .loc[\"Otto Porter\":\"Patrick Beverley\"]\n)\n\nWhat is the above code doing?\n\nNote: Both the starting value and the ending value are inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.loc-index-labels-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.loc-index-labels-2",
    "title": "Lecture 6",
    "section": "Locating Observations by .loc[ Index Labels ]",
    "text": "Locating Observations by .loc[ Index Labels ]\n\n\n(\n    nba\n    .sort_index()\n    .loc[\"Zach Collins\":]\n)\n\n(\n    nba\n    .sort_index()\n    .loc[:\"Al Horford\"]\n)\n\n\n\nWe can use loc[:] to pull rows:\n\nFrom the middle of the DataFrame to its end;\nFrom the beginning of the DataFrame to a specific index label."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.iloc-index-positions",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.iloc-index-positions",
    "title": "Lecture 6",
    "section": "Locating Observations by .iloc[ Index Positions ]",
    "text": "Locating Observations by .iloc[ Index Positions ]\n\n\nnba.iloc[ 300 ]\nnba.iloc[ [100, 200, 300, 400] ]\n\nnba.iloc[400:404]\nnba.iloc[:2]\nnba.iloc[447:]\nnba.iloc[-10:-6]\nnba.iloc[0:10:2] # every other rows\n\n\n\nThe .iloc (index location) attribute locates rows by index position.\n\nThis can be helpful when the position of rows has significance in our data set.\nWe pass integers.\n\nThe .iloc[:] is similar to the slicing syntax with strings/lists.\n\nThe end value is NOT inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-values-by-locrows-columns-or-ilocrows-columns",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-values-by-locrows-columns-or-ilocrows-columns",
    "title": "Lecture 6",
    "section": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]",
    "text": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.loc[\n    \"LeBron James\",\n    \"Team\"\n]\n\nnba.loc[\n     \"James Harden\", \n      [\"Position\", \"Birthday\"] \n]\n\nnba.loc[\n    [\"Russell Westbrook\", \"Anthony Davis\"],\n     [\"Team\", \"Salary\"]\n]\n\nnba.loc[\n    \"Joel Embiid\", \n    \"Position\":\"Salary\"\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .loc, we have to provide the column names."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-values-by-locrows-columns-or-ilocrows-columns-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-values-by-locrows-columns-or-ilocrows-columns-1",
    "title": "Lecture 6",
    "section": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]",
    "text": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.iloc[\n    57, \n    3\n]\n\nnba.iloc[\n    100:104, \n    :3\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .iloc, we have to provide the column position."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#mathematical-operations",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#mathematical-operations",
    "title": "Lecture 6",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\nnba.max()\nnba.min()\n\nThe max() method returns a Series with the maximum value from each variable.\nThe min() method returns a Series with the minimum value from each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#mathematical-operations-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#mathematical-operations-1",
    "title": "Lecture 6",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\n\n\nnba.sum()\nnba.mean()\nnba.median()\nnba.quantile(0.75) # 0 to 1\nnba.std()\n\nnba.sum(numeric_only = True)\nnba.mean(numeric_only = True)\nnba.median(numeric_only = True)\nnba.quantile(0.75, numeric_only=True)\nnba.std(numeric_only = True)\n\n\n\nThe sum()/mean()/median() method returns a Series with the sum/mean/median of the values in each variable.\nThe quantile() method returns a Series with the percentile value of the values in each variable (e.g., 25th, 75th, 90th percentile).\nThe std() method returns a Series with the standard deviation of the values in each variable.\nTo limit the operation to numeric volumes, we can pass True to the sum()/mean()/median()/std() method‚Äôs numeric_only parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#vectorized-operations",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#vectorized-operations",
    "title": "Lecture 6",
    "section": "Vectorized Operations",
    "text": "Vectorized Operations\nnba[\"Salary_2x\"] = nba[\"Salary\"] + nba[\"Salary\"]\nnba[\"Name_w_Position\"] = nba[\"Name\"] + \" (\" + nba[\"Position\"] + \")\"\nnba[\"Salary_minus_Mean\"] = nba[\"Salary\"] - nba[\"Salary\"].mean()\n\npandas performs a vectorized operation on Series or a variable in DataFrame.\n\nThis means an element-by-element operation.\nThis enables us to apply functions and perform operations on the data efficiently, without the need for explicit loops."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#adding-and-removing-variables",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#adding-and-removing-variables",
    "title": "Lecture 6",
    "section": "Adding and Removing Variables",
    "text": "Adding and Removing Variables\n\n\nHere we use [] to add variables:\n\nnba['Salary_k'] = nba['Salary'] / 1000\nnba['Salary_2x'] = nba['Salary'] + nba['Salary']\nnba['Salary_3x'] = nba['Salary'] * 3"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#removing-variables-with-dropcolumns-...",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#removing-variables-with-dropcolumns-...",
    "title": "Lecture 6",
    "section": "Removing Variables with drop(columns = ... )",
    "text": "Removing Variables with drop(columns = ... )\n\n\nWe can use .drop(columns = ...) to drop variables:\n\nnba.drop(columns = \"Salary_k\")\nnba.drop(columns = [\"Salary_2x\", \"Salary_3x\"])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#renaming-variables-with-nba.columns",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#renaming-variables-with-nba.columns",
    "title": "Lecture 6",
    "section": "Renaming Variables with nba.columns",
    "text": "Renaming Variables with nba.columns\n\n\nDo you recall the .columns attribute?\n\nnba.columns\n\nWe can rename any or all of a DataFrame‚Äôs columns by assigning a list of new names to the attribute:\n\nnba.columns = [\"Team\", \"Position\", \"Date of Birth\", \"Income\"]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "title": "Lecture 6",
    "section": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )\nnba.rename( columns = { \"Date of Birth\": \"Birthday\" } )\n\nThe above rename() method renames the variable Date of Birth to Birthday."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#renaming-rows-with-rename-index-existing-one-new-one",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#renaming-rows-with-rename-index-existing-one-new-one",
    "title": "Lecture 6",
    "section": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )\nnba = nba.rename(\n    index = { \"LeBron James\": \"LeBron Raymone James\" }\n)\n\nThe above rename() method renames the observation LeBron James to LeBron Raymone James."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#relocating-variables-with-.columns.get_loc-.pop-and-.insert",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#relocating-variables-with-.columns.get_loc-.pop-and-.insert",
    "title": "Lecture 6",
    "section": "Relocating Variables with .columns.get_loc(), .pop(), and .insert()",
    "text": "Relocating Variables with .columns.get_loc(), .pop(), and .insert()\nref_var = nba.columns.get_loc('Team') \nvar_to_move = nba.pop('Salary')\nnba.insert(ref_var, 'Salary', var_to_move) # insert() directly alters 'nba'\n\nStep 1. DataFrame.columns.get_loc('Reference_Var')\n\nGet the integer position (right before the reference variable, ‚ÄòReference_Var‚Äô)\n\nStep 2. DataFrame.pop('Some_Var_To_Move')\n\nRemove the variable we want to relocate from the DataFrame and store it in a Series\n\nStep 3. DataFrame.insert(ref_var, 'Some_Var_To_Move', var_to_move)\n\nInsert the variable back into the DataFrame right after the reference variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-1",
    "title": "Lecture 6",
    "section": "Converting Data Types with the astype() Method",
    "text": "Converting Data Types with the astype() Method\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-2",
    "title": "Lecture 6",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\n\n\nWhat values are in the Mgmt variable?\n\n\nemp[\"Mgmt\"].astype(bool)\n\nThe astype() method converts a Series‚Äô values to a different data type.\n\nIt can accept a single argument: the new data type."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-3",
    "title": "Lecture 6",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Mgmt\"] = emp[\"Mgmt\"].astype(bool)\n\nThe above code overwrites the Mgmt variable with our new Series of Booleans."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-4",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-4",
    "title": "Lecture 6",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"].astype(int)\n\nThe above code tries to coerce the Salary variable‚Äôs values to integers with the astype() method.\n\nPandas is unable to convert the NaN values to integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#fill-missing-values-with-the-fillna-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#fill-missing-values-with-the-fillna-method",
    "title": "Lecture 6",
    "section": "Fill Missing Values with the fillna() method",
    "text": "Fill Missing Values with the fillna() method\nemp[\"Salary\"].fillna(0)\n\nThe fillna() method replaces a Series‚Äô missing values with the argument we pass in.\nThe above example provides a fill value of 0.\n\nNote that our choice of value can distort the data; 0 is passed solely for the sake of example."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-5",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-5",
    "title": "Lecture 6",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0).astype(int)\n\nThe above code overwrites the Salary variable with our new Series of integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-6",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-6",
    "title": "Lecture 6",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n\nPandas includes a special data type called a category,\n\nIt is ideal for a variable consisting of a small number of unique values relative to its total size.\nE.g., gender, weekdays, blood types, planets, and income groups."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-pd.to_datetime-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-pd.to_datetime-method",
    "title": "Lecture 6",
    "section": "Converting Data Types with the pd.to_datetime() method",
    "text": "Converting Data Types with the pd.to_datetime() method\n# Below two are equivalent:\nemp[\"Start Date\"] = pd.to_datetime(emp[\"Start Date\"])\nemp[\"Start Date\"] = emp[\"Start Date\"].astype('datetime64')\n\nThe pd.to_datetime() function is used to convert a Series, DataFrame, or a single variable of a DataFrame from its current data type into datetime format."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-7",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#converting-data-types-with-the-astype-method-7",
    "title": "Lecture 6",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\n\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0)\nemp = emp.astype({'Mgmt': 'bool', \n                  'Salary': 'int',\n                  'Gender': 'category',\n                  'Start Date': 'datetime64'})\n\nWe can provide a dictionary of variable-type pairs to astype()."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-condition-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-condition-1",
    "title": "Lecture 6",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition",
    "title": "Lecture 6",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with ‚ÄúDonna‚Äù.\n\npandas performs a vectorized operation (element-by-element operation) on Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-1",
    "title": "Lecture 6",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-2",
    "title": "Lecture 6",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[ donnas ]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-3",
    "title": "Lecture 6",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to extract a subset of employees who are not on the ‚ÄúMarketing‚Äù team?\n\n\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not ‚ÄúMarketing‚Äù, and False indicates the Team value is ‚ÄúMarketing‚Äù"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-4",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-4",
    "title": "Lecture 6",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to retrieve all the managers in the company?\n\nManagers have a value of True in the Mgmt variable.\n\n\n\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-5",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-single-condition-5",
    "title": "Lecture 6",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-condition-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-condition-2",
    "title": "Lecture 6",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ] # '|' is 'or' opeartor\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria.\nWhat if our next report asked for employees from 30 teams instead of three?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-with-the-isin-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-with-the-isin-method",
    "title": "Lecture 6",
    "section": "Filtering with the isin() method",
    "text": "Filtering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[ on_star_teams ]\n\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, array, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-condition-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-condition-3",
    "title": "Lecture 6",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000.\n\n\n\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ] # '&' is 'and' opeartor\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-with-the-between-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-with-the-between-method",
    "title": "Lecture 6",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[ between_90k_and_100k ]\n\nA slightly cleaner solution is to use a method called between().\n\nIt returns a Boolean Series where True denotes that an observation‚Äôs value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-with-the-between-method-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-with-the-between-method-1",
    "title": "Lecture 6",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[ name_starts_with_t ]\n\nWe can also apply the between() method to string variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-condition-with-the-query-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#filtering-by-a-condition-with-the-query-method",
    "title": "Lecture 6",
    "section": "Filtering by a Condition with the query() method!",
    "text": "Filtering by a Condition with the query() method!\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 & `First Name` == 'Douglas'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\n\nquery() accepts a string value that describes filtering conditions.\n\nWhen using the query() method, if we have variable names with spaces, we can wrap the variable names in backtick (`)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-1",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-2",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation‚Äôs value is missing.\n\nIs a value of a variable ‚ÄúXYZ‚Äù missing?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation‚Äôs value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values: The value_counts(dropna = False) method",
    "text": "Dealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values: The dropna() method",
    "text": "Dealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method-with-how",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method-with-how",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values: The dropna() method with how",
    "text": "Dealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter‚Äôs default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "title": "Lecture 6",
    "section": "Dealing with Missing Values: The dropna() method with thresh",
    "text": "Dealing with Missing Values: The dropna() method with thresh\nemp.dropna(thresh = 4)\n\nThe thresh parameter specifies a minimum threshold of non-missing values that an observation must have for pandas to keep it."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-duplicated-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-duplicated-method",
    "title": "Lecture 6",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "title": "Lecture 6",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method‚Äôs keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value.\n\nQ. How can we keep observations with the first occurrences of a value in the Team variable?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "title": "Lecture 6",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "title": "Lecture 6",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "title": "Lecture 6",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation‚Äôs uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "title": "Lecture 6",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "title": "Lecture 6",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value‚Äôs last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of ‚ÄúDouglas‚Äù and a Gender of ‚ÄúMale‚Äù. Then check which ‚ÄúDouglas‚Äù is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#long-vs.-wide-dataframes",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#long-vs.-wide-dataframes",
    "title": "Lecture 6",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\n\nThe following DataFrames measure temperatures in two cities over two days.\n\n\ndf_wide = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday'],\n    'Miami': [80, 83],\n    'Rochester': [57, 62],\n    'St. Louis': [71, 75]\n})\n\ndf_long = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Wednesday'],\n    'City': ['Miami', 'Miami', 'Rochester', 'Rochester', 'St. Louis', 'St. Louis'],\n    'Temperature': [80, 83, 57, 62, 71, 75]\n})"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#long-vs.-wide-dataframes-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#long-vs.-wide-dataframes-1",
    "title": "Lecture 6",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nA DataFrame can store its values in wide or long format.\nThese names reflect the direction in which the data set expands as we add more values to it.\n\nA long DataFrame increases in height.\nA wide DataFrame increases in width."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#long-vs.-wide-dataframes-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#long-vs.-wide-dataframes-2",
    "title": "Lecture 6",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nThe optimal storage format for a DataFrame depends on the insight we are trying to glean from it.\n\nWe consider making DataFrames longer if one variable is spread across multiple columns.\nWe consider making DataFrames wider if one observation is spread across multiple rows."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-longer-with-melt",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-longer-with-melt",
    "title": "Lecture 6",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-longer-with-melt-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-longer-with-melt-1",
    "title": "Lecture 6",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the ‚Äúidentifier‚Äù."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-longer-with-melt-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-longer-with-melt-2",
    "title": "Lecture 6",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-longer-with-melt-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-longer-with-melt-3",
    "title": "Lecture 6",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\",\n          value_vars = ['Miami', 'Rochester'])\n)\n\n\nmelt() can take a few parameters:\n\nvalue_vars parameter allows us to select which specific columns we want to ‚Äúmelt‚Äù.\nBy default, it will melt all the columns not specified in the id_vars parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-wider-with-pivot",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#make-dataframe-wider-with-pivot",
    "title": "Lecture 6",
    "section": "Make DataFrame Wider with pivot()",
    "text": "Make DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the new variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#concatenate-with-different-indices",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#concatenate-with-different-indices",
    "title": "Lecture 6",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhat would happen when the row and column indices are not aligned?\nLet‚Äôs modify our DataFrames for the next few examples.\n\n# rename the columns of our dataframes\ndf1.columns = ['A', 'B', 'C', 'D']\ndf2.columns = ['E', 'F', 'G', 'H']\ndf3.columns = ['A', 'C', 'F', 'H']\n\nIf we try to concatenate these DataFrames as we did, the DataFrames now do much more than simply stack one on top of the other.\n\nrow_concat = pd.concat([df1, df2, df3])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#concatenate-with-different-indices-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#concatenate-with-different-indices-1",
    "title": "Lecture 6",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWe can set join = 'inner' to keep only the columns that are shared among the data sets.\n\npd.concat([df1, df2, df3], join ='inner')\n\nIf we use the DataFrames that have columns in common, only the columns that all of them share will be returned.\n\npd.concat([df1, df3], join ='inner',  ignore_index =False)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#concatenate-with-different-indices-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#concatenate-with-different-indices-2",
    "title": "Lecture 6",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nLet‚Äôs modify our DataFrames further.\n\n# re-indexing the rows of our DataFrames\ndf1.index = [0, 1, 2, 3]\ndf2.index = [4, 5, 6, 7]\ndf3.index = [0, 2, 5, 7]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#concatenate-with-different-indices-3",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#concatenate-with-different-indices-3",
    "title": "Lecture 6",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhen we concatenate along axis=\"columns\" (axis=1), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.\n\ncol_concat = pd.concat([df1, df2, df3], axis=\"columns\")\n\nJust as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using join=\"inner\".\n\npd.concat([df1, df3], axis =\"columns\", join='inner')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.locindex-labels",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.locindex-labels",
    "title": "Lecture 6",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n\n\nLet‚Äôs consider the nba with the Name index.\n\n# The two lines below are equivalent\nnba = nba.set_index(\"Name\")\nnba.set_index(\"Name\", inplace = True)\n\nBelow extracts observations:\n\n\nnba.loc[ \"LeBron James\" ]\nnba.loc[ [\"Kawhi Leonard\", \"Paul George\"] ]\n\nThe .loc attribute extracts an observation by index label (row name)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.locindex-labels-1",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.locindex-labels-1",
    "title": "Lecture 6",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n(\n    nba\n    .sort_index()\n    .loc[\"Otto Porter\":\"Patrick Beverley\"]\n)\n\nWhat is the above code doing?\n\nNote: Both the starting value and the ending value are inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.locindex-labels-2",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.locindex-labels-2",
    "title": "Lecture 6",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n\n\n(\n    nba\n    .sort_index()\n    .loc[\"Zach Collins\":]\n)\n\n(\n    nba\n    .sort_index()\n    .loc[:\"Al Horford\"]\n)\n\n\n\nWe can use loc[:] to pull rows:\n\nFrom the middle of the DataFrame to its end;\nFrom the beginning of the DataFrame to a specific index label."
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.ilocindex-positions",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#locating-observations-by-.ilocindex-positions",
    "title": "Lecture 6",
    "section": "Locating Observations by .iloc[Index Positions]",
    "text": "Locating Observations by .iloc[Index Positions]\n\n\nnba.iloc[ 300 ]\nnba.iloc[ [100, 200, 300, 400] ]\n\nnba.iloc[400:404]\nnba.iloc[:2]\nnba.iloc[447:]\nnba.iloc[-10:-6]\nnba.iloc[0:10:2] # every other rows\n\n\n\nThe .iloc (index location) attribute locates rows by index position.\n\nThis can be helpful when the position of rows has significance in our data set.\nWe pass integers.\n\nThe .iloc[:] is similar to the slicing syntax with strings/lists.\n\nThe end value is NOT inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dataframe-terminologies-variables-observations-and-values",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dataframe-terminologies-variables-observations-and-values",
    "title": "Lecture 7",
    "section": "DataFrame Terminologies: Variables, Observations, and Values",
    "text": "DataFrame Terminologies: Variables, Observations, and Values\n\n\n\n\nEach variable is a column.\nEach observation is a row.\nEach value is a cell."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dataframe-terminologies-dot-operators-methods-and-attributes",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dataframe-terminologies-dot-operators-methods-and-attributes",
    "title": "Lecture 7",
    "section": "DataFrame Terminologies: Dot Operators, Methods and Attributes",
    "text": "DataFrame Terminologies: Dot Operators, Methods and Attributes\nDot operator\n\nThe dot operator (DataFrame.) is used for an attribute or a method on objects.\n\n\n\nMethod\n\nA method (DataFrame.METHOD()) is a function that we can call on a DataFrame to perform operations, modify data, or derive insights.\n\ne.g., nba.info()\n\n\n\nAttribute\n\nAn attribute (DataFrame.ATTRIBUTE) is a property that provides information about the DataFrame‚Äôs structure or content without modifying it.\n\ne.g., nba.dtype"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#getting-a-summary-of-a-dataframe-with-.info",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#getting-a-summary-of-a-dataframe-with-.info",
    "title": "Lecture 7",
    "section": "Getting a Summary of a DataFrame with .info()",
    "text": "Getting a Summary of a DataFrame with .info()\n\n\nnba.info()    # method\n\nnba.shape     # attribute\nnba.dtypes    # attribute\nnba.columns   # attribute\nnba.count()   # method\n\n\n\nEvery DataFrame object has a .info() method that provides a summary of a DataFrame:\n\nVariable names (.columns)\nNumber of variables/observations (.shape)\nData type of each variable (.dtypes)\nNumber of non-missing values in each variable (.count())\n\nPandas often displays missing values as NaN."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#getting-a-summary-of-a-dataframe-with-.describe",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#getting-a-summary-of-a-dataframe-with-.describe",
    "title": "Lecture 7",
    "section": "Getting a Summary of a DataFrame with .describe()",
    "text": "Getting a Summary of a DataFrame with .describe()\nnba.describe()\nnba.describe(include='all')\n\n.describe() method generates descriptive statistics that summarize the central tendency, dispersion, and distribution of each variable.\n\nIt can also process string-type variables if specified explicitly (include='all')."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#selecting-a-variable-by-its-name",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#selecting-a-variable-by-its-name",
    "title": "Lecture 7",
    "section": "Selecting a Variable by its Name",
    "text": "Selecting a Variable by its Name\nnba_player_name_s = nba['Name']   # Series\nnba_player_name_s\n\nnba_player_name_df = nba[ ['Name'] ]   # DataFrame\nnba_player_name_df\n\nIf we want only a specific variable from a DataFrame, we can access the variable with its name using squared brackets, [ ].\n\nDataFrame[ 'var_1' ]\nDataFrame[ ['var_1'] ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#selecting-multiple-variables-by-their-names",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#selecting-multiple-variables-by-their-names",
    "title": "Lecture 7",
    "section": "Selecting Multiple Variables by their Names",
    "text": "Selecting Multiple Variables by their Names\nnba_player_name_team = nba[ ['Name', 'Team'] ]\nnba_player_name_team\n\nIn order to specify multiple variables by their names, we need to pass in a Python list between the square brackets.\n\nDataFrame[ ['var_1', 'var_2', ... ] ]\nThis is also how we can relocate variables by the order specified in the list."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#selecting-multiple-variables-with-select_dtypes",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#selecting-multiple-variables-with-select_dtypes",
    "title": "Lecture 7",
    "section": "Selecting Multiple Variables with select_dtypes()",
    "text": "Selecting Multiple Variables with select_dtypes()\n# To include only string variables\nnba.select_dtypes(include = \"object\")\n\n# To exclude string and integer variables\nnba.select_dtypes(exclude = [\"object\", \"int\"])\n\nWe can use the select_dtypes() method to select columns based on their data types.\n\nThe method accepts two parameters, include and exclude."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#counting-with-.count",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#counting-with-.count",
    "title": "Lecture 7",
    "section": "Counting with .count()",
    "text": "Counting with .count()\n\n\nnba['Salary'].count()\nnba[['Salary']].count()\n\n\n\nThe .count() counts the number of non-missing values in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#counting-with-.value_counts",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#counting-with-.value_counts",
    "title": "Lecture 7",
    "section": "Counting with .value_counts()",
    "text": "Counting with .value_counts()\n\n\nnba['Team'].value_counts()\n\nnba[['Team']].value_counts()\n\n\n\nThe .value_counts() counts the number of occurrences of each unique value in a Series/DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#counting-with-.nunique",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#counting-with-.nunique",
    "title": "Lecture 7",
    "section": "Counting with .nunique()",
    "text": "Counting with .nunique()\n\n\nnba[['Team']].nunique()\n\nnba.nunique()\n\n\n\nThe .nunique() counts the number of unique values in each variable in a DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics",
    "title": "Lecture 7",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 1-3 in Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-methods-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-methods-1",
    "title": "Lecture 7",
    "section": "Sorting Methods",
    "text": "Sorting Methods\n\n\nLet‚Äôs read nba.csv as nba.\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])\n                  \n# Below is to view the nba DataFrame and to get a summary of it\nnba\nnba.info()\nnba.describe( include=\"all\" )"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-a-single-variable-with-sort_values",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-a-single-variable-with-sort_values",
    "title": "Lecture 7",
    "section": "Sorting by a Single Variable with sort_values()",
    "text": "Sorting by a Single Variable with sort_values()\n# The two lines below are equivalent\nnba.sort_values([\"Name\"])\nnba.sort_values(by = [\"Name\"])\n\n\nThe sort_values() method‚Äôs first parameter, by, accepts the variables that pandas should use to sort observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-a-single-variable-with-sort_values-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-a-single-variable-with-sort_values-1",
    "title": "Lecture 7",
    "section": "Sorting by a Single Variable with sort_values()",
    "text": "Sorting by a Single Variable with sort_values()\nnba.sort_values([\"Name\"], ascending = False)\n\n\nThe sort_values() method‚Äôs ascending parameter determines the sort order.\n\nascending has a default argument of True.\nBy default, pandas will sort:\n\nA variable of numbers in increasing order;\nA variable of strings in alphabetical order;\nA variable of datetimes in chronological order."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-1",
    "title": "Lecture 7",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMethod Chaining\n(\n    nba\n    .sort_values(['Salary'])\n    .head(5)\n)\n\n\nDataFrame has various methods that modify the existing DataFrame.\nMethod Chaining: We can call methods sequentially without the need to store intermediate results."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest",
    "title": "Lecture 7",
    "section": "Sorting by a Single Variable with nsmallest() and nlargest()",
    "text": "Sorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(5, 'Salary')\nnba.nlargest(5, 'Salary')\n\nnsmallest() are useful to get the first n observations ordered by a variable in ascending order.\nnlargest() are useful to get the first n observations ordered by a variable in descending order."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest-1",
    "title": "Lecture 7",
    "section": "Sorting by a Single Variable with nsmallest() and nlargest()",
    "text": "Sorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(4, 'Salary', keep = \"all\")\nnba.nlargest(4, 'Salary', keep = \"all\")\n\nkeep = \"all\" keeps all duplicates, even it means selecting more than n observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-multiple-variables-with-sort_values",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-multiple-variables-with-sort_values",
    "title": "Lecture 7",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values([\"Team\", \"Name\"])\nnba.sort_values(by = [\"Team\", \"Name\"])\n\nWe can sort a DataFrame by multiple columns by passing a list to the by parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-multiple-variables-with-sort_values-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-multiple-variables-with-sort_values-1",
    "title": "Lecture 7",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = False)\n\nWe can pass a single Boolean to the ascending parameter to apply the same sort order to each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-multiple-variables-with-sort_values-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-multiple-variables-with-sort_values-2",
    "title": "Lecture 7",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = [False, True])\n\nIf we want to sort each variable in a different order, we can pass a Boolean list to the ascending parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-multiple-variables-with-sort_values-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-multiple-variables-with-sort_values-3",
    "title": "Lecture 7",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nQ. Which players on each team are paid the most?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-row-index-with-sort_index",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#sorting-by-row-index-with-sort_index",
    "title": "Lecture 7",
    "section": "Sorting by Row Index with sort_index()",
    "text": "Sorting by Row Index with sort_index()\n\n\n# Below lines are equivalent\nnba.sort_index()\nnba.sort_index(ascending = True)\n\nnba.sort_index(ascending = False)\n\n\n\nIf we assigned nba to nba DataFrame sorted by ‚ÄúName‚Äù, how can we return it to its original form of DataFrame?\n\nOur nba DataFrame still has its numeric index labels.\nsort_index() sorts observations by their index labels (row names)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#relocating-variables-with-sort_index",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#relocating-variables-with-sort_index",
    "title": "Lecture 7",
    "section": "Relocating Variables with sort_index()",
    "text": "Relocating Variables with sort_index()\n# The two lines below are equivalent\nnba.sort_index(axis = \"columns\")\nnba.sort_index(axis = 1)\n\nThe sort_index() method can also be used to change the order of variables in an alphabetical order.\n\nWe need to add an axis parameter and pass it an argument of \"columns\" or 1."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#setting-a-new-index-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#setting-a-new-index-1",
    "title": "Lecture 7",
    "section": "Setting a New Index",
    "text": "Setting a New Index\n\nWe can use the set_index() method when we want to change the current index of a DataFrame to one or more existing columns.\n\nThis is particularly useful when:\n\nWe have a column that uniquely identifies each observation (e.g., ID);\nWe sometimes want to use an unique identifier as the index for more efficient data wrangling."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#setting-a-new-index-with-set_index",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#setting-a-new-index-with-set_index",
    "title": "Lecture 7",
    "section": "Setting a New Index with set_index()",
    "text": "Setting a New Index with set_index()\n# The two lines below are equivalent\nnba.set_index(keys = \"Name\")\nnba.set_index(\"Name\")\n\nThe set_index() method returns a new DataFrame with a given column set as the index.\n\nIts first parameter, keys, accepts the column name."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#re-setting-an-index-with-reset_index",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#re-setting-an-index-with-reset_index",
    "title": "Lecture 7",
    "section": "Re-setting an Index with reset_index()",
    "text": "Re-setting an Index with reset_index()\nnba2 = nba.set_index(\"Name\")\nnba2.reset_index(inplace=True)    # Useful for the method chaining\n\nWe use the reset_index() method:\n\nWhen we want to convert the index back into a DataFrame column;\nWhen we need to reset the index to the default integer index.\n\nNote: With inplace=True, the operation alters the original DataFrame directly."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-1",
    "title": "Lecture 7",
    "section": "Locating Observations",
    "text": "Locating Observations\n\n\nLet‚Äôs read nba.csv as nba.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observationsvalues",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observationsvalues",
    "title": "Lecture 7",
    "section": "Locating Observations/Values",
    "text": "Locating Observations/Values\n\nWe can extract observations, variables, and values from a DataFrame by using the loc[] and iloc[] accessors.\n\nThese accessors work well when we know the index labels and positions of the observations/variables we want to target."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-by-.locindex-labels",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-by-.locindex-labels",
    "title": "Lecture 7",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n\n\nLet‚Äôs consider the nba with the Name index.\n\n# The two lines below are equivalent\nnba = nba.set_index(\"Name\")\nnba.set_index(\"Name\", inplace = True)\n\nBelow extracts observations:\n\n\nnba.loc[ \"LeBron James\" ]\nnba.loc[ [\"Kawhi Leonard\", \"Paul George\"] ]\n\nThe .loc attribute extracts an observation by index label (row name)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-by-.locindex-labels-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-by-.locindex-labels-1",
    "title": "Lecture 7",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n(\n    nba\n    .sort_index()\n    .loc[\"Otto Porter\":\"Patrick Beverley\"]\n)\n\nWhat is the above code doing?\n\nNote: Both the starting value and the ending value are inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-by-.locindex-labels-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-by-.locindex-labels-2",
    "title": "Lecture 7",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n\n\n(\n    nba\n    .sort_index()\n    .loc[\"Zach Collins\":]\n)\n\n(\n    nba\n    .sort_index()\n    .loc[:\"Al Horford\"]\n)\n\n\n\nWe can use loc[:] to pull rows:\n\nFrom the middle of the DataFrame to its end;\nFrom the beginning of the DataFrame to a specific index label."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-by-.ilocindex-positions",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#locating-observations-by-.ilocindex-positions",
    "title": "Lecture 7",
    "section": "Locating Observations by .iloc[Index Positions]",
    "text": "Locating Observations by .iloc[Index Positions]\n\n\nnba.iloc[ 300 ]\nnba.iloc[ [100, 200, 300, 400] ]\n\nnba.iloc[400:404]\nnba.iloc[:2]\nnba.iloc[447:]\nnba.iloc[-10:-6]\nnba.iloc[0:10:2] # every other rows\n\n\n\nThe .iloc (index location) attribute locates rows by index position.\n\nThis can be helpful when the position of rows has significance in our data set.\nWe pass integers.\n\nThe .iloc[:] is similar to the slicing syntax with strings/lists.\n\nThe end value is NOT inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-2",
    "title": "Lecture 7",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 4-7 in Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#locating-values-by-locrows-columns-or-ilocrows-columns",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#locating-values-by-locrows-columns-or-ilocrows-columns",
    "title": "Lecture 7",
    "section": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]",
    "text": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.loc[\n    \"LeBron James\",\n    \"Team\"\n]\n\nnba.loc[\n     \"James Harden\", \n      [\"Position\", \"Birthday\"] \n]\n\nnba.loc[\n    [\"Russell Westbrook\", \"Anthony Davis\"],\n     [\"Team\", \"Salary\"]\n]\n\nnba.loc[\n    \"Joel Embiid\", \n    \"Position\":\"Salary\"\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .loc, we have to provide the column names."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#locating-values-by-locrows-columns-or-ilocrows-columns-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#locating-values-by-locrows-columns-or-ilocrows-columns-1",
    "title": "Lecture 7",
    "section": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]",
    "text": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.iloc[\n    57, \n    3\n]\n\nnba.iloc[\n    100:104, \n    :3\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .iloc, we have to provide the column position."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#mathematical-operations",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#mathematical-operations",
    "title": "Lecture 7",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\nnba.max()\nnba.min()\n\nThe max() method returns a Series with the maximum value from each variable.\nThe min() method returns a Series with the minimum value from each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#mathematical-operations-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#mathematical-operations-1",
    "title": "Lecture 7",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\n\n\nnba.sum()\nnba.mean()\nnba.median()\nnba.quantile(0.75) # 0 to 1\nnba.std()\n\nnba.sum(numeric_only = True)\nnba.mean(numeric_only = True)\nnba.median(numeric_only = True)\nnba.quantile(0.75, numeric_only=True)\nnba.std(numeric_only = True)\n\n\n\nThe sum()/mean()/median() method returns a Series with the sum/mean/median of the values in each variable.\nThe quantile() method returns a Series with the percentile value of the values in each variable (e.g., 25th, 75th, 90th percentile).\nThe std() method returns a Series with the standard deviation of the values in each variable.\nTo limit the operation to numeric volumes, we can pass True to the sum()/mean()/median()/std() method‚Äôs numeric_only parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#vectorized-operations",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#vectorized-operations",
    "title": "Lecture 7",
    "section": "Vectorized Operations",
    "text": "Vectorized Operations\nnba[\"Salary_2x\"] = nba[\"Salary\"] + nba[\"Salary\"]\nnba[\"Name_w_Position\"] = nba[\"Name\"] + \" (\" + nba[\"Position\"] + \")\"\nnba[\"Salary_minus_Mean\"] = nba[\"Salary\"] - nba[\"Salary\"].mean()\n\npandas performs a vectorized operation on Series or a variable in DataFrame.\n\nThis means an element-by-element operation.\nThis enables us to apply functions and perform operations on the data efficiently, without the need for explicit loops."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#adding-and-removing-variables",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#adding-and-removing-variables",
    "title": "Lecture 7",
    "section": "Adding and Removing Variables",
    "text": "Adding and Removing Variables\n\n\nHere we use [] to add variables:\n\nnba['Salary_k'] = nba['Salary'] / 1000\nnba['Salary_2x'] = nba['Salary'] + nba['Salary']\nnba['Salary_3x'] = nba['Salary'] * 3"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#removing-variables-with-dropcolumns-...",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#removing-variables-with-dropcolumns-...",
    "title": "Lecture 7",
    "section": "Removing Variables with drop(columns = ... )",
    "text": "Removing Variables with drop(columns = ... )\n\n\nWe can use .drop(columns = ...) to drop variables:\n\nnba.drop(columns = \"Salary_k\")\nnba.drop(columns = [\"Salary_2x\", \"Salary_3x\"])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#renaming-variables-with-nba.columns",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#renaming-variables-with-nba.columns",
    "title": "Lecture 7",
    "section": "Renaming Variables with nba.columns",
    "text": "Renaming Variables with nba.columns\n\n\nDo you recall the .columns attribute?\n\nnba.columns\n\nWe can rename any or all of a DataFrame‚Äôs columns by assigning a list of new names to the attribute:\n\nnba.columns = [\"Team\", \"Position\", \"Date of Birth\", \"Income\"]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "title": "Lecture 7",
    "section": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )\nnba.rename( columns = { \"Date of Birth\": \"Birthday\" } )\n\nThe above rename() method renames the variable Date of Birth to Birthday."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#renaming-rows-with-rename-index-existing-one-new-one",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#renaming-rows-with-rename-index-existing-one-new-one",
    "title": "Lecture 7",
    "section": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )\nnba = nba.rename(\n    index = { \"LeBron James\": \"LeBron Raymone James\" }\n)\n\nThe above rename() method renames the observation LeBron James to LeBron Raymone James."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#relocating-variables-with-.columns.get_loc-.pop-and-.insert",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#relocating-variables-with-.columns.get_loc-.pop-and-.insert",
    "title": "Lecture 7",
    "section": "Relocating Variables with .columns.get_loc(), .pop(), and .insert()",
    "text": "Relocating Variables with .columns.get_loc(), .pop(), and .insert()\nref_var = nba.columns.get_loc('Team') \nvar_to_move = nba.pop('Salary')\nnba.insert(ref_var, 'Salary', var_to_move) # insert() directly alters 'nba'\n\nStep 1. DataFrame.columns.get_loc('Reference_Var')\n\nGet the integer position (right before the reference variable, ‚ÄòReference_Var‚Äô)\n\nStep 2. DataFrame.pop('Some_Var_To_Move')\n\nRemove the variable we want to relocate from the DataFrame and store it in a Series\n\nStep 3. DataFrame.insert(ref_var, 'Some_Var_To_Move', var_to_move)\n\nInsert the variable back into the DataFrame right after the reference variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-1",
    "title": "Lecture 7",
    "section": "Converting Data Types with the astype() Method",
    "text": "Converting Data Types with the astype() Method\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-2",
    "title": "Lecture 7",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\n\n\nWhat values are in the Mgmt variable?\n\n\nemp[\"Mgmt\"].astype(bool)\n\nThe astype() method converts a Series‚Äô values to a different data type.\n\nIt can accept a single argument: the new data type."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-3",
    "title": "Lecture 7",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Mgmt\"] = emp[\"Mgmt\"].astype(bool)\n\nThe above code overwrites the Mgmt variable with our new Series of Booleans."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-4",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-4",
    "title": "Lecture 7",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"].astype(int)\n\nThe above code tries to coerce the Salary variable‚Äôs values to integers with the astype() method.\n\nPandas is unable to convert the NaN values to integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#fill-missing-values-with-the-fillna-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#fill-missing-values-with-the-fillna-method",
    "title": "Lecture 7",
    "section": "Fill Missing Values with the fillna() method",
    "text": "Fill Missing Values with the fillna() method\nemp[\"Salary\"].fillna(0)\n\nThe fillna() method replaces a Series‚Äô missing values with the argument we pass in.\nThe above example provides a fill value of 0.\n\nNote that our choice of value can distort the data; 0 is passed solely for the sake of example."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-5",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-5",
    "title": "Lecture 7",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0).astype(int)\n\nThe above code overwrites the Salary variable with our new Series of integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-6",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-6",
    "title": "Lecture 7",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n\nPandas includes a special data type called a category,\n\nIt is ideal for a variable consisting of a small number of unique values relative to its total size.\nE.g., gender, weekdays, blood types, planets, and income groups."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-pd.to_datetime-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-pd.to_datetime-method",
    "title": "Lecture 7",
    "section": "Converting Data Types with the pd.to_datetime() method",
    "text": "Converting Data Types with the pd.to_datetime() method\n# Below two are equivalent:\nemp[\"Start Date\"] = pd.to_datetime(emp[\"Start Date\"])\nemp[\"Start Date\"] = emp[\"Start Date\"].astype('datetime64')\n\nThe pd.to_datetime() function is used to convert a Series, DataFrame, or a single variable of a DataFrame from its current data type into datetime format."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-7",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#converting-data-types-with-the-astype-method-7",
    "title": "Lecture 7",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\n\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0)\nemp = emp.astype({'Mgmt': 'bool', \n                  'Salary': 'int',\n                  'Gender': 'category',\n                  'Start Date': 'datetime64'})\n\nWe can provide a dictionary of variable-type pairs to astype()."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-3",
    "title": "Lecture 7",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Question 1 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-condition-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-condition-1",
    "title": "Lecture 7",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition",
    "title": "Lecture 7",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with ‚ÄúDonna‚Äù.\n\npandas performs a vectorized operation (element-by-element operation) on Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-1",
    "title": "Lecture 7",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-2",
    "title": "Lecture 7",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[ donnas ]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-3",
    "title": "Lecture 7",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to extract a subset of employees who are not on the ‚ÄúMarketing‚Äù team?\n\n\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not ‚ÄúMarketing‚Äù, and False indicates the Team value is ‚ÄúMarketing‚Äù"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-4",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-4",
    "title": "Lecture 7",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to retrieve all the managers in the company?\n\nManagers have a value of True in the Mgmt variable.\n\n\n\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-5",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-single-condition-5",
    "title": "Lecture 7",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-condition-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-condition-2",
    "title": "Lecture 7",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ] # '|' is 'or' opeartor\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria.\nWhat if our next report asked for employees from 30 teams instead of three?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-with-the-isin-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-with-the-isin-method",
    "title": "Lecture 7",
    "section": "Filtering with the isin() method",
    "text": "Filtering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[ on_star_teams ]\n\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, array, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-condition-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-condition-3",
    "title": "Lecture 7",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000.\n\n\n\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ] # '&' is 'and' opeartor\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-with-the-between-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-with-the-between-method",
    "title": "Lecture 7",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[ between_90k_and_100k ]\n\nA slightly cleaner solution is to use a method called between().\n\nIt returns a Boolean Series where True denotes that an observation‚Äôs value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-with-the-between-method-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-with-the-between-method-1",
    "title": "Lecture 7",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[ name_starts_with_t ]\n\nWe can also apply the between() method to string variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-condition-with-the-query-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#filtering-by-a-condition-with-the-query-method",
    "title": "Lecture 7",
    "section": "Filtering by a Condition with the query() method!",
    "text": "Filtering by a Condition with the query() method!\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 & `First Name` == 'Douglas'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\n\nquery() accepts a string value that describes filtering conditions.\n\nWhen using the query() method, if we have variable names with spaces, we can wrap the variable names in backtick (`)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-4",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-4",
    "title": "Lecture 7",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 2-6 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-1",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-2",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation‚Äôs value is missing.\n\nIs a value of a variable ‚ÄúXYZ‚Äù missing?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation‚Äôs value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values: The value_counts(dropna = False) method",
    "text": "Dealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values: The dropna() method",
    "text": "Dealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method-with-how",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method-with-how",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values: The dropna() method with how",
    "text": "Dealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter‚Äôs default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "title": "Lecture 7",
    "section": "Dealing with Missing Values: The dropna() method with thresh",
    "text": "Dealing with Missing Values: The dropna() method with thresh\nemp.dropna(thresh = 4)\n\nThe thresh parameter specifies a minimum threshold of non-missing values that an observation must have for pandas to keep it."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-duplicated-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-duplicated-method",
    "title": "Lecture 7",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "title": "Lecture 7",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method‚Äôs keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value.\n\nQ. How can we keep observations with the first occurrences of a value in the Team variable?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "title": "Lecture 7",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "title": "Lecture 7",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "title": "Lecture 7",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation‚Äôs uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "title": "Lecture 7",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "title": "Lecture 7",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value‚Äôs last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of ‚ÄúDouglas‚Äù and a Gender of ‚ÄúMale‚Äù. Then check which ‚ÄúDouglas‚Äù is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-5",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#pandas-basics-5",
    "title": "Lecture 7",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-1",
    "title": "Lecture 7",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nTidy DataFrames\n\n\n\n\nThere are three interrelated rules that make a DataFrame tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-2",
    "title": "Lecture 7",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nA DataFrame can be given in a format unsuited for the analysis that we would like to perform on it.\n\nA DataFrame may have larger structural problems that extend beyond the data.\nPerhaps the DataFrame stores its values in a format that makes it easy to extract a single row but difficult to aggregate the data.\n\nReshaping a DataFrame means manipulating it into a different shape.\nIn this section, we will discuss pandas techniques for molding a DataFrame into the shape we desire."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#long-vs.-wide-dataframes",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#long-vs.-wide-dataframes",
    "title": "Lecture 7",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\n\nThe following DataFrames measure temperatures in two cities over two days.\n\n\ndf_wide = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday'],\n    'Miami': [80, 83],\n    'Rochester': [57, 62],\n    'St. Louis': [71, 75]\n})\n\ndf_long = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Wednesday'],\n    'City': ['Miami', 'Miami', 'Rochester', 'Rochester', 'St. Louis', 'St. Louis'],\n    'Temperature': [80, 83, 57, 62, 71, 75]\n})"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#long-vs.-wide-dataframes-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#long-vs.-wide-dataframes-1",
    "title": "Lecture 7",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nA DataFrame can store its values in wide or long format.\nThese names reflect the direction in which the data set expands as we add more values to it.\n\nA long DataFrame increases in height.\nA wide DataFrame increases in width."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#long-vs.-wide-dataframes-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#long-vs.-wide-dataframes-2",
    "title": "Lecture 7",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nThe optimal storage format for a DataFrame depends on the insight we are trying to glean from it.\n\nWe consider making DataFrames longer if one variable is spread across multiple columns.\nWe consider making DataFrames wider if one observation is spread across multiple rows."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-3",
    "title": "Lecture 7",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nmelt() and pivot()\n\n\n\n\nmelt() makes DataFrame longer.\npivot() and pivot_table() make DataFrame wider."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-longer-with-melt",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-longer-with-melt",
    "title": "Lecture 7",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-longer-with-melt-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-longer-with-melt-1",
    "title": "Lecture 7",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the ‚Äúidentifier‚Äù."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-longer-with-melt-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-longer-with-melt-2",
    "title": "Lecture 7",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-longer-with-melt-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-longer-with-melt-3",
    "title": "Lecture 7",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\",\n          value_vars = ['Miami', 'Rochester'])\n)\n\n\nmelt() can take a few parameters:\n\nvalue_vars parameter allows us to select which specific columns we want to ‚Äúmelt‚Äù.\nBy default, it will melt all the columns not specified in the id_vars parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-wider-with-pivot",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#make-dataframe-wider-with-pivot",
    "title": "Lecture 7",
    "section": "Make DataFrame Wider with pivot()",
    "text": "Make DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the new variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-4",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-4",
    "title": "Lecture 7",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-5",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-5",
    "title": "Lecture 7",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-6",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#reshaping-dataframes-6",
    "title": "Lecture 7",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet‚Äôs do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-1",
    "title": "Lecture 7",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more DataFrames based on common data values in those DataFrames.\n\nThis task is known in the database world as performing a ‚Äújoin.‚Äù\nWe can do this with the merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-2",
    "title": "Lecture 7",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\n\nThe variables that are used to connect each pair of tables are called keys."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-1",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nInner Join\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n# the default value for 'how' is 'inner'\n# so it doesn't actually need to be specified\nmerge_inner = pd.merge(x, y, on='key', how='inner')\nmerge_inner_x = x.merge(y, on='key', how='inner')\nmerge_inner_x_how = x.merge(y, on='key')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-2",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLeft Join\n\nA left join keeps all observations in x.\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-3",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nRight Join\n\nA right join keeps all observations in y.\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-4",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-4",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nOuter (Full) Join\n\nA full join keeps all observations in x and y.\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-5",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-5",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: one-to-many\n\nOne DataFrame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key':[1, 2, 2, 3],\n    'val_x':['x1', 'x2', 'x3', 'x4']})\n\ny = pd.DataFrame({\n    'key':[1, 2],\n    'val_y':['y1', 'y2'] })\none_to_many = x.merge(y, on='key', \n                         how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-6",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-6",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: many-to-many\n\nBoth DataFrames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key':[1, 2, 2, 3],\n  'val_x':['x1','x2','x3','x4']})\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', \n                          how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-7",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-7",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDefining the key columns\n\n\nIf the left and right columns do not have the same name for the key variables, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = \n  x.merge(y, left_on = 'key_x', \n             right_on = 'key_y', \n             how = 'left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-8",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#joining-dataframes-with-merge-8",
    "title": "Lecture 7",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLet‚Äôs do Part 2 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-1",
    "title": "Lecture 7",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\n\nConcatenation can be thought of as appending a row or column to our data.\n\nThis approach is possible if our data was split into parts or if we performed a calculation that we want to append to our existing data set.\n\nLet‚Äôs consider the following example DataFrames:\n\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-2",
    "title": "Lecture 7",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nConcatenating the DataFrames on top of each other uses the concat() method.\n\nAll of the DataFrames to be concatenated are passed in a list.\n\n\nrow_concat = pd.concat([df1, df2, df3])\nrow_concat"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-3",
    "title": "Lecture 7",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nLet‚Äôs consider a new Series and concatenate it with df1:\n\n# create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\nnew_row_series\n\n\n# attempt to add the new row to a dataframe\ndf = pd.concat([df1, new_row_series])\ndf\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-4",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-4",
    "title": "Lecture 7",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nTo fix the problem, we need turn our Series into a DataFrame.\n\nThis data frame contains one row of data, and the column names are the ones the data will bind to.\n\n\nnew_row_df = pd.DataFrame(\n  # note the double brackets to create a \"row\" of data\n  data =[[\"n1\", \"n2\", \"n3\", \"n4\"]],\n  columns =[\"A\", \"B\", \"C\", \"D\"],\n)\n\ndf = pd.concat([df1, new_row_df])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-5",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-5",
    "title": "Lecture 7",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nConcatenating columns is very similar to concatenating rows.\n\nThe main difference is the axis parameter in the concat() method.\nThe default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion.\nIf we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\n\n\ncol_concat = pd.concat([df1, df2, df3], axis = \"columns\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-6",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-6",
    "title": "Lecture 7",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nWe can use ignore_index=True to reset the column indices, so that we do not have duplicated column names.\n\npd.concat([df1, df2, df3], axis=\"columns\", ignore_index=True)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#concatenate-with-different-indices",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#concatenate-with-different-indices",
    "title": "Lecture 7",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhat would happen when the row and column indices are not aligned?\nLet‚Äôs modify our DataFrames for the next few examples.\n\n# rename the columns of our dataframes\ndf1.columns = ['A', 'B', 'C', 'D']\ndf2.columns = ['E', 'F', 'G', 'H']\ndf3.columns = ['A', 'C', 'F', 'H']\n\nIf we try to concatenate these DataFrames as we did, the DataFrames now do much more than simply stack one on top of the other.\n\nrow_concat = pd.concat([df1, df2, df3])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#concatenate-with-different-indices-1",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#concatenate-with-different-indices-1",
    "title": "Lecture 7",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWe can set join = 'inner' to keep only the columns that are shared among the data sets.\n\npd.concat([df1, df2, df3], join ='inner')\n\nIf we use the DataFrames that have columns in common, only the columns that all of them share will be returned.\n\npd.concat([df1, df3], join ='inner',  ignore_index =False)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#concatenate-with-different-indices-2",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#concatenate-with-different-indices-2",
    "title": "Lecture 7",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nLet‚Äôs modify our DataFrames further.\n\n# re-indexing the rows of our DataFrames\ndf1.index = [0, 1, 2, 3]\ndf2.index = [4, 5, 6, 7]\ndf3.index = [0, 2, 5, 7]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#concatenate-with-different-indices-3",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#concatenate-with-different-indices-3",
    "title": "Lecture 7",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhen we concatenate along axis=\"columns\" (axis=1), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.\n\ncol_concat = pd.concat([df1, df2, df3], axis=\"columns\")\n\nJust as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using join=\"inner\".\n\npd.concat([df1, df3], axis =\"columns\", join='inner')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-7",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#data-concatenation-7",
    "title": "Lecture 7",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet‚Äôs do Part 3 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#dataframe-terminologies",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#dataframe-terminologies",
    "title": "Lecture 7",
    "section": "DataFrame Terminologies",
    "text": "DataFrame Terminologies\nDot Operators, Methods, and Attributes\nDot operator\n\nThe dot operator (DataFrame.) is used for an attribute or a method on objects.\n\n\n\nMethod\n\nA method (DataFrame.METHOD()) is a function that we can call on a DataFrame to perform operations, modify data, or derive insights.\n\ne.g., nba.info()\n\n\n\nAttribute\n\nAn attribute (DataFrame.ATTRIBUTE) is a property that provides information about the DataFrame‚Äôs structure or content without modifying it.\n\ne.g., nba.dtype"
  },
  {
    "objectID": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics",
    "href": "danl-lec/danl-210-lec-06-2025-0210.html#pandas-basics",
    "title": "Lecture 6",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLearning Objectives\n\nLoading DataFrame with read_csv()\nGetting a Summary with info() and describe()\nSelecting and Relocating Variables with []\nCounting Values with value_counts(), nunique(), and count()\nSorting with sort_values() and sort_index()\nIndexing with set_index() and reset_index()\nLocating Observations and Values with loc[] and iloc[]\nMathematical & Vectorized Operations\nAdding, Removing, and Renaming Variables\nConverting Data Types with .astype()\nFiltering Observations"
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#getting-a-summary-of-a-dataframe",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#getting-a-summary-of-a-dataframe",
    "title": "Lecture 7",
    "section": "Getting a Summary of a DataFrame",
    "text": "Getting a Summary of a DataFrame\n\n\nnba.info()    # method\n\nnba.shape     # attribute\nnba.dtypes    # attribute\nnba.columns   # attribute\nnba.count()   # method\n\n\n\nEvery DataFrame object has a .info() method that provides a summary of a DataFrame:\n\nVariable names (.columns)\nNumber of variables/observations (.shape)\nData type of each variable (.dtypes)\nNumber of non-missing values in each variable (.count())\n\nPandas often displays missing values as NaN."
  },
  {
    "objectID": "danl-lec/danl-210-lec-07-2025-0212.html#nba-dataframe",
    "href": "danl-lec/danl-210-lec-07-2025-0212.html#nba-dataframe",
    "title": "Lecture 7",
    "section": "nba DataFrame",
    "text": "nba DataFrame\n\n\nLet‚Äôs read the nba.csv file as nba:\n\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#nba-dataframe",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#nba-dataframe",
    "title": "Lecture 8",
    "section": "nba DataFrame",
    "text": "nba DataFrame\n\n\nLet‚Äôs read the nba.csv file as nba:\n\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-a-single-variable-with-sort_values",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-a-single-variable-with-sort_values",
    "title": "Lecture 8",
    "section": "Sorting by a Single Variable with sort_values()",
    "text": "Sorting by a Single Variable with sort_values()\n# The two lines below are equivalent\nnba.sort_values([\"Name\"])\nnba.sort_values(by = [\"Name\"])\n\n\nThe sort_values() method‚Äôs first parameter, by, accepts the variables that pandas should use to sort observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-a-single-variable-with-sort_values-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-a-single-variable-with-sort_values-1",
    "title": "Lecture 8",
    "section": "Sorting by a Single Variable with sort_values()",
    "text": "Sorting by a Single Variable with sort_values()\nnba.sort_values([\"Name\"], ascending = False)\n\n\nThe sort_values() method‚Äôs ascending parameter determines the sort order.\n\nascending has a default argument of True.\nBy default, pandas will sort:\n\nA variable of numbers in increasing order;\nA variable of strings in alphabetical order;\nA variable of datetimes in chronological order."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics",
    "title": "Lecture 8",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nMethod Chaining\n(\n    nba\n    .sort_values(['Salary'])\n    .head(5)\n)\n\n\nDataFrame has various methods that modify the existing DataFrame.\nMethod Chaining: We can call methods sequentially without the need to store intermediate results."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest",
    "title": "Lecture 8",
    "section": "Sorting by a Single Variable with nsmallest() and nlargest()",
    "text": "Sorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(5, 'Salary')\nnba.nlargest(5, 'Salary')\n\nnsmallest() are useful to get the first n observations ordered by a variable in ascending order.\nnlargest() are useful to get the first n observations ordered by a variable in descending order."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-a-single-variable-with-nsmallest-and-nlargest-1",
    "title": "Lecture 8",
    "section": "Sorting by a Single Variable with nsmallest() and nlargest()",
    "text": "Sorting by a Single Variable with nsmallest() and nlargest()\nnba.nsmallest(4, 'Salary', keep = \"all\")\nnba.nlargest(4, 'Salary', keep = \"all\")\n\nkeep = \"all\" keeps all duplicates, even it means selecting more than n observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-multiple-variables-with-sort_values",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-multiple-variables-with-sort_values",
    "title": "Lecture 8",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values([\"Team\", \"Name\"])\nnba.sort_values(by = [\"Team\", \"Name\"])\n\nWe can sort a DataFrame by multiple columns by passing a list to the by parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-multiple-variables-with-sort_values-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-multiple-variables-with-sort_values-1",
    "title": "Lecture 8",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = False)\n\nWe can pass a single Boolean to the ascending parameter to apply the same sort order to each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-multiple-variables-with-sort_values-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-multiple-variables-with-sort_values-2",
    "title": "Lecture 8",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nnba.sort_values(by = [\"Team\", \"Name\"], \n                ascending = [False, True])\n\nIf we want to sort each variable in a different order, we can pass a Boolean list to the ascending parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-multiple-variables-with-sort_values-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-multiple-variables-with-sort_values-3",
    "title": "Lecture 8",
    "section": "Sorting by Multiple Variables with sort_values()",
    "text": "Sorting by Multiple Variables with sort_values()\nQ. Which players on each team are paid the most?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-row-index-with-sort_index",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#sorting-by-row-index-with-sort_index",
    "title": "Lecture 8",
    "section": "Sorting by Row Index with sort_index()",
    "text": "Sorting by Row Index with sort_index()\n\n\n# Below lines are equivalent\nnba.sort_index()\nnba.sort_index(ascending = True)\n\nnba.sort_index(ascending = False)\n\n\n\nIf we assigned nba to nba DataFrame sorted by ‚ÄúName‚Äù, how can we return it to its original form of DataFrame?\n\nOur nba DataFrame still has its numeric index labels.\nsort_index() sorts observations by their index labels (row names)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#relocating-variables-with-sort_index",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#relocating-variables-with-sort_index",
    "title": "Lecture 8",
    "section": "Relocating Variables with sort_index()",
    "text": "Relocating Variables with sort_index()\n# The two lines below are equivalent\nnba.sort_index(axis = \"columns\")\nnba.sort_index(axis = 1)\n\nThe sort_index() method can also be used to change the order of variables in an alphabetical order.\n\nWe need to add an axis parameter and pass it an argument of \"columns\" or 1."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#setting-a-new-index-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#setting-a-new-index-1",
    "title": "Lecture 8",
    "section": "Setting a New Index",
    "text": "Setting a New Index\n\nWe can use the set_index() method when we want to change the current index of a DataFrame to one or more existing columns.\n\nThis is particularly useful when:\n\nWe have a column that uniquely identifies each observation (e.g., ID);\nWe sometimes want to use an unique identifier as the index for more efficient data wrangling."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#setting-a-new-index-with-set_index",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#setting-a-new-index-with-set_index",
    "title": "Lecture 8",
    "section": "Setting a New Index with set_index()",
    "text": "Setting a New Index with set_index()\n# The two lines below are equivalent\nnba.set_index(keys = \"Name\")\nnba.set_index(\"Name\")\n\nThe set_index() method returns a new DataFrame with a given column set as the index.\n\nIts first parameter, keys, accepts the column name."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#re-setting-an-index-with-reset_index",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#re-setting-an-index-with-reset_index",
    "title": "Lecture 8",
    "section": "Re-setting an Index with reset_index()",
    "text": "Re-setting an Index with reset_index()\nnba2 = nba.set_index(\"Name\")\nnba2.reset_index(inplace=True)    # Useful for the method chaining\n\nWe use the reset_index() method:\n\nWhen we want to convert the index back into a DataFrame column;\nWhen we need to reset the index to the default integer index.\n\nNote: With inplace=True, the operation alters the original DataFrame directly."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-1",
    "title": "Lecture 8",
    "section": "Locating Observations",
    "text": "Locating Observations\n\n\nLet‚Äôs read nba.csv as nba.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observationsvalues",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observationsvalues",
    "title": "Lecture 8",
    "section": "Locating Observations/Values",
    "text": "Locating Observations/Values\n\nWe can extract observations, variables, and values from a DataFrame by using the loc[] and iloc[] accessors.\n\nThese accessors work well when we know the index labels and positions of the observations/variables we want to target."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-by-.locindex-labels",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-by-.locindex-labels",
    "title": "Lecture 8",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n\n\nLet‚Äôs consider the nba with the Name index.\n\n# The two lines below are equivalent\nnba = nba.set_index(\"Name\")\nnba.set_index(\"Name\", inplace = True)\n\nBelow extracts observations:\n\n\nnba.loc[ \"LeBron James\" ]\nnba.loc[ [\"Kawhi Leonard\", \"Paul George\"] ]\n\nThe .loc attribute extracts an observation by index label (row name)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-by-.locindex-labels-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-by-.locindex-labels-1",
    "title": "Lecture 8",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n(\n    nba\n    .sort_index()\n    .loc[\"Otto Porter\":\"Patrick Beverley\"]\n)\n\nWhat is the above code doing?\n\nNote: Both the starting value and the ending value are inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-by-.locindex-labels-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-by-.locindex-labels-2",
    "title": "Lecture 8",
    "section": "Locating Observations by .loc[Index Labels]",
    "text": "Locating Observations by .loc[Index Labels]\n\n\n(\n    nba\n    .sort_index()\n    .loc[\"Zach Collins\":]\n)\n\n(\n    nba\n    .sort_index()\n    .loc[:\"Al Horford\"]\n)\n\n\n\nWe can use loc[:] to pull rows:\n\nFrom the middle of the DataFrame to its end;\nFrom the beginning of the DataFrame to a specific index label."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-by-.ilocindex-positions",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#locating-observations-by-.ilocindex-positions",
    "title": "Lecture 8",
    "section": "Locating Observations by .iloc[Index Positions]",
    "text": "Locating Observations by .iloc[Index Positions]\n\n\nnba.iloc[ 300 ]\nnba.iloc[ [100, 200, 300, 400] ]\n\nnba.iloc[400:404]\nnba.iloc[:2]\nnba.iloc[447:]\nnba.iloc[-10:-6]\nnba.iloc[0:10:2] # every other rows\n\n\n\nThe .iloc (index location) attribute locates rows by index position.\n\nThis can be helpful when the position of rows has significance in our data set.\nWe pass integers.\n\nThe .iloc[:] is similar to the slicing syntax with strings/lists.\n\nThe end value is NOT inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics-1",
    "title": "Lecture 8",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 4-7 in Classwork 5!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#locating-values-by-locrows-columns-or-ilocrows-columns",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#locating-values-by-locrows-columns-or-ilocrows-columns",
    "title": "Lecture 8",
    "section": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]",
    "text": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.loc[\n    \"LeBron James\",\n    \"Team\"\n]\n\nnba.loc[\n     \"James Harden\", \n      [\"Position\", \"Birthday\"] \n]\n\nnba.loc[\n    [\"Russell Westbrook\", \"Anthony Davis\"],\n     [\"Team\", \"Salary\"]\n]\n\nnba.loc[\n    \"Joel Embiid\", \n    \"Position\":\"Salary\"\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .loc, we have to provide the column names."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#locating-values-by-locrows-columns-or-ilocrows-columns-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#locating-values-by-locrows-columns-or-ilocrows-columns-1",
    "title": "Lecture 8",
    "section": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]",
    "text": "Locating Values by loc[Rows, Columns] or iloc[Rows, Columns]\n\n\nnba.iloc[\n    57, \n    3\n]\n\nnba.iloc[\n    100:104, \n    :3\n]\n\n\n\nBoth the .loc and .iloc attributes accept a second argument representing the column(s) to extract.\n\nIf we are using .iloc, we have to provide the column position."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#mathematical-operations",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#mathematical-operations",
    "title": "Lecture 8",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\nnba.max()\nnba.min()\n\nThe max() method returns a Series with the maximum value from each variable.\nThe min() method returns a Series with the minimum value from each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#mathematical-operations-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#mathematical-operations-1",
    "title": "Lecture 8",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\n\n\nnba.sum()\nnba.mean()\nnba.median()\nnba.quantile(0.75) # 0 to 1\nnba.std()\n\nnba.sum(numeric_only = True)\nnba.mean(numeric_only = True)\nnba.median(numeric_only = True)\nnba.quantile(0.75, numeric_only=True)\nnba.std(numeric_only = True)\n\n\n\nThe sum()/mean()/median() method returns a Series with the sum/mean/median of the values in each variable.\nThe quantile() method returns a Series with the percentile value of the values in each variable (e.g., 25th, 75th, 90th percentile).\nThe std() method returns a Series with the standard deviation of the values in each variable.\nTo limit the operation to numeric volumes, we can pass True to the sum()/mean()/median()/std() method‚Äôs numeric_only parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#vectorized-operations",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#vectorized-operations",
    "title": "Lecture 8",
    "section": "Vectorized Operations",
    "text": "Vectorized Operations\nnba[\"Salary_2x\"] = nba[\"Salary\"] + nba[\"Salary\"]\nnba[\"Name_w_Position\"] = nba[\"Name\"] + \" (\" + nba[\"Position\"] + \")\"\nnba[\"Salary_minus_Mean\"] = nba[\"Salary\"] - nba[\"Salary\"].mean()\n\npandas performs a vectorized operation on Series or a variable in DataFrame.\n\nThis means an element-by-element operation.\nThis enables us to apply functions and perform operations on the data efficiently, without the need for explicit loops."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#adding-and-removing-variables",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#adding-and-removing-variables",
    "title": "Lecture 8",
    "section": "Adding and Removing Variables",
    "text": "Adding and Removing Variables\n\n\nHere we use [] to add variables:\n\nnba['Salary_k'] = nba['Salary'] / 1000\nnba['Salary_2x'] = nba['Salary'] + nba['Salary']\nnba['Salary_3x'] = nba['Salary'] * 3"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#removing-variables-with-dropcolumns-...",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#removing-variables-with-dropcolumns-...",
    "title": "Lecture 8",
    "section": "Removing Variables with drop(columns = ... )",
    "text": "Removing Variables with drop(columns = ... )\n\n\nWe can use .drop(columns = ...) to drop variables:\n\nnba.drop(columns = \"Salary_k\")\nnba.drop(columns = [\"Salary_2x\", \"Salary_3x\"])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#renaming-variables-with-nba.columns",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#renaming-variables-with-nba.columns",
    "title": "Lecture 8",
    "section": "Renaming Variables with nba.columns",
    "text": "Renaming Variables with nba.columns\n\n\nDo you recall the .columns attribute?\n\nnba.columns\n\nWe can rename any or all of a DataFrame‚Äôs columns by assigning a list of new names to the attribute:\n\nnba.columns = [\"Team\", \"Position\", \"Date of Birth\", \"Income\"]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "title": "Lecture 8",
    "section": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )\nnba.rename( columns = { \"Date of Birth\": \"Birthday\" } )\n\nThe above rename() method renames the variable Date of Birth to Birthday."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#renaming-rows-with-rename-index-existing-one-new-one",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#renaming-rows-with-rename-index-existing-one-new-one",
    "title": "Lecture 8",
    "section": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )\nnba = nba.rename(\n    index = { \"LeBron James\": \"LeBron Raymone James\" }\n)\n\nThe above rename() method renames the observation LeBron James to LeBron Raymone James."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#relocating-variables-with-.columns.get_loc-.pop-and-.insert",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#relocating-variables-with-.columns.get_loc-.pop-and-.insert",
    "title": "Lecture 8",
    "section": "Relocating Variables with .columns.get_loc(), .pop(), and .insert()",
    "text": "Relocating Variables with .columns.get_loc(), .pop(), and .insert()\nref_var = nba.columns.get_loc('Team') \nvar_to_move = nba.pop('Salary')\nnba.insert(ref_var, 'Salary', var_to_move) # insert() directly alters 'nba'\n\nStep 1. DataFrame.columns.get_loc('Reference_Var')\n\nGet the integer position (right before the reference variable, ‚ÄòReference_Var‚Äô)\n\nStep 2. DataFrame.pop('Some_Var_To_Move')\n\nRemove the variable we want to relocate from the DataFrame and store it in a Series\n\nStep 3. DataFrame.insert(ref_var, 'Some_Var_To_Move', var_to_move)\n\nInsert the variable back into the DataFrame right after the reference variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-1",
    "title": "Lecture 8",
    "section": "Converting Data Types with the astype() Method",
    "text": "Converting Data Types with the astype() Method\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-2",
    "title": "Lecture 8",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\n\n\nWhat values are in the Mgmt variable?\n\n\nemp[\"Mgmt\"].astype(bool)\n\nThe astype() method converts a Series‚Äô values to a different data type.\n\nIt can accept a single argument: the new data type."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-3",
    "title": "Lecture 8",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Mgmt\"] = emp[\"Mgmt\"].astype(bool)\n\nThe above code overwrites the Mgmt variable with our new Series of Booleans."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-4",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-4",
    "title": "Lecture 8",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"].astype(int)\n\nThe above code tries to coerce the Salary variable‚Äôs values to integers with the astype() method.\n\nPandas is unable to convert the NaN values to integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#fill-missing-values-with-the-fillna-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#fill-missing-values-with-the-fillna-method",
    "title": "Lecture 8",
    "section": "Fill Missing Values with the fillna() method",
    "text": "Fill Missing Values with the fillna() method\nemp[\"Salary\"].fillna(0)\n\nThe fillna() method replaces a Series‚Äô missing values with the argument we pass in.\nThe above example provides a fill value of 0.\n\nNote that our choice of value can distort the data; 0 is passed solely for the sake of example."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-5",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-5",
    "title": "Lecture 8",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0).astype(int)\n\nThe above code overwrites the Salary variable with our new Series of integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-6",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-6",
    "title": "Lecture 8",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n\nPandas includes a special data type called a category,\n\nIt is ideal for a variable consisting of a small number of unique values relative to its total size.\nE.g., gender, weekdays, blood types, planets, and income groups."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-pd.to_datetime-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-pd.to_datetime-method",
    "title": "Lecture 8",
    "section": "Converting Data Types with the pd.to_datetime() method",
    "text": "Converting Data Types with the pd.to_datetime() method\n# Below two are equivalent:\nemp[\"Start Date\"] = pd.to_datetime(emp[\"Start Date\"])\nemp[\"Start Date\"] = emp[\"Start Date\"].astype('datetime64')\n\nThe pd.to_datetime() function is used to convert a Series, DataFrame, or a single variable of a DataFrame from its current data type into datetime format."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-7",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#converting-data-types-with-the-astype-method-7",
    "title": "Lecture 8",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\n\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0)\nemp = emp.astype({'Mgmt': 'bool', \n                  'Salary': 'int',\n                  'Gender': 'category',\n                  'Start Date': 'datetime64'})\n\nWe can provide a dictionary of variable-type pairs to astype()."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics-2",
    "title": "Lecture 8",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Question 1 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-condition-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-condition-1",
    "title": "Lecture 8",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition",
    "title": "Lecture 8",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with ‚ÄúDonna‚Äù.\n\npandas performs a vectorized operation (element-by-element operation) on Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-1",
    "title": "Lecture 8",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-2",
    "title": "Lecture 8",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[ donnas ]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-3",
    "title": "Lecture 8",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to extract a subset of employees who are not on the ‚ÄúMarketing‚Äù team?\n\n\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not ‚ÄúMarketing‚Äù, and False indicates the Team value is ‚ÄúMarketing‚Äù"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-4",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-4",
    "title": "Lecture 8",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to retrieve all the managers in the company?\n\nManagers have a value of True in the Mgmt variable.\n\n\n\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-5",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-single-condition-5",
    "title": "Lecture 8",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-condition-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-condition-2",
    "title": "Lecture 8",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ] # '|' is 'or' opeartor\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria.\nWhat if our next report asked for employees from 30 teams instead of three?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-with-the-isin-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-with-the-isin-method",
    "title": "Lecture 8",
    "section": "Filtering with the isin() method",
    "text": "Filtering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[ on_star_teams ]\n\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, array, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-condition-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-condition-3",
    "title": "Lecture 8",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000.\n\n\n\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ] # '&' is 'and' opeartor\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-with-the-between-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-with-the-between-method",
    "title": "Lecture 8",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[ between_90k_and_100k ]\n\nA slightly cleaner solution is to use a method called between().\n\nIt returns a Boolean Series where True denotes that an observation‚Äôs value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-with-the-between-method-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-with-the-between-method-1",
    "title": "Lecture 8",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[ name_starts_with_t ]\n\nWe can also apply the between() method to string variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-condition-with-the-query-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#filtering-by-a-condition-with-the-query-method",
    "title": "Lecture 8",
    "section": "Filtering by a Condition with the query() method!",
    "text": "Filtering by a Condition with the query() method!\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 & `First Name` == 'Douglas'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\n\nquery() accepts a string value that describes filtering conditions.\n\nWhen using the query() method, if we have variable names with spaces, we can wrap the variable names in backtick (`)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics-3",
    "title": "Lecture 8",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 2-6 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-1",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-2",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation‚Äôs value is missing.\n\nIs a value of a variable ‚ÄúXYZ‚Äù missing?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation‚Äôs value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values: The value_counts(dropna = False) method",
    "text": "Dealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values: The dropna() method",
    "text": "Dealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method-with-how",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method-with-how",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values: The dropna() method with how",
    "text": "Dealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter‚Äôs default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "title": "Lecture 8",
    "section": "Dealing with Missing Values: The dropna() method with thresh",
    "text": "Dealing with Missing Values: The dropna() method with thresh\nemp.dropna(thresh = 4)\n\nThe thresh parameter specifies a minimum threshold of non-missing values that an observation must have for pandas to keep it."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-duplicated-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-duplicated-method",
    "title": "Lecture 8",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "title": "Lecture 8",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method‚Äôs keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value.\n\nQ. How can we keep observations with the first occurrences of a value in the Team variable?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "title": "Lecture 8",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "title": "Lecture 8",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "title": "Lecture 8",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation‚Äôs uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "title": "Lecture 8",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "title": "Lecture 8",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value‚Äôs last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of ‚ÄúDouglas‚Äù and a Gender of ‚ÄúMale‚Äù. Then check which ‚ÄúDouglas‚Äù is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics-4",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#pandas-basics-4",
    "title": "Lecture 8",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-1",
    "title": "Lecture 8",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nTidy DataFrames\n\n\n\n\nThere are three interrelated rules that make a DataFrame tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-2",
    "title": "Lecture 8",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nA DataFrame can be given in a format unsuited for the analysis that we would like to perform on it.\n\nA DataFrame may have larger structural problems that extend beyond the data.\nPerhaps the DataFrame stores its values in a format that makes it easy to extract a single row but difficult to aggregate the data.\n\nReshaping a DataFrame means manipulating it into a different shape.\nIn this section, we will discuss pandas techniques for molding a DataFrame into the shape we desire."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#long-vs.-wide-dataframes",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#long-vs.-wide-dataframes",
    "title": "Lecture 8",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\n\nThe following DataFrames measure temperatures in two cities over two days.\n\n\ndf_wide = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday'],\n    'Miami': [80, 83],\n    'Rochester': [57, 62],\n    'St. Louis': [71, 75]\n})\n\ndf_long = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Wednesday'],\n    'City': ['Miami', 'Miami', 'Rochester', 'Rochester', 'St. Louis', 'St. Louis'],\n    'Temperature': [80, 83, 57, 62, 71, 75]\n})"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#long-vs.-wide-dataframes-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#long-vs.-wide-dataframes-1",
    "title": "Lecture 8",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nA DataFrame can store its values in wide or long format.\nThese names reflect the direction in which the data set expands as we add more values to it.\n\nA long DataFrame increases in height.\nA wide DataFrame increases in width."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#long-vs.-wide-dataframes-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#long-vs.-wide-dataframes-2",
    "title": "Lecture 8",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nThe optimal storage format for a DataFrame depends on the insight we are trying to glean from it.\n\nWe consider making DataFrames longer if one variable is spread across multiple columns.\nWe consider making DataFrames wider if one observation is spread across multiple rows."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-3",
    "title": "Lecture 8",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nmelt() and pivot()\n\n\n\n\nmelt() makes DataFrame longer.\npivot() and pivot_table() make DataFrame wider."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-longer-with-melt",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-longer-with-melt",
    "title": "Lecture 8",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-longer-with-melt-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-longer-with-melt-1",
    "title": "Lecture 8",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the ‚Äúidentifier‚Äù."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-longer-with-melt-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-longer-with-melt-2",
    "title": "Lecture 8",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-longer-with-melt-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-longer-with-melt-3",
    "title": "Lecture 8",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\",\n          value_vars = ['Miami', 'Rochester'])\n)\n\n\nmelt() can take a few parameters:\n\nvalue_vars parameter allows us to select which specific columns we want to ‚Äúmelt‚Äù.\nBy default, it will melt all the columns not specified in the id_vars parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-wider-with-pivot",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#make-dataframe-wider-with-pivot",
    "title": "Lecture 8",
    "section": "Make DataFrame Wider with pivot()",
    "text": "Make DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the new variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-4",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-4",
    "title": "Lecture 8",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-5",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-5",
    "title": "Lecture 8",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-6",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#reshaping-dataframes-6",
    "title": "Lecture 8",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet‚Äôs do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-1",
    "title": "Lecture 8",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more DataFrames based on common data values in those DataFrames.\n\nThis task is known in the database world as performing a ‚Äújoin.‚Äù\nWe can do this with the merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-2",
    "title": "Lecture 8",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\n\nThe variables that are used to connect each pair of tables are called keys."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-1",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nInner Join\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n# the default value for 'how' is 'inner'\n# so it doesn't actually need to be specified\nmerge_inner = pd.merge(x, y, on='key', how='inner')\nmerge_inner_x = x.merge(y, on='key', how='inner')\nmerge_inner_x_how = x.merge(y, on='key')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-2",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLeft Join\n\nA left join keeps all observations in x.\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join."
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-3",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nRight Join\n\nA right join keeps all observations in y.\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-4",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-4",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nOuter (Full) Join\n\nA full join keeps all observations in x and y.\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-5",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-5",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: one-to-many\n\nOne DataFrame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key':[1, 2, 2, 3],\n    'val_x':['x1', 'x2', 'x3', 'x4']})\n\ny = pd.DataFrame({\n    'key':[1, 2],\n    'val_y':['y1', 'y2'] })\none_to_many = x.merge(y, on='key', \n                         how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-6",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-6",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: many-to-many\n\nBoth DataFrames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key':[1, 2, 2, 3],\n  'val_x':['x1','x2','x3','x4']})\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', \n                          how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-7",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-7",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDefining the key columns\n\n\nIf the left and right columns do not have the same name for the key variables, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = \n  x.merge(y, left_on = 'key_x', \n             right_on = 'key_y', \n             how = 'left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-8",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#joining-dataframes-with-merge-8",
    "title": "Lecture 8",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLet‚Äôs do Part 2 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-1",
    "title": "Lecture 8",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\n\nConcatenation can be thought of as appending a row or column to our data.\n\nThis approach is possible if our data was split into parts or if we performed a calculation that we want to append to our existing data set.\n\nLet‚Äôs consider the following example DataFrames:\n\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-2",
    "title": "Lecture 8",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nConcatenating the DataFrames on top of each other uses the concat() method.\n\nAll of the DataFrames to be concatenated are passed in a list.\n\n\nrow_concat = pd.concat([df1, df2, df3])\nrow_concat"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-3",
    "title": "Lecture 8",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nLet‚Äôs consider a new Series and concatenate it with df1:\n\n# create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\nnew_row_series\n\n\n# attempt to add the new row to a dataframe\ndf = pd.concat([df1, new_row_series])\ndf\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-4",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-4",
    "title": "Lecture 8",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nTo fix the problem, we need turn our Series into a DataFrame.\n\nThis data frame contains one row of data, and the column names are the ones the data will bind to.\n\n\nnew_row_df = pd.DataFrame(\n  # note the double brackets to create a \"row\" of data\n  data =[[\"n1\", \"n2\", \"n3\", \"n4\"]],\n  columns =[\"A\", \"B\", \"C\", \"D\"],\n)\n\ndf = pd.concat([df1, new_row_df])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-5",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-5",
    "title": "Lecture 8",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nConcatenating columns is very similar to concatenating rows.\n\nThe main difference is the axis parameter in the concat() method.\nThe default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion.\nIf we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\n\n\ncol_concat = pd.concat([df1, df2, df3], axis = \"columns\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-6",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-6",
    "title": "Lecture 8",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nWe can use ignore_index=True to reset the column indices, so that we do not have duplicated column names.\n\npd.concat([df1, df2, df3], axis=\"columns\", ignore_index=True)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#concatenate-with-different-indices",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#concatenate-with-different-indices",
    "title": "Lecture 8",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhat would happen when the row and column indices are not aligned?\nLet‚Äôs modify our DataFrames for the next few examples.\n\n# rename the columns of our dataframes\ndf1.columns = ['A', 'B', 'C', 'D']\ndf2.columns = ['E', 'F', 'G', 'H']\ndf3.columns = ['A', 'C', 'F', 'H']\n\nIf we try to concatenate these DataFrames as we did, the DataFrames now do much more than simply stack one on top of the other.\n\nrow_concat = pd.concat([df1, df2, df3])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#concatenate-with-different-indices-1",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#concatenate-with-different-indices-1",
    "title": "Lecture 8",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWe can set join = 'inner' to keep only the columns that are shared among the data sets.\n\npd.concat([df1, df2, df3], join ='inner')\n\nIf we use the DataFrames that have columns in common, only the columns that all of them share will be returned.\n\npd.concat([df1, df3], join ='inner',  ignore_index =False)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#concatenate-with-different-indices-2",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#concatenate-with-different-indices-2",
    "title": "Lecture 8",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nLet‚Äôs modify our DataFrames further.\n\n# re-indexing the rows of our DataFrames\ndf1.index = [0, 1, 2, 3]\ndf2.index = [4, 5, 6, 7]\ndf3.index = [0, 2, 5, 7]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#concatenate-with-different-indices-3",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#concatenate-with-different-indices-3",
    "title": "Lecture 8",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhen we concatenate along axis=\"columns\" (axis=1), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.\n\ncol_concat = pd.concat([df1, df2, df3], axis=\"columns\")\n\nJust as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using join=\"inner\".\n\npd.concat([df1, df3], axis =\"columns\", join='inner')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-7",
    "href": "danl-lec/danl-210-lec-08-2025-0214.html#data-concatenation-7",
    "title": "Lecture 8",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet‚Äôs do Part 3 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#nba-dataframe",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#nba-dataframe",
    "title": "Lecture 9",
    "section": "nba DataFrame",
    "text": "nba DataFrame\n\n\nLet‚Äôs read the nba.csv file as nba:\n\n\n# Below is to import the pandas library as pd\nimport pandas as pd \n\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table  \ndata_table.enable_dataframe_formatter()\n\n# Below is to read nba.csv as nba DataFrame\nnba = pd.read_csv(\"https://bcdanl.github.io/data/nba.csv\",\n                  parse_dates = [\"Birthday\"])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#mathematical-operations",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#mathematical-operations",
    "title": "Lecture 9",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\nnba.max()\nnba.min()\n\nThe max() method returns a Series with the maximum value from each variable.\nThe min() method returns a Series with the minimum value from each variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#mathematical-operations-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#mathematical-operations-1",
    "title": "Lecture 9",
    "section": "Mathematical Operations",
    "text": "Mathematical Operations\n\n\nnba.sum()\nnba.mean()\nnba.median()\nnba.quantile(0.75) # 0 to 1\nnba.std()\n\nnba.sum(numeric_only = True)\nnba.mean(numeric_only = True)\nnba.median(numeric_only = True)\nnba.quantile(0.75, numeric_only=True)\nnba.std(numeric_only = True)\n\n\n\nThe sum()/mean()/median() method returns a Series with the sum/mean/median of the values in each variable.\nThe quantile() method returns a Series with the percentile value of the values in each variable (e.g., 25th, 75th, 90th percentile).\nThe std() method returns a Series with the standard deviation of the values in each variable.\nTo limit the operation to numeric volumes, we can pass True to the sum()/mean()/median()/std() method‚Äôs numeric_only parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#vectorized-operations",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#vectorized-operations",
    "title": "Lecture 9",
    "section": "Vectorized Operations",
    "text": "Vectorized Operations\nnba[\"Salary_2x\"] = nba[\"Salary\"] + nba[\"Salary\"]\nnba[\"Name_w_Position\"] = nba[\"Name\"] + \" (\" + nba[\"Position\"] + \")\"\nnba[\"Salary_minus_Mean\"] = nba[\"Salary\"] - nba[\"Salary\"].mean()\n\npandas performs a vectorized operation on Series or a variable in DataFrame.\n\nThis means an element-by-element operation.\nThis enables us to apply functions and perform operations on the data efficiently, without the need for explicit loops."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#adding-and-removing-variables",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#adding-and-removing-variables",
    "title": "Lecture 9",
    "section": "Adding and Removing Variables",
    "text": "Adding and Removing Variables\n\n\nHere we use [] to add variables:\n\nnba['Salary_k'] = nba['Salary'] / 1000\nnba['Salary_2x'] = nba['Salary'] + nba['Salary']\nnba['Salary_3x'] = nba['Salary'] * 3"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#removing-variables-with-dropcolumns-...",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#removing-variables-with-dropcolumns-...",
    "title": "Lecture 9",
    "section": "Removing Variables with drop(columns = ... )",
    "text": "Removing Variables with drop(columns = ... )\n\n\nWe can use .drop(columns = ...) to drop variables:\n\nnba.drop(columns = \"Salary_k\")\nnba.drop(columns = [\"Salary_2x\", \"Salary_3x\"])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#renaming-variables-with-nba.columns",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#renaming-variables-with-nba.columns",
    "title": "Lecture 9",
    "section": "Renaming Variables with nba.columns",
    "text": "Renaming Variables with nba.columns\n\n\nDo you recall the .columns attribute?\n\nnba.columns\n\nWe can rename any or all of a DataFrame‚Äôs columns by assigning a list of new names to the attribute:\n\nnba.columns = [\"Team\", \"Position\", \"Date of Birth\", \"Income\"]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#renaming-variables-with-rename-columns-existing-one-new-one",
    "title": "Lecture 9",
    "section": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming Variables with rename( columns = { \"Existing One\" : \"New One\" } )\nnba.rename( columns = { \"Date of Birth\": \"Birthday\" } )\n\nThe above rename() method renames the variable Date of Birth to Birthday."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#renaming-rows-with-rename-index-existing-one-new-one",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#renaming-rows-with-rename-index-existing-one-new-one",
    "title": "Lecture 9",
    "section": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )",
    "text": "Renaming rows with rename( index = { \"Existing One\" : \"New One\" } )\nnba = nba.rename(\n    index = { \"LeBron James\": \"LeBron Raymone James\" }\n)\n\nThe above rename() method renames the observation LeBron James to LeBron Raymone James."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#relocating-variables-with-.columns.get_loc-.pop-and-.insert",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#relocating-variables-with-.columns.get_loc-.pop-and-.insert",
    "title": "Lecture 8",
    "section": "Relocating Variables with .columns.get_loc(), .pop(), and .insert()",
    "text": "Relocating Variables with .columns.get_loc(), .pop(), and .insert()\nref_var = nba.columns.get_loc('Team') \nvar_to_move = nba.pop('Salary')\nnba.insert(ref_var, 'Salary', var_to_move) # insert() directly alters 'nba'\n\nStep 1. DataFrame.columns.get_loc('Reference_Var')\n\nGet the integer position (right before the reference variable, ‚ÄòReference_Var‚Äô)\n\nStep 2. DataFrame.pop('Some_Var_To_Move')\n\nRemove the variable we want to relocate from the DataFrame and store it in a Series\n\nStep 3. DataFrame.insert(ref_var, 'Some_Var_To_Move', var_to_move)\n\nInsert the variable back into the DataFrame right after the reference variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-1",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() Method",
    "text": "Converting Data Types with the astype() Method\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-2",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\n\n\nWhat values are in the Mgmt variable?\n\n\nemp[\"Mgmt\"].astype(bool)\n\nThe astype() method converts a Series‚Äô values to a different data type.\n\nIt can accept a single argument: the new data type."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-3",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Mgmt\"] = emp[\"Mgmt\"].astype(bool)\n\nThe above code overwrites the Mgmt variable with our new Series of Booleans."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-4",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-4",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"].astype(int)\n\nThe above code tries to coerce the Salary variable‚Äôs values to integers with the astype() method.\n\nPandas is unable to convert the NaN values to integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#fill-missing-values-with-the-fillna-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#fill-missing-values-with-the-fillna-method",
    "title": "Lecture 9",
    "section": "Fill Missing Values with the fillna() method",
    "text": "Fill Missing Values with the fillna() method\nemp[\"Salary\"].fillna(0)\n\nThe fillna() method replaces a Series‚Äô missing values with the argument we pass in.\nThe above example provides a fill value of 0.\n\nNote that our choice of value can distort the data; 0 is passed solely for the sake of example."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-5",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-5",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0).astype(int)\n\nThe above code overwrites the Salary variable with our new Series of integers."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-6",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-6",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp[\"Gender\"] = emp[\"Gender\"].astype(\"category\")\n\nPandas includes a special data type called a category,\n\nIt is ideal for a variable consisting of a small number of unique values relative to its total number of values.\nE.g., gender, weekdays, blood types, planets, and income groups."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-pd.to_datetime-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-pd.to_datetime-method",
    "title": "Lecture 9",
    "section": "Converting Data Types with the pd.to_datetime() method",
    "text": "Converting Data Types with the pd.to_datetime() method\n# Below two are equivalent:\nemp[\"Start Date\"] = pd.to_datetime(emp[\"Start Date\"])\nemp[\"Start Date\"] = emp[\"Start Date\"].astype('datetime64[ns]')\n\nThe pd.to_datetime() function is used to convert a Series, DataFrame, or a single variable of a DataFrame from its current data type into datetime format."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-7",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#converting-data-types-with-the-astype-method-7",
    "title": "Lecture 9",
    "section": "Converting Data Types with the astype() method",
    "text": "Converting Data Types with the astype() method\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")\n\nemp[\"Salary\"] = emp[\"Salary\"].fillna(0)\nemp = emp.astype({'Mgmt': 'bool', \n                  'Salary': 'int',\n                  'Gender': 'category',\n                  'Start Date': 'datetime64[ns]',\n                  'Team': 'category'})\n\nWe can provide a dictionary of variable-type pairs to astype()."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#pandas-basics",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#pandas-basics",
    "title": "Lecture 9",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Question 1 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-condition-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-condition-1",
    "title": "Lecture 9",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition",
    "title": "Lecture 9",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with ‚ÄúDonna‚Äù.\n\npandas performs a vectorized operation (element-by-element operation) on Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-1",
    "title": "Lecture 9",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-2",
    "title": "Lecture 9",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[ donnas ]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-3",
    "title": "Lecture 9",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to extract a subset of employees who are not on the ‚ÄúMarketing‚Äù team?\n\n\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not ‚ÄúMarketing‚Äù, and False indicates the Team value is ‚ÄúMarketing‚Äù"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-4",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-4",
    "title": "Lecture 9",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to retrieve all the managers in the company?\n\nManagers have a value of True in the Mgmt variable.\n\n\n\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-5",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-single-condition-5",
    "title": "Lecture 9",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-condition-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-condition-2",
    "title": "Lecture 9",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ] # '|' is 'or' opeartor\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria.\nWhat if our next report asked for employees from 30 teams instead of three?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-with-the-isin-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-with-the-isin-method",
    "title": "Lecture 9",
    "section": "Filtering with the isin() method",
    "text": "Filtering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[ on_star_teams ]\n\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, array, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-condition-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-condition-3",
    "title": "Lecture 9",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000.\n\n\n\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ] # '&' is 'and' opeartor\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-with-the-between-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-with-the-between-method",
    "title": "Lecture 9",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[ between_90k_and_100k ]\n\nA slightly cleaner solution is to use a method called between().\n\nIt returns a Boolean Series where True denotes that an observation‚Äôs value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is also inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-with-the-between-method-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-with-the-between-method-1",
    "title": "Lecture 9",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[ name_starts_with_t ]\n\nWe can also apply the between() method to string variables.\n\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-condition-with-the-query-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#filtering-by-a-condition-with-the-query-method",
    "title": "Lecture 9",
    "section": "Filtering by a Condition with the query() method!",
    "text": "Filtering by a Condition with the query() method!\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 & `First Name` == 'Douglas'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\n\nquery() accepts a string value that describes filtering conditions.\n\nWhen using the query() method, if we have variable names with spaces, we can wrap the variable names in backtick (`)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#pandas-basics-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#pandas-basics-1",
    "title": "Lecture 9",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 2-6 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-1",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-2",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation‚Äôs value is missing.\n\nIs a value of a variable ‚ÄúXYZ‚Äù missing?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation‚Äôs value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values: The value_counts(dropna = False) method",
    "text": "Dealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values: The dropna() method",
    "text": "Dealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method-with-how",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method-with-how",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values: The dropna() method with how",
    "text": "Dealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter‚Äôs default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "title": "Lecture 9",
    "section": "Dealing with Missing Values: The dropna() method with thresh",
    "text": "Dealing with Missing Values: The dropna() method with thresh\nemp.dropna(thresh = 4)\n\nThe thresh parameter specifies a minimum threshold of non-missing values that an observation must have for pandas to keep it."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-duplicated-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-duplicated-method",
    "title": "Lecture 9",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "title": "Lecture 9",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method‚Äôs keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value.\n\nQ. How can we keep observations with the first occurrences of a value in the Team variable?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "title": "Lecture 9",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "title": "Lecture 9",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "title": "Lecture 9",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation‚Äôs uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "title": "Lecture 9",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "title": "Lecture 9",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value‚Äôs last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of ‚ÄúDouglas‚Äù and a Gender of ‚ÄúMale‚Äù. Then check which ‚ÄúDouglas‚Äù is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#pandas-basics-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#pandas-basics-2",
    "title": "Lecture 9",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-1",
    "title": "Lecture 9",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nTidy DataFrames\n\n\n\n\nThere are three interrelated rules that make a DataFrame tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-2",
    "title": "Lecture 9",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nA DataFrame can be given in a format unsuited for the analysis that we would like to perform on it.\n\nA DataFrame may have larger structural problems that extend beyond the data.\nPerhaps the DataFrame stores its values in a format that makes it easy to extract a single row but difficult to aggregate the data.\n\nReshaping a DataFrame means manipulating it into a different shape.\nIn this section, we will discuss pandas techniques for molding a DataFrame into the shape we desire."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#long-vs.-wide-dataframes",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#long-vs.-wide-dataframes",
    "title": "Lecture 9",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\n\nThe following DataFrames measure temperatures in two cities over two days.\n\n\ndf_wide = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday'],\n    'Miami': [80, 83],\n    'Rochester': [57, 62],\n    'St. Louis': [71, 75]\n})\n\ndf_long = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Wednesday'],\n    'City': ['Miami', 'Miami', 'Rochester', 'Rochester', 'St. Louis', 'St. Louis'],\n    'Temperature': [80, 83, 57, 62, 71, 75]\n})"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#long-vs.-wide-dataframes-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#long-vs.-wide-dataframes-1",
    "title": "Lecture 9",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nA DataFrame can store its values in wide or long format.\nThese names reflect the direction in which the data set expands as we add more values to it.\n\nA long DataFrame increases in height.\nA wide DataFrame increases in width."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#long-vs.-wide-dataframes-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#long-vs.-wide-dataframes-2",
    "title": "Lecture 9",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nThe optimal storage format for a DataFrame depends on the insight we are trying to glean from it.\n\nWe consider making DataFrames longer if one variable is spread across multiple columns.\nWe consider making DataFrames wider if one observation is spread across multiple rows."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-3",
    "title": "Lecture 9",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nmelt() and pivot()\n\n\n\n\nmelt() makes DataFrame longer.\npivot() and pivot_table() make DataFrame wider."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-longer-with-melt",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-longer-with-melt",
    "title": "Lecture 9",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-longer-with-melt-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-longer-with-melt-1",
    "title": "Lecture 9",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the ‚Äúidentifier‚Äù."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-longer-with-melt-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-longer-with-melt-2",
    "title": "Lecture 9",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-longer-with-melt-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-longer-with-melt-3",
    "title": "Lecture 9",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\",\n          value_vars = ['Miami', 'Rochester'])\n)\n\n\nmelt() can take a few parameters:\n\nvalue_vars parameter allows us to select which specific columns we want to ‚Äúmelt‚Äù.\nBy default, it will melt all the columns not specified in the id_vars parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-wider-with-pivot",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#make-dataframe-wider-with-pivot",
    "title": "Lecture 9",
    "section": "Make DataFrame Wider with pivot()",
    "text": "Make DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the new variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-4",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-4",
    "title": "Lecture 9",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-5",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-5",
    "title": "Lecture 9",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-6",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#reshaping-dataframes-6",
    "title": "Lecture 9",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet‚Äôs do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-1",
    "title": "Lecture 9",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more DataFrames based on common data values in those DataFrames.\n\nThis task is known in the database world as performing a ‚Äújoin.‚Äù\nWe can do this with the merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-2",
    "title": "Lecture 9",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\n\nThe variables that are used to connect each pair of tables are called keys."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-1",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nInner Join\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n# the default value for 'how' is 'inner'\n# so it doesn't actually need to be specified\nmerge_inner = pd.merge(x, y, on='key', how='inner')\nmerge_inner_x = x.merge(y, on='key', how='inner')\nmerge_inner_x_how = x.merge(y, on='key')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-2",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLeft Join\n\nA left join keeps all observations in x.\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join."
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-3",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nRight Join\n\nA right join keeps all observations in y.\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-4",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-4",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nOuter (Full) Join\n\nA full join keeps all observations in x and y.\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-5",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-5",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: one-to-many\n\nOne DataFrame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key':[1, 2, 2, 3],\n    'val_x':['x1', 'x2', 'x3', 'x4']})\n\ny = pd.DataFrame({\n    'key':[1, 2],\n    'val_y':['y1', 'y2'] })\none_to_many = x.merge(y, on='key', \n                         how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-6",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-6",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: many-to-many\n\nBoth DataFrames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key':[1, 2, 2, 3],\n  'val_x':['x1','x2','x3','x4']})\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', \n                          how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-7",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-7",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDefining the key columns\n\n\nIf the left and right columns do not have the same name for the key variables, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = \n  x.merge(y, left_on = 'key_x', \n             right_on = 'key_y', \n             how = 'left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-8",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#joining-dataframes-with-merge-8",
    "title": "Lecture 9",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLet‚Äôs do Part 2 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-1",
    "title": "Lecture 9",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\n\nConcatenation can be thought of as appending a row or column to our data.\n\nThis approach is possible if our data was split into parts or if we performed a calculation that we want to append to our existing data set.\n\nLet‚Äôs consider the following example DataFrames:\n\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-2",
    "title": "Lecture 9",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nConcatenating the DataFrames on top of each other uses the concat() method.\n\nAll of the DataFrames to be concatenated are passed in a list.\n\n\nrow_concat = pd.concat([df1, df2, df3])\nrow_concat"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-3",
    "title": "Lecture 9",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nLet‚Äôs consider a new Series and concatenate it with df1:\n\n# create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\nnew_row_series\n\n\n# attempt to add the new row to a dataframe\ndf = pd.concat([df1, new_row_series])\ndf\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-4",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-4",
    "title": "Lecture 9",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nTo fix the problem, we need turn our Series into a DataFrame.\n\nThis data frame contains one row of data, and the column names are the ones the data will bind to.\n\n\nnew_row_df = pd.DataFrame(\n  # note the double brackets to create a \"row\" of data\n  data =[[\"n1\", \"n2\", \"n3\", \"n4\"]],\n  columns =[\"A\", \"B\", \"C\", \"D\"],\n)\n\ndf = pd.concat([df1, new_row_df])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-5",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-5",
    "title": "Lecture 9",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nConcatenating columns is very similar to concatenating rows.\n\nThe main difference is the axis parameter in the concat() method.\nThe default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion.\nIf we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\n\n\ncol_concat = pd.concat([df1, df2, df3], axis = \"columns\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-6",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-6",
    "title": "Lecture 9",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nWe can use ignore_index=True to reset the column indices, so that we do not have duplicated column names.\n\npd.concat([df1, df2, df3], axis=\"columns\", ignore_index=True)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#concatenate-with-different-indices",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#concatenate-with-different-indices",
    "title": "Lecture 9",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhat would happen when the row and column indices are not aligned?\nLet‚Äôs modify our DataFrames for the next few examples.\n\n# rename the columns of our dataframes\ndf1.columns = ['A', 'B', 'C', 'D']\ndf2.columns = ['E', 'F', 'G', 'H']\ndf3.columns = ['A', 'C', 'F', 'H']\n\nIf we try to concatenate these DataFrames as we did, the DataFrames now do much more than simply stack one on top of the other.\n\nrow_concat = pd.concat([df1, df2, df3])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#concatenate-with-different-indices-1",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#concatenate-with-different-indices-1",
    "title": "Lecture 9",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWe can set join = 'inner' to keep only the columns that are shared among the data sets.\n\npd.concat([df1, df2, df3], join ='inner')\n\nIf we use the DataFrames that have columns in common, only the columns that all of them share will be returned.\n\npd.concat([df1, df3], join ='inner',  ignore_index =False)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#concatenate-with-different-indices-2",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#concatenate-with-different-indices-2",
    "title": "Lecture 9",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nLet‚Äôs modify our DataFrames further.\n\n# re-indexing the rows of our DataFrames\ndf1.index = [0, 1, 2, 3]\ndf2.index = [4, 5, 6, 7]\ndf3.index = [0, 2, 5, 7]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#concatenate-with-different-indices-3",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#concatenate-with-different-indices-3",
    "title": "Lecture 9",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhen we concatenate along axis=\"columns\" (axis=1), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.\n\ncol_concat = pd.concat([df1, df2, df3], axis=\"columns\")\n\nJust as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using join=\"inner\".\n\npd.concat([df1, df3], axis =\"columns\", join='inner')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-7",
    "href": "danl-lec/danl-210-lec-09-2025-0217.html#data-concatenation-7",
    "title": "Lecture 9",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet‚Äôs do Part 3 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#employment-data",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#employment-data",
    "title": "Lecture 10",
    "section": "Employment Data",
    "text": "Employment Data\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-condition-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-condition-1",
    "title": "Lecture 10",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\nWe may often not know the index labels and positions of the observations we want to target.\nWe may want to target observations not by an index label but by a Boolean condition."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[\"First Name\"] == \"Donna\"\n\nTo compare every value in Series with a constant value, we place the Series on one side of the equality operator (==) and the value on the other.\n\nSeries == value\n\nThe above example compares each First Name value with ‚ÄúDonna‚Äù.\n\npandas performs a vectorized operation (element-by-element operation) on Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-1",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nemp[ emp[\"First Name\"] == \"Donna\" ]\n\nTo filter observations, we provide the Boolean Series between square brackets following the DataFrame.\n\nDataFrame[ Boolean_Series ]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-2",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\ndonnas = emp[\"First Name\"] == \"Donna\"\nemp[ donnas ]\n\nIf the use of multiple square brackets is confusing, we can assign the Boolean Series to an object and then pass it into the square brackets instead."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-3",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-3",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to extract a subset of employees who are not on the ‚ÄúMarketing‚Äù team?\n\n\nnon_marketing = emp[\"Team\"] != \"Marketing\"  # != means \"not equal to\"\nemp[ non_marketing ]\n\nTrue denotes that the Team value for a given index is not ‚ÄúMarketing‚Äù, and False indicates the Team value is ‚ÄúMarketing‚Äù"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-4",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-4",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\n\n\nWhat if we want to retrieve all the managers in the company?\n\nManagers have a value of True in the Mgmt variable.\n\n\n\nemp[ emp[\"Mgmt\"] ]\n\nWe could execute emp[\"Mgmt\"] == True, but we do not need to."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-5",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-single-condition-5",
    "title": "Lecture 10",
    "section": "Filtering by a Single Condition",
    "text": "Filtering by a Single Condition\nhigh_earners = emp[\"Salary\"] &gt; 100000\nemp[ high_earners ]\n\nWe can also use arithmetic operands to filter observations based on mathematical conditions."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-condition-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-condition-2",
    "title": "Lecture 10",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\nsales = emp[\"Team\"] == \"Sales\"\nlegal = emp[\"Team\"] == \"Legal\"\nfnce = emp[\"Team\"] == \"Finance\"\nemp[ sales | legal | fnce ] # '|' is 'or' opeartor\n\nWe could provide three separate Boolean Series inside the square brackets and add the | symbol to declare OR criteria.\nWhat if our next report asked for employees from 30 teams instead of three?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-with-the-isin-method",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-with-the-isin-method",
    "title": "Lecture 10",
    "section": "Filtering with the isin() method",
    "text": "Filtering with the isin() method\nstar_teams = [\"Sales\", \"Legal\", \"Finance\"]\non_star_teams = emp[\"Team\"].isin(star_teams)\nemp[ on_star_teams ]\n\nA better solution is the isin() method, which accepts an iterable (e.g., list, tuple, array, Series) and returns a Boolean Series."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-condition-3",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-condition-3",
    "title": "Lecture 10",
    "section": "Filtering by a Condition",
    "text": "Filtering by a Condition\n\n\nWhen working with numbers or dates, we often want to extract values that fall within a range.\n\nE.g., Identify all employees with a salary between $90,000 and $100,000.\n\n\n\nhigher_than_90k = emp[\"Salary\"] &gt;= 90000\nlower_than_100k = emp[\"Salary\"] &lt; 100000\nemp[ higher_than_90k & lower_than_100k ] # '&' is 'and' opeartor\n\nWe can create two Boolean Series, one to declare the lower bound and one to declare the upper bound.\nThen we can use the & operator to mandate that both conditions are True."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-with-the-between-method",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-with-the-between-method",
    "title": "Lecture 10",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nbetween_90k_and_100k = emp[\"Salary\"].between(90000, 100000)\nemp[ between_90k_and_100k ]\n\nA slightly cleaner solution is to use a method called between().\n\nIt returns a Boolean Series where True denotes that an observation‚Äôs value falls between the specified interval.\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is also inclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-with-the-between-method-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-with-the-between-method-1",
    "title": "Lecture 10",
    "section": "Filtering with the between() method",
    "text": "Filtering with the between() method\nname_starts_with_t = emp[\"First Name\"].between(\"T\", \"U\")\nemp[ name_starts_with_t ]\n\nWe can also apply the between() method to string variables.\n\nThe first argument, the lower bound, is inclusive, and the second argument, the upper bound, is exclusive."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-condition-with-the-query-method",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#filtering-by-a-condition-with-the-query-method",
    "title": "Lecture 10",
    "section": "Filtering by a Condition with the query() method!",
    "text": "Filtering by a Condition with the query() method!\nemp.query(\"Salary &gt;= 100000 & Team == 'Finance'\")\nemp.query(\"Salary &gt;= 100000 & `First Name` == 'Douglas'\")\n\nThe query() method filters observations using a concise, string-based query syntax.\n\nquery() accepts a string value that describes filtering conditions.\n\nWhen using the query() method, if we have variable names with spaces, we can wrap the variable names in backtick (`)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#pandas-basics",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#pandas-basics",
    "title": "Lecture 10",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 2-6 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-1",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-2",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation‚Äôs value is missing.\n\nIs a value of a variable ‚ÄúXYZ‚Äù missing?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation‚Äôs value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values: The value_counts(dropna = False) method",
    "text": "Dealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values: The dropna() method",
    "text": "Dealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method-with-how",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method-with-how",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values: The dropna() method with how",
    "text": "Dealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter‚Äôs default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-missing-values-the-dropna-method-with-thresh",
    "title": "Lecture 10",
    "section": "Dealing with Missing Values: The dropna() method with thresh",
    "text": "Dealing with Missing Values: The dropna() method with thresh\nemp.dropna(thresh = 4)\n\nThe thresh parameter specifies a minimum threshold of non-missing values that an observation must have for pandas to keep it."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-duplicated-method",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-duplicated-method",
    "title": "Lecture 10",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "title": "Lecture 10",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method‚Äôs keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "title": "Lecture 10",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "title": "Lecture 10",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "title": "Lecture 10",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation‚Äôs uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "title": "Lecture 10",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "title": "Lecture 10",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value‚Äôs last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of ‚ÄúDouglas‚Äù and a Gender of ‚ÄúMale‚Äù. Then check which ‚ÄúDouglas‚Äù is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#pandas-basics-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#pandas-basics-1",
    "title": "Lecture 10",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-1",
    "title": "Lecture 10",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nTidy DataFrames\n\n\n\n\nThere are three interrelated rules that make a DataFrame tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-2",
    "title": "Lecture 10",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nA DataFrame can be given in a format unsuited for the analysis that we would like to perform on it.\n\nA DataFrame may have larger structural problems that extend beyond the data.\nPerhaps the DataFrame stores its values in a format that makes it easy to extract a single row but difficult to aggregate the data.\n\nReshaping a DataFrame means manipulating it into a different shape.\nIn this section, we will discuss pandas techniques for molding a DataFrame into the shape we desire."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#long-vs.-wide-dataframes",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#long-vs.-wide-dataframes",
    "title": "Lecture 10",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\n\nThe following DataFrames measure temperatures in two cities over two days.\n\n\ndf_wide = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday'],\n    'Miami': [80, 83],\n    'Rochester': [57, 62],\n    'St. Louis': [71, 75]\n})\n\ndf_long = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Wednesday'],\n    'City': ['Miami', 'Miami', 'Rochester', 'Rochester', 'St. Louis', 'St. Louis'],\n    'Temperature': [80, 83, 57, 62, 71, 75]\n})"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#long-vs.-wide-dataframes-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#long-vs.-wide-dataframes-1",
    "title": "Lecture 10",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nA DataFrame can store its values in wide or long format.\nThese names reflect the direction in which the data set expands as we add more values to it.\n\nA long DataFrame increases in height.\nA wide DataFrame increases in width."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#long-vs.-wide-dataframes-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#long-vs.-wide-dataframes-2",
    "title": "Lecture 10",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nThe optimal storage format for a DataFrame depends on the insight we are trying to glean from it.\n\nWe consider making DataFrames longer if one variable is spread across multiple columns.\nWe consider making DataFrames wider if one observation is spread across multiple rows."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-3",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-3",
    "title": "Lecture 10",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nmelt() and pivot()\n\n\n\n\nmelt() makes DataFrame longer.\npivot() and pivot_table() make DataFrame wider."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-longer-with-melt",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-longer-with-melt",
    "title": "Lecture 10",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-longer-with-melt-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-longer-with-melt-1",
    "title": "Lecture 10",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the ‚Äúidentifier‚Äù."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-longer-with-melt-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-longer-with-melt-2",
    "title": "Lecture 10",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-longer-with-melt-3",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-longer-with-melt-3",
    "title": "Lecture 10",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\",\n          value_vars = ['Miami', 'Rochester'])\n)\n\n\nmelt() can take a few parameters:\n\nvalue_vars parameter allows us to select which specific columns we want to ‚Äúmelt‚Äù.\nBy default, it will melt all the columns not specified in the id_vars parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-wider-with-pivot",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#make-dataframe-wider-with-pivot",
    "title": "Lecture 10",
    "section": "Make DataFrame Wider with pivot()",
    "text": "Make DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the new variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-4",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-4",
    "title": "Lecture 10",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-5",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-5",
    "title": "Lecture 10",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-6",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#reshaping-dataframes-6",
    "title": "Lecture 10",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet‚Äôs do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-1",
    "title": "Lecture 10",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more DataFrames based on common data values in those DataFrames.\n\nThis task is known in the database world as performing a ‚Äújoin.‚Äù\nWe can do this with the merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-2",
    "title": "Lecture 10",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\n\nThe variables that are used to connect each pair of tables are called keys."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-1",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nInner Join\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n# the default value for 'how' is 'inner'\n# so it doesn't actually need to be specified\nmerge_inner = pd.merge(x, y, on='key', how='inner')\nmerge_inner_x = x.merge(y, on='key', how='inner')\nmerge_inner_x_how = x.merge(y, on='key')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-2",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLeft Join\n\nA left join keeps all observations in x.\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-3",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-3",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nRight Join\n\nA right join keeps all observations in y.\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-4",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-4",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nOuter (Full) Join\n\nA full join keeps all observations in x and y.\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-5",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-5",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: one-to-many\n\nOne DataFrame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key':[1, 2, 2, 3],\n    'val_x':['x1', 'x2', 'x3', 'x4']})\n\ny = pd.DataFrame({\n    'key':[1, 2],\n    'val_y':['y1', 'y2'] })\none_to_many = x.merge(y, on='key', \n                         how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-6",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-6",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: many-to-many\n\nBoth DataFrames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key':[1, 2, 2, 3],\n  'val_x':['x1','x2','x3','x4']})\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', \n                          how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-7",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-7",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDefining the key columns\n\n\nIf the left and right columns do not have the same name for the key variables, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = \n  x.merge(y, left_on = 'key_x', \n             right_on = 'key_y', \n             how = 'left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-8",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#joining-dataframes-with-merge-8",
    "title": "Lecture 10",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLet‚Äôs do Part 2 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-1",
    "title": "Lecture 10",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\n\nConcatenation can be thought of as appending a row or column to our data.\n\nThis approach is possible if our data was split into parts or if we performed a calculation that we want to append to our existing data set.\n\nLet‚Äôs consider the following example DataFrames:\n\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-2",
    "title": "Lecture 10",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nConcatenating the DataFrames on top of each other uses the concat() method.\n\nAll of the DataFrames to be concatenated are passed in a list.\n\n\nrow_concat = pd.concat([df1, df2, df3])\nrow_concat"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-3",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-3",
    "title": "Lecture 10",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nLet‚Äôs consider a new Series and concatenate it with df1:\n\n# create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\nnew_row_series\n\n\n# attempt to add the new row to a dataframe\ndf = pd.concat([df1, new_row_series])\ndf\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-4",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-4",
    "title": "Lecture 10",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nTo fix the problem, we need turn our Series into a DataFrame.\n\nThis data frame contains one row of data, and the column names are the ones the data will bind to.\n\n\nnew_row_df = pd.DataFrame(\n  # note the double brackets to create a \"row\" of data\n  data =[[\"n1\", \"n2\", \"n3\", \"n4\"]],\n  columns =[\"A\", \"B\", \"C\", \"D\"],\n)\n\ndf = pd.concat([df1, new_row_df])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-5",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-5",
    "title": "Lecture 10",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nConcatenating columns is very similar to concatenating rows.\n\nThe main difference is the axis parameter in the concat() method.\nThe default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion.\nIf we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\n\n\ncol_concat = pd.concat([df1, df2, df3], axis = \"columns\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-6",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-6",
    "title": "Lecture 10",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nWe can use ignore_index=True to reset the column indices, so that we do not have duplicated column names.\n\npd.concat([df1, df2, df3], axis=\"columns\", ignore_index=True)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#concatenate-with-different-indices",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#concatenate-with-different-indices",
    "title": "Lecture 10",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhat would happen when the row and column indices are not aligned?\nLet‚Äôs modify our DataFrames for the next few examples.\n\n# rename the columns of our dataframes\ndf1.columns = ['A', 'B', 'C', 'D']\ndf2.columns = ['E', 'F', 'G', 'H']\ndf3.columns = ['A', 'C', 'F', 'H']\n\nIf we try to concatenate these DataFrames as we did, the DataFrames now do much more than simply stack one on top of the other.\n\nrow_concat = pd.concat([df1, df2, df3])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#concatenate-with-different-indices-1",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#concatenate-with-different-indices-1",
    "title": "Lecture 10",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWe can set join = 'inner' to keep only the columns that are shared among the data sets.\n\npd.concat([df1, df2, df3], join ='inner')\n\nIf we use the DataFrames that have columns in common, only the columns that all of them share will be returned.\n\npd.concat([df1, df3], join ='inner',  ignore_index =False)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#concatenate-with-different-indices-2",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#concatenate-with-different-indices-2",
    "title": "Lecture 10",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nLet‚Äôs modify our DataFrames further.\n\n# re-indexing the rows of our DataFrames\ndf1.index = [0, 1, 2, 3]\ndf2.index = [4, 5, 6, 7]\ndf3.index = [0, 2, 5, 7]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#concatenate-with-different-indices-3",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#concatenate-with-different-indices-3",
    "title": "Lecture 10",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhen we concatenate along axis=\"columns\" (axis=1), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.\n\ncol_concat = pd.concat([df1, df2, df3], axis=\"columns\")\n\nJust as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using join=\"inner\".\n\npd.concat([df1, df3], axis =\"columns\", join='inner')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-7",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#data-concatenation-7",
    "title": "Lecture 10",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet‚Äôs do Part 3 of Classwork 7!"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html",
    "href": "danl-hw/danl-210-hw-02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Please submit your Jupyter Notebook for Part 1, Part 2, and Part 3 in Homework 2 to Brightspace with the name below:\n\ndanl_210_hw2_LASTNAME_FIRSTNAME.ipynb\n( e.g., danl_210_hw2_choe_byeonghak.ipynb )\n\nThe due is March 3, 2025, 10:30 A.M.\nPlease send Byeong-Hak an email (bchoe@geneseo.edu) if you have any questions."
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-0",
    "href": "danl-hw/danl-210-hw-02.html#question-0",
    "title": "Homework 2",
    "section": "Question 0",
    "text": "Question 0\nProvide your GitHub username."
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-1",
    "href": "danl-hw/danl-210-hw-02.html#question-1",
    "title": "Homework 2",
    "section": "Question 1",
    "text": "Question 1\nSelect ‚ÄúFirst_Name‚Äù, ‚ÄúLast_Name‚Äù, ‚ÄúBase_Salary‚Äù, and ‚ÄúTotal_OT_Paid‚Äù, then sort the DataFrame with these selected variables by ‚ÄúBase_Salary‚Äù in descending order and display the top 10 entries.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-2",
    "href": "danl-hw/danl-210-hw-02.html#question-2",
    "title": "Homework 2",
    "section": "Question 2",
    "text": "Question 2\nUsing set_index(), change the DataFrame‚Äôs index to ‚ÄúLast_Name‚Äù, then locate the data for a specific last name, say ‚ÄúBROWN‚Äù, and display their ‚ÄúAgency_Name‚Äù, ‚ÄúBase_Salary‚Äù, and ‚ÄúTotal_OT_Paid‚Äù.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-3",
    "href": "danl-hw/danl-210-hw-02.html#question-3",
    "title": "Homework 2",
    "section": "Question 3",
    "text": "Question 3\nFind the 5 employees with the highest ‚ÄúRegular_Gross_Paid‚Äù and calculate their average ‚ÄúOT_Hours‚Äù. Also, reset the index if you have changed it previously.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-4",
    "href": "danl-hw/danl-210-hw-02.html#question-4",
    "title": "Homework 2",
    "section": "Question 4",
    "text": "Question 4\nSort the DataFrame by ‚ÄúFiscal_Year‚Äù and ‚ÄúTotal_Other_Pay‚Äù in descending order, then set ‚ÄúFirst_Name‚Äù as the index and use the loc accessor to retrieve the ‚ÄúTotal_Other_Pay‚Äù for a specific first name, say ‚ÄúMICHAEL‚Äù.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-5",
    "href": "danl-hw/danl-210-hw-02.html#question-5",
    "title": "Homework 2",
    "section": "Question 5",
    "text": "Question 5\nSort the DataFrame first by ‚ÄúWork_Location_Borough‚Äù alphabetically, and then by ‚ÄúTotal_Compensation‚Äù (sum of ‚ÄúBase_Salary‚Äù and ‚ÄúTotal_OT_Paid‚Äù) in descending order within each borough.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#variable-description",
    "href": "danl-hw/danl-210-hw-02.html#variable-description",
    "title": "Homework 2",
    "section": "Variable Description",
    "text": "Variable Description\n\nFiscal_Year: Fiscal Year;\nPayroll_Number: Payroll Number;\nAgency_Name: The Payroll agency that the employee works for;\nLast_Name: Last name of employee;\nFirst_Name: First name of employee;\nMid_Init: Middle initial of employee;\nAgency_Start_Date: Date which employee began working for their current agency;\nWork_Location_Borough: Borough of employee‚Äôs primary work location;\nTitle_Description: Civil service title description of the employee;\nLeave_Status_as_of_June_30: Status of employee as of the close of the relevant fiscal year;\nBase_Salary: Base Salary assigned to the employee;\nPay_Basis: Lists whether the employee is paid on an hourly, per diem or annual basis;\nRegular_Hours: Number of regular hours employee worked in the fiscal year;\nRegular_Gross_Paid: The amount paid to the employee for base salary during the fiscal year;\nOT_Hours: Overtime Hours worked by employee in the fiscal year;\nTotal_OT_Paid: Total overtime pay paid to the employee in the fiscal year;\nTotal_Other_Pay: Includes any compensation in addition to gross salary and overtime pay, ie Differentials, lump sums, uniform allowance, meal allowance, retroactive pay increases, settlement amounts, and bonus pay, if applicable."
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-6",
    "href": "danl-hw/danl-210-hw-02.html#question-6",
    "title": "Homework 2",
    "section": "Question 6",
    "text": "Question 6\n\nSelect employees who have ‚ÄúOT_Hours‚Äù greater than 0, calculate their ‚ÄúOT_Rate‚Äù (‚ÄúTotal_OT_Paid‚Äù / ‚ÄúOT_Hours‚Äù), and then find the employee with the highest ‚ÄúOT_Rate‚Äù. Display their full name and ‚ÄúOT_Rate‚Äù.\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-7",
    "href": "danl-hw/danl-210-hw-02.html#question-7",
    "title": "Homework 2",
    "section": "Question 7",
    "text": "Question 7\nCreate a new DataFrame that includes employees from the ‚ÄúDEPARTMENT OF EDUCATION ADMIN‚Äù agency where the variables are ‚ÄúFirst_Name‚Äù, ‚ÄúLast_Name‚Äù, ‚ÄúTitle_Description‚Äù, ‚ÄúBase_Salary‚Äù, and ‚ÄúTotal_OT_Paid‚Äù. Additionally, include a new variable ‚ÄúTotal_Compensation‚Äù which is the sum of ‚ÄúBase_Salary‚Äù and ‚ÄúTotal_OT_Paid‚Äù.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-8",
    "href": "danl-hw/danl-210-hw-02.html#question-8",
    "title": "Homework 2",
    "section": "Question 8",
    "text": "Question 8\n\nHow many employees have a ‚ÄúBase_Salary‚Äù within the top 10% of the DataFrame?\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-9",
    "href": "danl-hw/danl-210-hw-02.html#question-9",
    "title": "Homework 2",
    "section": "Question 9",
    "text": "Question 9\nFilter the DataFrame for employees who have ‚ÄúOT_Hours‚Äù greater than 0 but less than 100, and their ‚ÄúLeave_Status_as_of_June_30‚Äù is ‚ÄúACTIVE‚Äù.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-10",
    "href": "danl-hw/danl-210-hw-02.html#question-10",
    "title": "Homework 2",
    "section": "Question 10",
    "text": "Question 10\nFind the unique job titles in the ‚ÄúDEPARTMENT OF EDUCATION ADMIN‚Äù agency and count how many there are.\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-11",
    "href": "danl-hw/danl-210-hw-02.html#question-11",
    "title": "Homework 2",
    "section": "Question 11",
    "text": "Question 11\n\nIdentify the employee(s) with the highest ‚ÄúTotal_OT_Paid‚Äù in the DataFrame.\n\nInclude their ‚ÄúFirst_Name‚Äù, ‚ÄúLast_Name‚Äù, and ‚ÄúTotal_OT_Paid‚Äù.\n\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#variable-description-1",
    "href": "danl-hw/danl-210-hw-02.html#variable-description-1",
    "title": "Homework 2",
    "section": "Variable description",
    "text": "Variable description\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nweek: Season week.\nposteam: String abbreviation for the team with possession.\nqtr: Quarter of the game (5 is overtime).\nhalf_seconds_remaining: Numeric seconds remaining in the half.\ndown: The down for the given play.\n\nBasically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it).\nIf you make 10 yards then you get another set of four downs.\n\npass: Binary indicator if the play was a pass play.\nwp: Estimated winning probability for the posteam given the current situation at the start of the given play."
  },
  {
    "objectID": "danl-lec/danl-210-lec-10-2025-0219.html#adding-a-variable-based-on-a-condition-using-np.where",
    "href": "danl-lec/danl-210-lec-10-2025-0219.html#adding-a-variable-based-on-a-condition-using-np.where",
    "title": "Lecture 10",
    "section": "Adding a Variable based on a Condition using np.where()",
    "text": "Adding a Variable based on a Condition using np.where()\n\n\nWe can use np.where from NumPy to add a new variable to a DataFrame based on a condition.\n\n\nimport numpy as np\n\n# Using np.where to add the 'pass_fail' column\nemp['high_salary'] = np.where(emp['Salary'] &gt;= 100000, 'Yes', 'No')\n\nWe want to add a new variable high_salary:\n\n‚ÄúYes‚Äù if score is greater than or equal to 100,000.\n‚ÄúNo‚Äù otherwise."
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-12",
    "href": "danl-hw/danl-210-hw-02.html#question-12",
    "title": "Homework 2",
    "section": "Question 12",
    "text": "Question 12\n\nWhat percentage of the values is missing for each variable?\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-13",
    "href": "danl-hw/danl-210-hw-02.html#question-13",
    "title": "Homework 2",
    "section": "Question 13",
    "text": "Question 13\n\nFill missing values in the ‚ÄúLast_Name‚Äù variable with ‚ÄúUNKNOWN‚Äù.\n\nAnswer"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-14",
    "href": "danl-hw/danl-210-hw-02.html#question-14",
    "title": "Homework 2",
    "section": "Question 14",
    "text": "Question 14\nIn DataFrame, NFL2022_stuffs, remove observations for which the value of posteam is missing.\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-15",
    "href": "danl-hw/danl-210-hw-02.html#question-15",
    "title": "Homework 2",
    "section": "Question 15",
    "text": "Question 15\n\nCalculate the mean value of pass for the BUF posteam when all the following conditions hold:\n\nwp is greater than 20% and less than 75%;\ndown is less than or equal to 2; and\nhalf_seconds_remaining is greater than 120.\n\n\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-16",
    "href": "danl-hw/danl-210-hw-02.html#question-16",
    "title": "Homework 2",
    "section": "Question 16",
    "text": "Question 16\n\nConsider the following DataFrame, NFL2022_epa:\n\n\nNFL2022_epa = pd.read_csv('https://bcdanl.github.io/data/NFL2022_epa.csv')\n\n\n\n\n\n  \n\n\n\n\nVariable Description for NFL2022_epa\n\nplay_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play\ngame_id: Ten digit identifier for NFL game.\ndrive: Numeric drive number in the game.\nposteam: String abbreviation for the team with possession.\npasser: Name of the player who passed a ball to a receiver by initially taking a three-step drop and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks)\nreceiver: Name of the receiver.\nepa: Expected points added (EPA) by the posteam for the given play.\n\n\n\nCreate the following DataFrame, NFL2022_stuffs_EPA, that includes\n\nAll the variables in the DataFrame, NFL2022_stuffs;\nThe variables, passer, receiver, and epa, from the DataFrame, NFL2022_epa by joining the two DataFrames.\n\nIn the resulting DataFrame, NFL2022_stuffs_EPA, remove observations with NA in passer after the join.\n\n\n\n\n\n\n\n\nAnswer:"
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#variable-description-2",
    "href": "danl-hw/danl-210-hw-02.html#variable-description-2",
    "title": "Homework 2",
    "section": "Variable Description",
    "text": "Variable Description\n\n\n\n\n\n\n\n\nvariable\ntype\ndescription\n\n\n\n\nName\nstring\nName of the Trash Wheel\n\n\nMonth\nstring\nMonth\n\n\nYear\nnumeric\nYear\n\n\nDate\nstring\nDate (Daily)\n\n\nWeight\nnumeric\nWeight in tons\n\n\nVolume\nnumeric\nVolume in cubic yards\n\n\nPlasticBottles\nnumeric\nNumber of plastic bottles\n\n\nPolystyrene\nnumeric\nNumber of polystyrene items\n\n\nCigaretteButts\nnumeric\nNumber of cigarette butts\n\n\nGlassBottles\nnumeric\nNumber of glass bottles\n\n\nPlasticBags\nnumeric\nNumber of plastic bags\n\n\nWrappers\nnumeric\nNumber of wrappers\n\n\nSportsBalls\nnumeric\nNumber of sports balls\n\n\nHomesPowered\nnumeric\nHomes Powered - Each ton of trash equates to on average 500 kilowatts of electricity. An average household will use 30 kilowatts per day."
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#question-17",
    "href": "danl-hw/danl-210-hw-02.html#question-17",
    "title": "Homework 2",
    "section": "Question 17",
    "text": "Question 17\n\nReshape the trashwheel DataFrame into a DataFrame called trashwheel_long that includes variables for ‚ÄúName‚Äù, ‚ÄúDate‚Äù, ‚ÄúTrash_Type‚Äù, and ‚ÄúNumber‚Äù.\n\nThe ‚ÄúTrash_Type‚Äù variable should indicate the type of trash from the original DataFrame, and ‚ÄúNumber‚Äù should contain the corresponding values.\nFinally, sort trashwheel_long by ‚ÄúName‚Äù and ‚ÄúDate‚Äù in ascending order."
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#variable-description-3",
    "href": "danl-hw/danl-210-hw-02.html#variable-description-3",
    "title": "Homework 2",
    "section": "Variable Description",
    "text": "Variable Description\n\npid: playlist ID; unique ID for playlist\nplaylist_name: a name of playlist\npos: a position of the track within a playlist (starting from 0)\nartist_name: name of the track‚Äôs primary artist\ntrack_name: name of the track\nduration_ms: duration of the track in milliseconds\nalbum_name: name of the track‚Äôs album\n\n\n\nWrite a blog post about your favorite artist(s) in the spotify DataFrame using Jupyter Notebook, and add it to your online blog.\n\nIn your blog post, utilize counting, sorting, indexing, and filtering methods."
  },
  {
    "objectID": "danl-hw/danl-210-hw-02.html#meet-the-mr.-trash-wheel-family",
    "href": "danl-hw/danl-210-hw-02.html#meet-the-mr.-trash-wheel-family",
    "title": "Homework 2",
    "section": "Meet the Mr.¬†Trash Wheel Family",
    "text": "Meet the Mr.¬†Trash Wheel Family\n\n\n\n\n\n\nMister Trash Wheel\n\n\n\n\nInstalled: May 9, 2014\nLocation: Jones Falls stream, Inner Harbor, Baltimore, MD\n\n\n\n\n\n\n\n\nProfessor Trash Wheel\n\n\n\n\nInstalled: December 4, 2016\nLocation: Harris Creek, Canton neighborhood, Baltimore, MD\n\n\n\n\n\n\n\n\nCaptain Trash Wheel\n\n\n\n\n\nInstalled: June 5, 2018\nLocation: Masonville Cove, Baltimore, MD\n\n\n\n\n\n\n\n\nGwynnda Trash Wheel\n\n\n\n\n\nInstalled: June 3, 2021\nLocation: Gwynns Falls, West Baltimore, MD"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\n\nLet‚Äôs read employment.csv as emp.\n\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nemp = pd.read_csv(\"https://bcdanl.github.io/data/employment.csv\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-2",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values",
    "text": "Dealing with Missing Values\n\nPandas often marks (1) missing text values and (2) missing numeric values with a NaN (not a number);\n\nIt also marks missing datetime values with a NaT (not a time)."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-isna-and-notna-methods",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\nemp[\"Team\"].isna()\nemp[\"Start Date\"].isna()\n\nThe isna() method returns a Boolean Series in which True denotes that an observation‚Äôs value is missing.\n\nIs a value of a variable ‚ÄúXYZ‚Äù missing?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-isna-and-notna-methods-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The isna() and notna() methods",
    "text": "Dealing with Missing Values: The isna() and notna() methods\n# Below two are equivalent.\nemp[\"Team\"].notna()\n~emp[\"Team\"].isna()\n\nThe notna() method returns the inverse Series, one in which True indicates that an observation‚Äôs value is present.\nWe use the tilde symbol (~) to invert a Boolean Series.\nQ. How can we pull out employees with non-missing Team values?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-value_countsdropna-false-method",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The value_counts(dropna = False) method",
    "text": "Dealing with Missing Values: The value_counts(dropna = False) method\nemp[\"Mgmt\"].isna().sum()\nemp[\"Mgmt\"].value_counts()\nemp[\"Mgmt\"].value_counts(dropna = False)\n\nOne way to missing data counts is to use the isna().sum() on a Series.\n\nTrue is 1 and False is 0.\n\nAnother way to get missing data counts is to use the .value_counts() method on a Series.\n\nIf we use the dropna = False option, we can also get a missing value count."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-dropna-method",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-dropna-method",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method",
    "text": "Dealing with Missing Values: The dropna() method\nemp.dropna()\n\nThe dropna() method removes observations that hold any NaN or NaT values."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-dropna-method-with-how",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-dropna-method-with-how",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with how",
    "text": "Dealing with Missing Values: The dropna() method with how\nemp.dropna(how = \"all\")\n\nWe can pass the how parameter an argument of \"all\" to remove observations in which all values are missing.\nNote that the how parameter‚Äôs default argument is \"any\"."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-dropna-method-with-subset",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Gender\"])\n\nWe can use the subset parameter to target observations with a missing value in a specific variable.\n\nThe above example removes observations that have a missing value in the Gender variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-missing-values-the-dropna-method-with-subset-1",
    "title": "Lecture 11",
    "section": "Dealing with Missing Values: The dropna() method with subset",
    "text": "Dealing with Missing Values: The dropna() method with subset\nemp.dropna(subset = [\"Start Date\", \"Salary\"])\n\nWe can also pass the subset parameter a list of variables."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-duplicated-method",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-duplicated-method",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\n\n\nMissing values are a common occurrence in messy data sets, and so are duplicate values.\n\n\nemp[\"Team\"].duplicated()\n\nThe duplicated() method returns a Boolean Series that identifies duplicates in a variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-duplicated-method-1",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the duplicated() method",
    "text": "Dealing with Duplicates with the duplicated() method\nemp[\"Team\"].duplicated(keep = \"first\")\nemp[\"Team\"].duplicated(keep = \"last\")\n~emp[\"Team\"].duplicated()\n\nThe duplicated() method‚Äôs keep parameter informs pandas which duplicate occurrence to keep.\n\nIts default argument, \"first\", keeps the first occurrence of each duplicate value.\nIts argument, \"last\", keeps the last occurrence of each duplicate value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates()\n\nThe drop_duplicates() method removes observations in which all values are equal to those in a previously encountered observations."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method-1",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\n\n\nBelow is an example of the drop_duplicates() method:\n\n\n# Sample DataFrame with duplicate observations\ndata = {\n    'Name': ['John', 'Anna', 'John', 'Mike', 'Anna'],\n    'Age': [28, 23, 28, 32, 23],\n    'City': ['New York', 'Paris', 'New York', 'London', 'Paris']\n}\n\n# pd.DataFrame( Series, List, or Dict ) creates a DataFrame\ndf = pd.DataFrame(data)  \ndf_unique = df.drop_duplicates()"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method-2",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"])\n\nWe can pass the drop_duplicates() method a subset parameter with a list of columns that pandas should use to determine an observation‚Äôs uniqueness.\n\nThe above example finds the first occurrence of each unique value in the Team variable."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method-3",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Gender\", \"Team\"])\n\nThe above example uses a combination of values across the Gender and Team variables to identify duplicates."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#dealing-with-duplicates-with-the-drop_duplicates-method-4",
    "title": "Lecture 11",
    "section": "Dealing with Duplicates with the drop_duplicates() method",
    "text": "Dealing with Duplicates with the drop_duplicates() method\nemp.drop_duplicates(subset = [\"Team\"], keep = \"last\")\nemp.drop_duplicates(subset = [\"Team\"], keep = False)\n\nThe drop_duplicates() method also accepts a keep parameter.\n\nWe can pass it an argument of \"last\" to keep the observations with each duplicate value‚Äôs last occurrence.\nWe can pass it an argument of False to exclude all observations with duplicate values.\n\nQ. What does emp.drop_duplicates(subset = [\"First Name\"], keep = False) do?\nQ. Find a subset of all employees with a First Name of ‚ÄúDouglas‚Äù and a Gender of ‚ÄúMale‚Äù. Then check which ‚ÄúDouglas‚Äù is in the DataFrame emp.drop_duplicates(subset = [\"Gender\", \"Team\"])."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#pandas-basics",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#pandas-basics",
    "title": "Lecture 11",
    "section": "Pandas Basics",
    "text": "Pandas Basics\nLet‚Äôs do Questions 7-8 in Classwork 6!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-1",
    "title": "Lecture 11",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nTidy DataFrames\n\n\n\n\nThere are three interrelated rules that make a DataFrame tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is a row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-2",
    "title": "Lecture 11",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nimport pandas as pd\n# Below is for an interactive display of DataFrame in Colab\nfrom google.colab import data_table\ndata_table.enable_dataframe_formatter()\n\nA DataFrame can be given in a format unsuited for the analysis that we would like to perform on it.\n\nA DataFrame may have larger structural problems that extend beyond the data.\nPerhaps the DataFrame stores its values in a format that makes it easy to extract a single row but difficult to aggregate the data.\n\nReshaping a DataFrame means manipulating it into a different shape.\nIn this section, we will discuss pandas techniques for molding a DataFrame into the shape we desire."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#long-vs.-wide-dataframes",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#long-vs.-wide-dataframes",
    "title": "Lecture 11",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\n\nThe following DataFrames measure temperatures in two cities over two days.\n\n\ndf_wide = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday'],\n    'Miami': [80, 83],\n    'Rochester': [57, 62],\n    'St. Louis': [71, 75]\n})\n\ndf_long = pd.DataFrame({\n    'Weekday': ['Tuesday', 'Wednesday', 'Tuesday', 'Wednesday', 'Tuesday', 'Wednesday'],\n    'City': ['Miami', 'Miami', 'Rochester', 'Rochester', 'St. Louis', 'St. Louis'],\n    'Temperature': [80, 83, 57, 62, 71, 75]\n})"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#long-vs.-wide-dataframes-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#long-vs.-wide-dataframes-1",
    "title": "Lecture 11",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nA DataFrame can store its values in wide or long format.\nThese names reflect the direction in which the data set expands as we add more values to it.\n\nA long DataFrame increases in height.\nA wide DataFrame increases in width."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#long-vs.-wide-dataframes-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#long-vs.-wide-dataframes-2",
    "title": "Lecture 11",
    "section": "Long vs.¬†Wide DataFrames",
    "text": "Long vs.¬†Wide DataFrames\n\nThe optimal storage format for a DataFrame depends on the insight we are trying to glean from it.\n\nWe consider making DataFrames longer if one variable is spread across multiple columns.\nWe consider making DataFrames wider if one observation is spread across multiple rows."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-3",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-3",
    "title": "Lecture 11",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nmelt() and pivot()\n\n\n\n\nmelt() makes DataFrame longer.\npivot() and pivot_table() make DataFrame wider."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-longer-with-melt",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-longer-with-melt",
    "title": "Lecture 11",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt()\n)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-longer-with-melt-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-longer-with-melt-1",
    "title": "Lecture 11",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\")\n)\n\n\n\n\n\nmelt() can take a few parameters:\n\nid_vars is a container (string, list, tuple, or array) that represents the variables that will remain as is.\nid_vars can indicate which column should be the ‚Äúidentifier‚Äù."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-longer-with-melt-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-longer-with-melt-2",
    "title": "Lecture 11",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\")\n)\n\n\n\nmelt() can take a few parameters:\n\nvar_name is a string for the name of the variable whose values are taken from column names in a given wide-form DataFrame.\nvalue_name is a string for the name of the variable whose values are taken from the values in a given wide-form DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-longer-with-melt-3",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-longer-with-melt-3",
    "title": "Lecture 11",
    "section": "Make DataFrame Longer with melt()",
    "text": "Make DataFrame Longer with melt()\ndf_wide_to_long = (\n    df_wide\n    .melt(id_vars = \"Weekday\",\n          var_name = \"City\",\n          value_name = \"Temperature\",\n          value_vars = ['Miami', 'Rochester'])\n)\n\n\nmelt() can take a few parameters:\n\nvalue_vars parameter allows us to select which specific columns we want to ‚Äúmelt‚Äù.\nBy default, it will melt all the columns not specified in the id_vars parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-wider-with-pivot",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#make-dataframe-wider-with-pivot",
    "title": "Lecture 11",
    "section": "Make DataFrame Wider with pivot()",
    "text": "Make DataFrame Wider with pivot()\ndf_long_to_wide = (\n    df_long\n    .pivot(index = \"Weekday\",\n           columns = \"City\",\n           values = \"Temperature\"  \n        )\n    .reset_index()\n    )\n\nWhen using pivot(), we need to specify a few parameters:\n\nindex that takes the column to pivot on;\ncolumns that takes the column to be used to make the new variable names of the wider DataFrame;\nvalues that takes the column that provides the values of the variables in the wider DataFrame."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-4",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-4",
    "title": "Lecture 11",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\n\nThe pivot() method can also take a list of variable names for the index parameter."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-5",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-5",
    "title": "Lecture 11",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\n\n\nLet‚Äôs consider the following wide-form DataFrame, df, containing information about the number of courses each student took from each department in each year.\n\n\ndict_data = {\"Name\": [\"Donna\", \"Donna\", \"Mike\", \"Mike\"],\n             \"Department\": [\"ECON\", \"DANL\", \"ECON\", \"DANL\"],\n             \"2018\": [1, 2, 3, 1],\n             \"2019\": [2, 3, 4, 2],\n             \"2020\": [5, 1, 2, 2]}\ndf = pd.DataFrame(dict_data)\n\ndf_longer = df.melt(id_vars=[\"Name\", \"Department\"], \n                    var_name=\"Year\", \n                    value_name=\"Number of Courses\")\nQ. How can we use the df_longer to create the wide-form DataFrame, df_wider, which is equivalent to the df?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-6",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#reshaping-dataframes-6",
    "title": "Lecture 11",
    "section": "Reshaping DataFrames",
    "text": "Reshaping DataFrames\nLet‚Äôs do Part 1 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-1",
    "title": "Lecture 11",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\nSometimes, one data set is scattered across multiple files.\n\nThe size of the files can be huge.\nThe data collection process can be scattered across time and space.\nE.g., DataFrame for county-level data and DataFrame for geographic information, such as longitude and latitude.\n\nSometimes we want to combine two or more DataFrames based on common data values in those DataFrames.\n\nThis task is known in the database world as performing a ‚Äújoin.‚Äù\nWe can do this with the merge() method in Pandas."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-2",
    "title": "Lecture 11",
    "section": "Joining DataFrames",
    "text": "Joining DataFrames\nRelational Data\n\n\nThe variables that are used to connect each pair of tables are called keys."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\n\n\n\n\n\nx = pd.DataFrame({\n    'key': [1, 2, 3],\n    'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n    'key': [1, 2, 4],\n    'val_y': ['y1', 'y2', 'y3']\n})\n\n\n\nThe colored column represents the ‚Äúkey‚Äù variable.\nThe grey column represents the ‚Äúvalue‚Äù column."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-1",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nInner Join\n\nAn inner join matches pairs of observations whenever their keys are equal:\n\n\n\n\n# the default value for 'how' is 'inner'\n# so it doesn't actually need to be specified\nmerge_inner = pd.merge(x, y, on='key', how='inner')\nmerge_inner_x = x.merge(y, on='key', how='inner')\nmerge_inner_x_how = x.merge(y, on='key')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-2",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLeft Join\n\nA left join keeps all observations in x.\n\n\n\n\nmerge_left = pd.merge(x, y, on='key', how='left')\nmerge_left_x = x.merge(y, on='key', how='left')\n\nThe most commonly used join is the left join."
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-3",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-3",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nRight Join\n\nA right join keeps all observations in y.\n\n\n\n\nmerge_right = pd.merge(x, y, on='key', how='right')\nmerge_right_x = x.merge(y, on='key', how='right')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-4",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-4",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nOuter (Full) Join\n\nA full join keeps all observations in x and y.\n\n\n\n\nmerge_outer = pd.merge(x, y, on='key', how='outer')\nmerge_outer_x = x.merge(y, on='key', how='outer')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-5",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-5",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: one-to-many\n\nOne DataFrame has duplicate keys (a one-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n    'key':[1, 2, 2, 3],\n    'val_x':['x1', 'x2', 'x3', 'x4']})\n\ny = pd.DataFrame({\n    'key':[1, 2],\n    'val_y':['y1', 'y2'] })\none_to_many = x.merge(y, on='key', \n                         how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-6",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-6",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDuplicate keys: many-to-many\n\nBoth DataFrames have duplicate keys (many-to-many relationship).\n\n\n\n\n\n\nx = pd.DataFrame({\n  'key':[1, 2, 2, 3],\n  'val_x':['x1','x2','x3','x4']})\n\ny = pd.DataFrame({\n  'key': [1, 2, 2, 3],\n  'val_y': ['y1', 'y2', 'y3', 'y4'] })\nmany_to_many = x.merge(y, on='key', \n                          how='left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-7",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-7",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nDefining the key columns\n\n\nIf the left and right columns do not have the same name for the key variables, we can use the left_on and right_on parameters instead.\n\n\n\n\nx = pd.DataFrame({\n  'key_x': [1, 2, 3],\n  'val_x': ['x1', 'x2', 'x3']\n})\n\ny = pd.DataFrame({\n  'key_y': [1, 2],\n  'val_y': ['y1', 'y2'] })\n\nkeys_xy = \n  x.merge(y, left_on = 'key_x', \n             right_on = 'key_y', \n             how = 'left')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-8",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#joining-dataframes-with-merge-8",
    "title": "Lecture 11",
    "section": "Joining DataFrames with merge()",
    "text": "Joining DataFrames with merge()\nLet‚Äôs do Part 2 of Classwork 7!"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-1",
    "title": "Lecture 11",
    "section": "Data Concatenation",
    "text": "Data Concatenation\n\n\nConcatenation can be thought of as appending a row or column to our data.\n\nThis approach is possible if our data was split into parts or if we performed a calculation that we want to append to our existing data set.\n\nLet‚Äôs consider the following example DataFrames:\n\ndf1 = pd.read_csv('https://bcdanl.github.io/data/concat_1.csv')\ndf2 = pd.read_csv('https://bcdanl.github.io/data/concat_2.csv')\ndf3 = pd.read_csv('https://bcdanl.github.io/data/concat_3.csv')\n\nWe will be working with .index and .columns in this Section.\n\ndf1.index\ndf1.columns"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-2",
    "title": "Lecture 11",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nConcatenating the DataFrames on top of each other uses the concat() method.\n\nAll of the DataFrames to be concatenated are passed in a list.\n\n\nrow_concat = pd.concat([df1, df2, df3])\nrow_concat"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-3",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-3",
    "title": "Lecture 11",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nLet‚Äôs consider a new Series and concatenate it with df1:\n\n# create a new row of data\nnew_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\nnew_row_series\n\n\n# attempt to add the new row to a dataframe\ndf = pd.concat([df1, new_row_series])\ndf\n\nNot only did our code not append the values as a row, but it also created a new column completely misaligned with everything else.\nWhy?"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-4",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-4",
    "title": "Lecture 11",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Rows\n\n\nTo fix the problem, we need turn our Series into a DataFrame.\n\nThis data frame contains one row of data, and the column names are the ones the data will bind to.\n\n\nnew_row_df = pd.DataFrame(\n  # note the double brackets to create a \"row\" of data\n  data =[[\"n1\", \"n2\", \"n3\", \"n4\"]],\n  columns =[\"A\", \"B\", \"C\", \"D\"],\n)\n\ndf = pd.concat([df1, new_row_df])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-5",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-5",
    "title": "Lecture 11",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nConcatenating columns is very similar to concatenating rows.\n\nThe main difference is the axis parameter in the concat() method.\nThe default value of axis is 0 (or axis = \"index\"), so it will concatenate data in a row-wise fashion.\nIf we pass axis = 1 (or axis = \"columns\") to the function, it will concatenate data in a column-wise manner.\n\n\ncol_concat = pd.concat([df1, df2, df3], axis = \"columns\")"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-6",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-6",
    "title": "Lecture 11",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nAdd Columns\n\n\nWe can use ignore_index=True to reset the column indices, so that we do not have duplicated column names.\n\npd.concat([df1, df2, df3], axis=\"columns\", ignore_index=True)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#concatenate-with-different-indices",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#concatenate-with-different-indices",
    "title": "Lecture 11",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhat would happen when the row and column indices are not aligned?\nLet‚Äôs modify our DataFrames for the next few examples.\n\n# rename the columns of our dataframes\ndf1.columns = ['A', 'B', 'C', 'D']\ndf2.columns = ['E', 'F', 'G', 'H']\ndf3.columns = ['A', 'C', 'F', 'H']\n\nIf we try to concatenate these DataFrames as we did, the DataFrames now do much more than simply stack one on top of the other.\n\nrow_concat = pd.concat([df1, df2, df3])"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#concatenate-with-different-indices-1",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#concatenate-with-different-indices-1",
    "title": "Lecture 11",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWe can set join = 'inner' to keep only the columns that are shared among the data sets.\n\npd.concat([df1, df2, df3], join ='inner')\n\nIf we use the DataFrames that have columns in common, only the columns that all of them share will be returned.\n\npd.concat([df1, df3], join ='inner',  ignore_index =False)"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#concatenate-with-different-indices-2",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#concatenate-with-different-indices-2",
    "title": "Lecture 11",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nLet‚Äôs modify our DataFrames further.\n\n# re-indexing the rows of our DataFrames\ndf1.index = [0, 1, 2, 3]\ndf2.index = [4, 5, 6, 7]\ndf3.index = [0, 2, 5, 7]"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#concatenate-with-different-indices-3",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#concatenate-with-different-indices-3",
    "title": "Lecture 11",
    "section": "Concatenate with Different Indices",
    "text": "Concatenate with Different Indices\n\n\nWhen we concatenate along axis=\"columns\" (axis=1), the new DataFrames will be added in a column-wise fashion and matched against their respective row indices.\n\ncol_concat = pd.concat([df1, df2, df3], axis=\"columns\")\n\nJust as we did when we concatenated in a row-wise manner, we can choose to keep the results only when there are matching indices by using join=\"inner\".\n\npd.concat([df1, df3], axis =\"columns\", join='inner')"
  },
  {
    "objectID": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-7",
    "href": "danl-lec/danl-210-lec-11-2025-0221.html#data-concatenation-7",
    "title": "Lecture 11",
    "section": "Data Concatenation",
    "text": "Data Concatenation\nLet‚Äôs do Part 3 of Classwork 7!"
  }
]